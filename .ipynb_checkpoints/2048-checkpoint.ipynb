{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "directed-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "from tkinter import *\n",
    "import pylab\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "three-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env():\n",
    "    LEFT = 0\n",
    "    UP = 1\n",
    "    RIGHT = 2\n",
    "    DOWN = 3\n",
    "\n",
    "    ACTION_STRING = {LEFT : 'left', UP:'up' , RIGHT:'right', DOWN:'down'}\n",
    "\n",
    "    def __init__(self, width =4, height =4):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        \n",
    "        self.board = None\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.board = np.zeros((self.width,self.height),dtype = np.int64)\n",
    "        self.place_random_tiles(self.board,cnt=2)\n",
    "        return self.board\n",
    "        \n",
    "    def canMove(self, action:int, state):\n",
    "        state = state.reshape((4,4))\n",
    "        rotated_obs = np.rot90(state, k=action)\n",
    "        reward, updated_obs = self.slide_left_and_merge(rotated_obs)\n",
    "        bord = np.rot90(updated_obs, k=4 - action).reshape(1,-1)\n",
    "        return bord\n",
    "    \n",
    "    def canMove_t(self, action:int, state):\n",
    "        state_ = state.to('cpu').numpy().copy()[0][0]\n",
    "        state.to('cuda')\n",
    "        rotated_obs = np.rot90(state_, k=action)\n",
    "        reward, updated_obs = self.slide_left_and_merge(rotated_obs)\n",
    "        bord = np.rot90(updated_obs, k=4 - action)\n",
    "        return state_.reshape(-1,16), bord.reshape(-1,16)\n",
    "    \n",
    "    def step(self,action:int):\n",
    "        rotated_obs = np.rot90(self.board, k=action)\n",
    "        reward, updated_obs = self.slide_left_and_merge(rotated_obs)\n",
    "        self.board = np.rot90(updated_obs, k=4 - action)\n",
    "        \n",
    "        self.place_random_tiles(self.board, cnt=1)\n",
    "        done = self.is_done()\n",
    "        \n",
    "        return self.board, reward,done,{}\n",
    "    \n",
    "    def is_done(self):\n",
    "        temp = self.board.copy()\n",
    "        if not temp.all():\n",
    "            return False\n",
    "        \n",
    "        for action in range(4):\n",
    "            rotated_obs = np.rot90(temp,k=action)\n",
    "            _,updated_obs = self.slide_left_and_merge(rotated_obs)\n",
    "            if not updated_obs.all():\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "            \n",
    "            \n",
    "        \n",
    "    def sample_tiles(self, cnt=1):\n",
    "\n",
    "        choices = [2, 4]\n",
    "        probs = [0.9, 0.1]\n",
    "\n",
    "        tiles = np.random.choice(choices,size=cnt, p=probs)\n",
    "        return tiles.tolist()\n",
    "\n",
    "    def place_random_tiles(self,board,cnt =1):\n",
    "        if not board.all():\n",
    "            tiles = self.sample_tiles(cnt)\n",
    "            tile_locations = self.sample_tile_locations(board, cnt)\n",
    "            board[tuple(tile_locations)] = tiles\n",
    "    \n",
    "    def sample_tile_locations(self, board, cnt=1):\n",
    "        zero_locations = np.argwhere(board==0)\n",
    "        zero_index = np.random.choice(len(zero_locations) , size = cnt)\n",
    "        \n",
    "        zero_position = zero_locations[zero_index]\n",
    "        zero_position = list(zip(*zero_position))\n",
    "        \n",
    "        return zero_position\n",
    "    \n",
    "    \n",
    "    def slide_left_and_merge(self, board):\n",
    "        result=[]\n",
    "        score = 0\n",
    "        for row in board:\n",
    "            row = np.extract(row>0,row)\n",
    "            score_, result_row = self.try_merge(row)\n",
    "            \n",
    "            score+= score_\n",
    "            row = np.pad(np.array(result_row), (0, self.width - len(result_row)), 'constant', constant_values=(0,))\n",
    "            result.append(row)\n",
    "            \n",
    "        return score, np.array(result, dtype=np.int64)\n",
    "    \n",
    "    @staticmethod\n",
    "    def try_merge(row):\n",
    "        score = 0\n",
    "        result_row = []\n",
    "        i=1\n",
    "        while i <len(row):\n",
    "            if row[i] == row[i-1]:\n",
    "                score += row[i]*2\n",
    "                result_row.append(row[i]*2)\n",
    "                i+=2\n",
    "            else:\n",
    "                result_row.append(row[i-1])\n",
    "                i+=1\n",
    "        if i==len(row):\n",
    "            result_row.append(row[i-1])\n",
    "        return score, result_row\n",
    "    \n",
    "    def render(self):\n",
    "        return self.board\n",
    "#         for row in self.board.tolist():\n",
    "#             print(' \\t'.join(map(str, row)))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "inappropriate-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "damaged-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self,state_size,action_size, load_model):\n",
    "        self.load_model = load_model\n",
    "        self.train_loss = 0\n",
    "        self.render = True\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.00005\n",
    "        \n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay=0.99999\n",
    "        self.epsilon_min = 0.10\n",
    "        \n",
    "        self.batch_size = 1024\n",
    "        self.train_start = 1024\n",
    "\n",
    "        self.queueLenMax = 5000\n",
    "        self.memory = deque(maxlen = self.queueLenMax)\n",
    "        \n",
    "        self.perfWindowSize =10\n",
    "        self.penalty = -100\n",
    "        \n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        self.model ,self.model_optim, self.model_loss= self.build_model()\n",
    "        self.target_model,self.target_model_optim,self.target_model_loss = self.build_model()\n",
    "    \n",
    "        self.update_target_model() # set same weights at the first time\n",
    "        \n",
    "        if self.load_model:\n",
    "            self.model.load_state_dict(torch.load(\"./save_model/2048_dqn_trained.pth\"))\n",
    "            self.epsilon_decay =1 \n",
    "            self.epsilon = 0\n",
    "            self.epsilon_min = 0\n",
    "            print('Model_loaded...')\n",
    "\n",
    "    def change_values(X):\n",
    "        power_mat = np.zeros(shape=(1,4,4,16),dtype=np.float32)\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                if(X[i][j]==0):\n",
    "                    power_mat[0][i][j][0] = 1.0\n",
    "                else:\n",
    "                    power = int(math.log(X[i][j],2))\n",
    "                    power_mat[0][i][j][power] = 1.0\n",
    "        return power_mat    \n",
    "    \n",
    "    def build_model(self):\n",
    "        \n",
    "        model = nn.Sequential(nn.Conv2d(1,16, kernel_size=2,stride=1),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Conv2d(16,32, kernel_size=2,stride=1),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Conv2d(32,64, kernel_size=2,stride=1),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Flatten(),\n",
    "                              nn.Linear(64,128),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Linear(128,16),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Linear(16,4))\n",
    "        model.to('cuda')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = self.learning_rate)\n",
    "        loss = nn.MSELoss()\n",
    "\n",
    "        return model,optimizer,loss\n",
    "    \n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        \n",
    "    \n",
    "    def get_action(self, state, env):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            legal_moves = list()\n",
    "            for i in range(4):\n",
    "                temp_board = env.canMove(i, state)\n",
    "                if(np.array_equal(temp_board,state)):\n",
    "                    continue\n",
    "                else:\n",
    "                    legal_moves.append(i)\n",
    "            return random.choice(legal_moves)\n",
    "        else:\n",
    "            state = torch.tensor([state],dtype =torch.float32).reshape(-1,1,4,4).to('cuda')\n",
    "            state_ = state.clone()\n",
    "            state_[state_ == 0] = 1.\n",
    "            q_value = self.model(torch.log2(state_))\n",
    "            q_value = q_value.cpu().detach().numpy()\n",
    "            legal_moves = list()\n",
    "            for i in range(4):\n",
    "                state_, temp_board = env.canMove_t(i, state)\n",
    "                if np.array_equal(temp_board,state_):\n",
    "                    continue\n",
    "                else:\n",
    "                    legal_moves.append(i)\n",
    "            while np.argmax(q_value[0]) not in legal_moves:\n",
    "                q_value[0][np.argmax(q_value[0])] = -np.inf\n",
    "                if len(legal_moves) == 0:\n",
    "                    break\n",
    "                continue\n",
    "            return np.argmax(q_value[0])\n",
    "        \n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "            \n",
    "    def train_model(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        else:\n",
    "            self.epsilon = self.epsilon_min\n",
    "            \n",
    "        mini_batch = random.sample(self.memory, self.batch_size)\n",
    "\n",
    "        states = np.zeros((self.batch_size, self.state_size))\n",
    "        next_states = np.zeros((self.batch_size, self.state_size))\n",
    "        actions, rewards, dones = [], [], []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            states[i] = mini_batch[i][0]\n",
    "            actions.append(mini_batch[i][1])\n",
    "            rewards.append(mini_batch[i][2])\n",
    "            next_states[i] = mini_batch[i][3]\n",
    "            dones.append(mini_batch[i][4])\n",
    "    \n",
    "        \n",
    "        states = torch.tensor(states, dtype =torch.float32).reshape(-1,1,4,4).to('cuda')\n",
    "        states[states==0] = 1.\n",
    "        next_states = torch.tensor(next_states,dtype =torch.float32).reshape(-1,1,4,4).to('cuda')\n",
    "        next_states[next_states==0] = 1.\n",
    "        \n",
    "        target = self.model(torch.log2(states))\n",
    "        target_val = self.target_model(torch.log2(next_states))\n",
    "    \n",
    "        target_val = target_val.cpu().detach().numpy()\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            if dones[i]:\n",
    "                target[i][actions[i]] = rewards[i]\n",
    "            else:\n",
    "                target[i][actions[i]] = rewards[i] + self.discount_factor * (np.amax(target_val[i]))\n",
    "\n",
    "        # and do the model fit!\n",
    "        self.model.train()\n",
    "        self.model_optim.zero_grad()\n",
    "        \n",
    "        output = self.model(torch.log2(states))\n",
    "        loss = self.model_loss(output,target)\n",
    "        loss.backward()\n",
    "        self.train_loss += loss.item()\n",
    "        self.model_optim.step()\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "interracial-effect",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   score: 1104  move: 118   memory length: 118   epsilon: 1.0  loss: 0.0\n",
      "Weights save... Top reward = 168\n",
      "episode: 1   score: 1636  move: 166   memory length: 284   epsilon: 1.0  loss: 0.0\n",
      "episode: 2   score: 448  move: 65   memory length: 349   epsilon: 1.0  loss: 0.0\n",
      "episode: 3   score: 916  move: 99   memory length: 448   epsilon: 1.0  loss: 0.0\n",
      "episode: 4   score: 1076  move: 116   memory length: 564   epsilon: 1.0  loss: 0.0\n",
      "episode: 5   score: 3040  move: 250   memory length: 814   epsilon: 1.0  loss: 0.0\n",
      "Weights save... Top reward = 260\n",
      "episode: 6   score: 724  move: 90   memory length: 904   epsilon: 1.0  loss: 0.0\n",
      "episode: 7   score: 1604  move: 158   memory length: 1062   epsilon: 0.9996100740908634  loss: 29.85304211966599\n",
      "episode: 8   score: 932  move: 116   memory length: 1178   epsilon: 0.998451192891553  loss: 156.13477739794502\n",
      "episode: 9   score: 792  move: 97   memory length: 1275   epsilon: 0.9974831599661506  loss: 286.7746789676627\n",
      "episode: 10   score: 572  move: 77   memory length: 1352   epsilon: 0.996715389723601  loss: 451.1269967710817\n",
      "episode: 11   score: 1228  move: 126   memory length: 1478   epsilon: 0.9954603129215938  loss: 358.3215570298452\n",
      "episode: 12   score: 1308  move: 133   memory length: 1611   epsilon: 0.9941372241390352  loss: 420.32497348641994\n",
      "episode: 13   score: 672  move: 87   memory length: 1698   epsilon: 0.9932726965554225  loss: 725.0849683038119\n",
      "episode: 14   score: 616  move: 88   memory length: 1786   epsilon: 0.9923989966982716  loss: 798.4503919861534\n",
      "episode: 15   score: 820  move: 103   memory length: 1889   epsilon: 0.9913773468634065  loss: 764.1062710215745\n",
      "episode: 16   score: 288  move: 55   memory length: 1944   epsilon: 0.9908322365161651  loss: 1517.0259804465554\n",
      "episode: 17   score: 1316  move: 135   memory length: 2079   epsilon: 0.9894955088074443  loss: 706.581374641701\n",
      "episode: 18   score: 1080  move: 125   memory length: 2204   epsilon: 0.9882594059661434  loss: 858.1589099426269\n",
      "episode: 19   score: 1332  move: 138   memory length: 2342   epsilon: 0.9868965417641706  loss: 875.1297857035761\n",
      "episode: 20   score: 1320  move: 139   memory length: 2481   epsilon: 0.9855257016714948  loss: 972.8536911285181\n",
      "episode: 21   score: 1268  move: 128   memory length: 2609   epsilon: 0.9842650294723211  loss: 1169.9618918597698\n",
      "episode: 22   score: 628  move: 87   memory length: 2696   epsilon: 0.9834090870059261  loss: 1841.9883142668625\n",
      "episode: 23   score: 1500  move: 158   memory length: 2854   epsilon: 0.9818565197367445  loss: 1142.2244740015344\n",
      "episode: 24   score: 1424  move: 146   memory length: 3000   epsilon: 0.9804240480143774  loss: 1370.14871260238\n",
      "episode: 25   score: 1244  move: 128   memory length: 3128   epsilon: 0.9791699017870016  loss: 1708.058908611536\n",
      "episode: 26   score: 1256  move: 132   memory length: 3260   epsilon: 0.9778782437402078  loss: 1808.234132680026\n",
      "episode: 27   score: 780  move: 94   memory length: 3354   epsilon: 0.9769594654906274  loss: 2701.522671435742\n",
      "episode: 28   score: 268  move: 51   memory length: 3405   epsilon: 0.9764613407052186  loss: 5151.178099164776\n",
      "episode: 29   score: 288  move: 52   memory length: 3457   epsilon: 0.9759537102652511  loss: 5229.070188595699\n",
      "episode: 30   score: 620  move: 79   memory length: 3536   epsilon: 0.9751830074483208  loss: 3636.1640449717074\n",
      "episode: 31   score: 460  move: 74   memory length: 3610   epsilon: 0.9744616353565387  loss: 4076.3760376492064\n",
      "episode: 32   score: 700  move: 94   memory length: 3704   epsilon: 0.9735460672258973  loss: 3414.7988482130336\n",
      "episode: 33   score: 800  move: 105   memory length: 3809   epsilon: 0.972524375229013  loss: 3276.8620076134093\n",
      "episode: 34   score: 548  move: 76   memory length: 3885   epsilon: 0.9717855338049332  loss: 4742.086653609025\n",
      "episode: 35   score: 1100  move: 117   memory length: 4002   epsilon: 0.970649203931331  loss: 3311.3527047899033\n",
      "episode: 36   score: 2224  move: 186   memory length: 4188   epsilon: 0.9688454653901825  loss: 2322.72740638897\n",
      "Weights save... Top reward = 264\n",
      "episode: 37   score: 1536  move: 150   memory length: 4338   epsilon: 0.9673932793429837  loss: 3129.4741588083903\n",
      "episode: 38   score: 976  move: 121   memory length: 4459   epsilon: 0.9662234355239969  loss: 4135.659213704511\n",
      "episode: 39   score: 616  move: 84   memory length: 4543   epsilon: 0.9654121445716033  loss: 6221.201884088062\n",
      "episode: 40   score: 1340  move: 142   memory length: 4685   epsilon: 0.964042225349551  loss: 3954.555675963281\n",
      "episode: 41   score: 420  move: 61   memory length: 4746   epsilon: 0.9634543359771267  loss: 9504.568522281334\n",
      "episode: 42   score: 1128  move: 120   memory length: 4866   epsilon: 0.9622988784098573  loss: 5125.033995469411\n",
      "episode: 43   score: 2204  move: 176   memory length: 5000   epsilon: 0.9606067134649825  loss: 3789.6101461107082\n",
      "episode: 44   score: 1236  move: 127   memory length: 5000   epsilon: 0.9593875112001754  loss: 5561.954713145579\n",
      "episode: 45   score: 1384  move: 146   memory length: 5000   epsilon: 0.957987820458238  loss: 5164.426427997955\n",
      "episode: 46   score: 1412  move: 145   memory length: 5000   epsilon: 0.9565997377813003  loss: 5538.707312458959\n",
      "episode: 47   score: 1272  move: 129   memory length: 5000   epsilon: 0.9553665135540816  loss: 6567.0802895301995\n",
      "episode: 48   score: 1316  move: 136   memory length: 5000   epsilon: 0.9540680917305051  loss: 6583.422114007613\n",
      "episode: 49   score: 580  move: 81   memory length: 5000   epsilon: 0.9532956056128836  loss: 11414.568971280698\n",
      "episode: 50   score: 1168  move: 126   memory length: 5000   epsilon: 0.9520952035599036  loss: 7706.104489795745\n",
      "episode: 51   score: 1052  move: 117   memory length: 5000   epsilon: 0.9509818980159508  loss: 8665.298690567668\n",
      "episode: 52   score: 1124  move: 120   memory length: 5000   epsilon: 0.9498413984724168  loss: 8825.062287807465\n",
      "episode: 53   score: 1444  move: 141   memory length: 5000   epsilon: 0.948503059159815  loss: 7895.587225866656\n",
      "episode: 54   score: 1060  move: 115   memory length: 5000   epsilon: 0.9474129021514164  loss: 10069.90254373965\n",
      "episode: 55   score: 1348  move: 140   memory length: 5000   epsilon: 0.946087445497267  loss: 8675.808815247672\n",
      "episode: 56   score: 1452  move: 145   memory length: 5000   epsilon: 0.9447166059459515  loss: 8785.266836784625\n",
      "episode: 57   score: 580  move: 80   memory length: 5000   epsilon: 0.9439611311140425  loss: 16349.058296251296\n",
      "episode: 58   score: 1420  move: 144   memory length: 5000   epsilon: 0.9426027985277531  loss: 9496.85729739401\n",
      "episode: 59   score: 1296  move: 132   memory length: 5000   epsilon: 0.94135937745504  loss: 10776.310814048305\n",
      "episode: 60   score: 1000  move: 105   memory length: 5000   epsilon: 0.9403714639145143  loss: 13964.313219815209\n",
      "episode: 61   score: 564  move: 76   memory length: 5000   epsilon: 0.939657049541714  loss: 19715.570115992898\n",
      "episode: 62   score: 316  move: 54   memory length: 5000   epsilon: 0.9391497691765831  loss: 28187.61640852469\n",
      "episode: 63   score: 1344  move: 138   memory length: 5000   epsilon: 0.9378546298710779  loss: 11475.523958869602\n",
      "episode: 64   score: 1316  move: 135   memory length: 5000   epsilon: 0.9365893740343191  loss: 12194.185197985615\n",
      "episode: 65   score: 744  move: 101   memory length: 5000   epsilon: 0.9356438915881379  loss: 16761.74721402461\n",
      "episode: 66   score: 264  move: 50   memory length: 5000   epsilon: 0.9351761842403863  loss: 34328.96674598694\n",
      "episode: 67   score: 1200  move: 129   memory length: 5000   epsilon: 0.9339705787174344  loss: 13786.545498308285\n",
      "episode: 68   score: 644  move: 84   memory length: 5000   epsilon: 0.9331863689244844  loss: 21654.038671084814\n",
      "episode: 69   score: 832  move: 99   memory length: 5000   epsilon: 0.9322629669616269  loss: 18849.473728256995\n",
      "episode: 70   score: 428  move: 60   memory length: 5000   epsilon: 0.9317037741600996  loss: 31593.4953748703\n",
      "episode: 71   score: 1136  move: 122   memory length: 5000   epsilon: 0.9305677829711908  loss: 16026.041880654508\n",
      "episode: 72   score: 332  move: 56   memory length: 5000   epsilon: 0.9300468082943756  loss: 35409.85606663568\n",
      "episode: 73   score: 992  move: 111   memory length: 5000   epsilon: 0.9290150239245072  loss: 18370.995677260664\n",
      "episode: 74   score: 696  move: 95   memory length: 5000   epsilon: 0.9281328743284313  loss: 21963.85022619147\n",
      "episode: 75   score: 876  move: 108   memory length: 5000   epsilon: 0.9271310269099017  loss: 19821.466213402924\n",
      "episode: 76   score: 452  move: 65   memory length: 5000   epsilon: 0.9265285845451753  loss: 33473.45332037119\n",
      "episode: 77   score: 1456  move: 151   memory length: 5000   epsilon: 0.9251305751551844  loss: 14929.550825839011\n",
      "episode: 78   score: 1428  move: 146   memory length: 5000   epsilon: 0.9237808632963057  loss: 15960.661760434712\n",
      "episode: 79   score: 1276  move: 129   memory length: 5000   epsilon: 0.922589948333376  loss: 18595.769109829453\n",
      "episode: 80   score: 1256  move: 125   memory length: 5000   epsilon: 0.9214374256121112  loss: 19727.11401309204\n",
      "episode: 81   score: 1300  move: 132   memory length: 5000   epsilon: 0.9202219245399927  loss: 19215.38035921617\n",
      "episode: 82   score: 1076  move: 116   memory length: 5000   epsilon: 0.9191550806623809  loss: 22406.635423758933\n",
      "episode: 83   score: 956  move: 114   memory length: 5000   epsilon: 0.9181078356772557  loss: 23355.31572298418\n",
      "episode: 84   score: 540  move: 72   memory length: 5000   epsilon: 0.9174470326491877  loss: 37550.793901496465\n",
      "episode: 85   score: 1264  move: 133   memory length: 5000   epsilon: 0.9162276330792264  loss: 20883.187051557958\n",
      "episode: 86   score: 1128  move: 120   memory length: 5000   epsilon: 0.9151288138488278  loss: 23701.52389160792\n",
      "episode: 87   score: 1436  move: 148   memory length: 5000   epsilon: 0.9137754181971709  loss: 19796.13968197075\n",
      "episode: 88   score: 2352  move: 195   memory length: 5000   epsilon: 0.9119952834264902  loss: 15587.80253822131\n",
      "Weights save... Top reward = 272\n",
      "episode: 89   score: 1376  move: 148   memory length: 5000   epsilon: 0.9106465219928631  loss: 21100.258693720843\n",
      "episode: 90   score: 1028  move: 112   memory length: 5000   epsilon: 0.9096271637386156  loss: 28450.673664808273\n",
      "episode: 91   score: 904  move: 97   memory length: 5000   epsilon: 0.9087452487781167  loss: 33429.93243176175\n",
      "episode: 92   score: 788  move: 105   memory length: 5000   epsilon: 0.9077915622714997  loss: 31456.425177183606\n",
      "episode: 93   score: 1824  move: 177   memory length: 5000   epsilon: 0.9061861843579633  loss: 19244.468105790304\n",
      "episode: 94   score: 788  move: 104   memory length: 5000   epsilon: 0.905244235914578  loss: 33334.63479749973\n",
      "episode: 95   score: 1320  move: 133   memory length: 5000   epsilon: 0.9040410553573347  loss: 26672.083133926964\n",
      "episode: 96   score: 364  move: 63   memory length: 5000   epsilon: 0.9034716860157853  loss: 56887.316970885746\n",
      "episode: 97   score: 608  move: 85   memory length: 5000   epsilon: 0.90270405753285  loss: 42768.99008488374\n",
      "episode: 98   score: 1348  move: 142   memory length: 5000   epsilon: 0.9014231210466125  loss: 26205.01658299943\n",
      "episode: 99   score: 1184  move: 126   memory length: 5000   epsilon: 0.9002880374914833  loss: 30133.757865936037\n",
      "episode: 100   score: 540  move: 74   memory length: 5000   epsilon: 0.8996220674531918  loss: 51934.0088553042\n",
      "episode: 101   score: 2900  move: 243   memory length: 5000   epsilon: 0.8974386288643864  loss: 16416.704184277067\n",
      "episode: 102   score: 1404  move: 147   memory length: 5000   epsilon: 0.8961203566560519  loss: 27764.812550161972\n",
      "episode: 103   score: 652  move: 86   memory length: 5000   epsilon: 0.8953500205896318  loss: 48095.35395018999\n",
      "episode: 104   score: 600  move: 83   memory length: 5000   epsilon: 0.8946071846779085  loss: 50471.78651175441\n",
      "episode: 105   score: 556  move: 78   memory length: 5000   epsilon: 0.8939096596563552  loss: 54320.07466697693\n",
      "episode: 106   score: 1040  move: 109   memory length: 5000   epsilon: 0.8929358240949473  loss: 39497.01725688549\n",
      "episode: 107   score: 884  move: 107   memory length: 5000   epsilon: 0.8919808889698878  loss: 40877.66636176421\n",
      "episode: 108   score: 1076  move: 113   memory length: 5000   epsilon: 0.8909735148020755  loss: 39327.0544448785\n",
      "episode: 109   score: 1168  move: 126   memory length: 5000   epsilon: 0.8898515895251503  loss: 35897.90879570492\n",
      "episode: 110   score: 584  move: 80   memory length: 5000   epsilon: 0.8891399893735392  loss: 57160.46392045021\n",
      "episode: 111   score: 632  move: 87   memory length: 5000   epsilon: 0.8883667701158332  loss: 53196.845111233066\n",
      "episode: 112   score: 560  move: 76   memory length: 5000   epsilon: 0.8876918644926372  loss: 61550.84701723801\n",
      "episode: 113   score: 2292  move: 189   memory length: 5000   epsilon: 0.8860157029595352  loss: 25410.648873727787\n",
      "episode: 114   score: 652  move: 89   memory length: 5000   epsilon: 0.885227495847057  loss: 54617.74013034949\n",
      "episode: 115   score: 1216  move: 132   memory length: 5000   epsilon: 0.8840597605886853  loss: 37471.31100917585\n",
      "episode: 116   score: 1088  move: 114   memory length: 5000   epsilon: 0.8830525016719851  loss: 44027.622257065355\n",
      "episode: 117   score: 1084  move: 118   memory length: 5000   epsilon: 0.8820111090555258  loss: 43183.92625727896\n",
      "episode: 118   score: 1700  move: 156   memory length: 5000   epsilon: 0.8806362375296519  loss: 33336.61022628882\n",
      "episode: 119   score: 1468  move: 146   memory length: 5000   epsilon: 0.8793514403290486  loss: 36291.6676170924\n",
      "episode: 120   score: 1124  move: 119   memory length: 5000   epsilon: 0.8783056292669946  loss: 45209.46584919521\n",
      "episode: 121   score: 1464  move: 151   memory length: 5000   epsilon: 0.8769803819540898  loss: 36317.41939713939\n",
      "episode: 122   score: 1356  move: 140   memory length: 5000   epsilon: 0.8757534623288865  loss: 39858.8542760849\n",
      "episode: 123   score: 840  move: 101   memory length: 5000   epsilon: 0.8748693934415279  loss: 55931.14672084846\n",
      "episode: 124   score: 652  move: 86   memory length: 5000   epsilon: 0.8741173254384196  loss: 66390.48785529025\n",
      "episode: 125   score: 1160  move: 125   memory length: 5000   epsilon: 0.873025355944888  loss: 46382.39765371704\n",
      "episode: 126   score: 456  move: 75   memory length: 5000   epsilon: 0.8723708291335276  loss: 78016.3341388448\n",
      "episode: 127   score: 620  move: 86   memory length: 5000   epsilon: 0.8716209089827543  loss: 68771.81392922513\n",
      "episode: 128   score: 2404  move: 203   memory length: 5000   epsilon: 0.8698533044251288  loss: 29843.781827522616\n",
      "episode: 129   score: 1476  move: 154   memory length: 5000   epsilon: 0.868514754591475  loss: 40050.833028149296\n",
      "episode: 130   score: 1104  move: 118   memory length: 5000   epsilon: 0.8674905064850427  loss: 52991.82656669617\n",
      "episode: 131   score: 1028  move: 124   memory length: 5000   epsilon: 0.8664154795363179  loss: 51173.74204810973\n",
      "episode: 132   score: 596  move: 83   memory length: 5000   epsilon: 0.8656966494499025  loss: 77204.04371647662\n",
      "episode: 133   score: 1388  move: 148   memory length: 5000   epsilon: 0.8644163596554072  loss: 44032.94216911213\n",
      "episode: 134   score: 2876  move: 241   memory length: 5000   epsilon: 0.8623356141303623  loss: 27751.3834963755\n",
      "episode: 135   score: 1048  move: 113   memory length: 5000   epsilon: 0.8613617203705282  loss: 59913.978900909424\n",
      "episode: 136   score: 924  move: 101   memory length: 5000   epsilon: 0.8604921798771157  loss: 67753.56270807097\n",
      "episode: 137   score: 1320  move: 133   memory length: 5000   epsilon: 0.8593484802881957  loss: 52173.4041584273\n",
      "episode: 138   score: 596  move: 83   memory length: 5000   epsilon: 0.8586355134069056  loss: 84314.7948459947\n",
      "episode: 139   score: 1168  move: 115   memory length: 5000   epsilon: 0.8576486451901293  loss: 61588.05383741959\n",
      "episode: 140   score: 1000  move: 121   memory length: 5000   epsilon: 0.8566115127354574  loss: 59271.40716366728\n",
      "episode: 141   score: 1632  move: 166   memory length: 5000   epsilon: 0.8551907101127403  loss: 43923.27754700902\n",
      "episode: 142   score: 564  move: 76   memory length: 5000   epsilon: 0.8545410088423009  loss: 96651.8183768925\n",
      "episode: 143   score: 952  move: 105   memory length: 5000   epsilon: 0.8536442072022602  loss: 70684.53938907442\n",
      "episode: 144   score: 704  move: 94   memory length: 5000   epsilon: 0.8528421546609772  loss: 79679.73076211645\n",
      "episode: 145   score: 1416  move: 144   memory length: 5000   epsilon: 0.8516149396290723  loss: 52715.50332146221\n",
      "episode: 146   score: 1904  move: 175   memory length: 5000   epsilon: 0.8501259093210992  loss: 44090.61574037824\n",
      "episode: 147   score: 736  move: 98   memory length: 5000   epsilon: 0.8492931898655434  loss: 79445.06035680187\n",
      "episode: 148   score: 1296  move: 135   memory length: 5000   epsilon: 0.8481474119044702  loss: 58378.40748915495\n",
      "episode: 149   score: 1672  move: 167   memory length: 5000   epsilon: 0.8467321806973984  loss: 47892.380551024115\n",
      "episode: 150   score: 716  move: 96   memory length: 5000   epsilon: 0.8459197037928536  loss: 84014.34909586112\n",
      "episode: 151   score: 1012  move: 109   memory length: 5000   epsilon: 0.8449981490465214  loss: 74726.817779716\n",
      "episode: 152   score: 1012  move: 108   memory length: 5000   epsilon: 0.8440860391130197  loss: 76108.39490102838\n",
      "episode: 153   score: 676  move: 91   memory length: 5000   epsilon: 0.843318266368142  loss: 91025.52769776229\n",
      "episode: 154   score: 404  move: 65   memory length: 5000   epsilon: 0.8427702848683745  loss: 128143.55360089816\n",
      "episode: 155   score: 756  move: 99   memory length: 5000   epsilon: 0.8419363509820676  loss: 84823.07071127073\n",
      "episode: 156   score: 720  move: 95   memory length: 5000   epsilon: 0.8411368872567094  loss: 89089.16031289351\n",
      "episode: 157   score: 336  move: 56   memory length: 5000   epsilon: 0.8406659801116156  loss: 151834.67680556435\n",
      "episode: 158   score: 1976  move: 161   memory length: 5000   epsilon: 0.8393135900877786  loss: 53528.633101682484\n",
      "episode: 159   score: 832  move: 98   memory length: 5000   epsilon: 0.8384914615676198  loss: 88675.87222745467\n",
      "episode: 160   score: 1172  move: 126   memory length: 5000   epsilon: 0.8374356223652297  loss: 69668.68764208234\n",
      "episode: 161   score: 292  move: 56   memory length: 5000   epsilon: 0.8369667873585824  loss: 157464.28557838712\n",
      "episode: 162   score: 552  move: 77   memory length: 5000   epsilon: 0.8363225677675883  loss: 115245.65454007433\n",
      "episode: 163   score: 1180  move: 128   memory length: 5000   epsilon: 0.8352527543584227  loss: 70019.87962427735\n",
      "episode: 164   score: 396  move: 66   memory length: 5000   epsilon: 0.8347016666640497  loss: 136472.80768267313\n",
      "episode: 165   score: 1352  move: 140   memory length: 5000   epsilon: 0.8335338961219788  loss: 65058.624471310206\n",
      "episode: 166   score: 1404  move: 145   memory length: 5000   epsilon: 0.8323261417673423  loss: 63514.257626790015\n",
      "episode: 167   score: 504  move: 73   memory length: 5000   epsilon: 0.8317187623674065  loss: 126845.32705380165\n",
      "episode: 168   score: 608  move: 85   memory length: 5000   epsilon: 0.8310120982608633  loss: 109634.14697539386\n",
      "episode: 169   score: 1004  move: 106   memory length: 5000   epsilon: 0.8301316877346661  loss: 88593.18425667961\n",
      "episode: 170   score: 748  move: 101   memory length: 5000   epsilon: 0.8292936738082524  loss: 93681.36000427397\n",
      "episode: 171   score: 1296  move: 134   memory length: 5000   epsilon: 0.8281831589439013  loss: 71285.00071320606\n",
      "episode: 172   score: 584  move: 80   memory length: 5000   epsilon: 0.8275208740545967  loss: 120090.75013337136\n",
      "episode: 173   score: 1088  move: 117   memory length: 5000   epsilon: 0.8265532359724207  loss: 82831.92269548595\n",
      "episode: 174   score: 1032  move: 108   memory length: 5000   epsilon: 0.825661035891333  loss: 90438.76398796505\n",
      "episode: 175   score: 1028  move: 112   memory length: 5000   epsilon: 0.8247368085739057  loss: 87884.99693342617\n",
      "episode: 176   score: 2192  move: 209   memory length: 5000   epsilon: 0.8230149000556316  loss: 47782.22591909381\n",
      "episode: 177   score: 768  move: 94   memory length: 5000   epsilon: 0.8222416256791008  loss: 106927.9300707959\n",
      "episode: 178   score: 1020  move: 111   memory length: 5000   epsilon: 0.8213294392707775  loss: 91249.36246569522\n",
      "episode: 179   score: 1292  move: 130   memory length: 5000   epsilon: 0.82026239939072  loss: 78594.99807918255\n",
      "episode: 180   score: 1336  move: 139   memory length: 5000   epsilon: 0.8191230210100955  loss: 74187.5801950633\n",
      "episode: 181   score: 1032  move: 123   memory length: 5000   epsilon: 0.8181161140344511  loss: 84506.39731098578\n",
      "episode: 182   score: 724  move: 95   memory length: 5000   epsilon: 0.8173392689017532  loss: 110087.58804726851\n",
      "episode: 183   score: 524  move: 77   memory length: 5000   epsilon: 0.8167101567583941  loss: 136487.88724294884\n",
      "episode: 184   score: 2348  move: 190   memory length: 5000   epsilon: 0.8151598729451299  loss: 55982.33542554755\n",
      "episode: 185   score: 1348  move: 139   memory length: 5000   epsilon: 0.814027582184666  loss: 77183.70010543385\n",
      "episode: 186   score: 1336  move: 139   memory length: 5000   epsilon: 0.8128968642228745  loss: 77860.68883259177\n",
      "episode: 187   score: 1744  move: 166   memory length: 5000   epsilon: 0.8115485680821907  loss: 65829.74845180742\n",
      "episode: 188   score: 888  move: 107   memory length: 5000   epsilon: 0.8106806711825015  loss: 102773.71295012714\n",
      "episode: 189   score: 540  move: 75   memory length: 5000   epsilon: 0.8100728855882722  loss: 147272.22016464232\n",
      "episode: 190   score: 396  move: 69   memory length: 5000   epsilon: 0.8095141252978822  loss: 160730.22422176859\n",
      "episode: 191   score: 248  move: 51   memory length: 5000   epsilon: 0.8091013762901768  loss: 218127.36910449757\n",
      "episode: 192   score: 1416  move: 145   memory length: 5000   epsilon: 0.8079290235939  loss: 77375.10682407247\n",
      "episode: 193   score: 276  move: 52   memory length: 5000   epsilon: 0.8075090076151685  loss: 216439.37364350833\n",
      "episode: 194   score: 1000  move: 109   memory length: 5000   epsilon: 0.8066292979271951  loss: 103904.19194090257\n",
      "episode: 195   score: 2952  move: 243   memory length: 5000   epsilon: 0.8046715585612171  loss: 47262.62249839061\n",
      "episode: 196   score: 1412  move: 146   memory length: 5000   epsilon: 0.8034975894218765  loss: 79327.72531914385\n",
      "episode: 197   score: 1056  move: 119   memory length: 5000   epsilon: 0.802541991206177  loss: 97971.8679749625\n",
      "episode: 198   score: 1472  move: 157   memory length: 5000   epsilon: 0.8012829825653313  loss: 74898.855013246\n",
      "episode: 199   score: 628  move: 87   memory length: 5000   epsilon: 0.8005861660455521  loss: 135794.56710311188\n",
      "episode: 200   score: 2104  move: 192   memory length: 5000   epsilon: 0.7990505076322806  loss: 62164.999181846775\n",
      "episode: 201   score: 2308  move: 195   memory length: 5000   epsilon: 0.7974938695745702  loss: 61828.99435168535\n",
      "episode: 202   score: 1412  move: 143   memory length: 5000   epsilon: 0.7963542626561854  loss: 84935.53496559517\n",
      "episode: 203   score: 1216  move: 126   memory length: 5000   epsilon: 0.7953514831550913  loss: 97008.15659238421\n",
      "episode: 204   score: 576  move: 77   memory length: 5000   epsilon: 0.7947392951747396  loss: 159369.37453931337\n",
      "episode: 205   score: 2044  move: 173   memory length: 5000   epsilon: 0.7933655779335276  loss: 71551.09856059785\n",
      "episode: 206   score: 1716  move: 160   memory length: 5000   epsilon: 0.7920972016385727  loss: 77993.42861435414\n",
      "episode: 207   score: 2104  move: 177   memory length: 5000   epsilon: 0.7906964226428937  loss: 71117.5291690503\n",
      "episode: 208   score: 968  move: 116   memory length: 5000   epsilon: 0.7897797419867935  loss: 109133.51840042246\n",
      "episode: 209   score: 600  move: 83   memory length: 5000   epsilon: 0.7891244934904423  loss: 153138.0348597607\n",
      "episode: 210   score: 688  move: 95   memory length: 5000   epsilon: 0.7883751774565142  loss: 134414.9354278966\n",
      "episode: 211   score: 680  move: 89   memory length: 5000   epsilon: 0.7876738321867887  loss: 144117.55790783314\n",
      "episode: 212   score: 664  move: 88   memory length: 5000   epsilon: 0.7869809806495924  loss: 146389.49216864325\n",
      "episode: 213   score: 1304  move: 134   memory length: 5000   epsilon: 0.7859271271058174  loss: 96771.3051406234\n",
      "episode: 214   score: 1052  move: 114   memory length: 5000   epsilon: 0.785031676207649  loss: 114377.59981593752\n",
      "episode: 215   score: 1052  move: 117   memory length: 5000   epsilon: 0.7841137216648335  loss: 112076.24474044539\n",
      "episode: 216   score: 372  move: 58   memory length: 5000   epsilon: 0.7836590652960769  loss: 226737.9696311293\n",
      "episode: 217   score: 588  move: 81   memory length: 5000   epsilon: 0.7830245552918785  loss: 162996.34742590823\n",
      "episode: 218   score: 884  move: 108   memory length: 5000   epsilon: 0.7821793410439375  loss: 122871.38174964764\n",
      "episode: 219   score: 1068  move: 117   memory length: 5000   epsilon: 0.7812647217984107  loss: 114066.21269855337\n",
      "episode: 220   score: 1380  move: 139   memory length: 5000   epsilon: 0.780179512804042  loss: 96658.81659673787\n",
      "episode: 221   score: 288  move: 55   memory length: 5000   epsilon: 0.7797505299081938  loss: 244913.09772872925\n",
      "episode: 222   score: 1044  move: 126   memory length: 5000   epsilon: 0.7787686580403261  loss: 107559.44832856314\n",
      "episode: 223   score: 1440  move: 145   memory length: 5000   epsilon: 0.7776402561332428  loss: 94111.73065935333\n",
      "episode: 224   score: 2636  move: 224   memory length: 5000   epsilon: 0.7759002827573566  loss: 61582.83699112279\n",
      "episode: 225   score: 1256  move: 142   memory length: 5000   epsilon: 0.7747992807472597  loss: 97796.73230101357\n",
      "episode: 226   score: 720  move: 93   memory length: 5000   epsilon: 0.7740790487747803  loss: 149980.89868086128\n",
      "episode: 227   score: 1276  move: 129   memory length: 5000   epsilon: 0.7730811256110696  loss: 108790.25712966919\n",
      "episode: 228   score: 496  move: 75   memory length: 5000   epsilon: 0.7725015292446833  loss: 187810.09714950563\n",
      "episode: 229   score: 752  move: 101   memory length: 5000   epsilon: 0.7717216926847158  loss: 140154.3876000206\n",
      "episode: 230   score: 516  move: 79   memory length: 5000   epsilon: 0.7711122702539358  loss: 179858.61435501484\n",
      "episode: 231   score: 632  move: 88   memory length: 5000   epsilon: 0.7704339865532914  loss: 162137.82103265414\n",
      "episode: 232   score: 916  move: 111   memory length: 5000   epsilon: 0.769579275007322  loss: 129222.03601751242\n",
      "episode: 233   score: 480  move: 71   memory length: 5000   epsilon: 0.7690330649185415  loss: 202699.3952875809\n",
      "episode: 234   score: 1084  move: 115   memory length: 5000   epsilon: 0.7681491808052384  loss: 125836.39676132202\n",
      "episode: 235   score: 592  move: 80   memory length: 5000   epsilon: 0.7675349041326391  loss: 181578.4512983799\n",
      "episode: 236   score: 1364  move: 136   memory length: 5000   epsilon: 0.7664917609454496  loss: 107512.47669099359\n",
      "episode: 237   score: 856  move: 104   memory length: 5000   epsilon: 0.7656950199075112  loss: 141276.59785538452\n",
      "episode: 238   score: 1288  move: 132   memory length: 5000   epsilon: 0.7646849642143692  loss: 111987.33654013547\n",
      "episode: 239   score: 632  move: 87   memory length: 5000   epsilon: 0.7640199742831154  loss: 170596.20890426636\n",
      "episode: 240   score: 468  move: 72   memory length: 5000   epsilon: 0.7634700751395811  loss: 206826.3863922225\n",
      "episode: 241   score: 696  move: 92   memory length: 5000   epsilon: 0.7627680021631741  loss: 162558.04840274478\n",
      "episode: 242   score: 684  move: 92   memory length: 5000   epsilon: 0.7620665748001058  loss: 163263.57717684042\n",
      "episode: 243   score: 1172  move: 119   memory length: 5000   epsilon: 0.7611602504144318  loss: 126927.78352256582\n",
      "episode: 244   score: 1152  move: 126   memory length: 5000   epsilon: 0.7602017876649297  loss: 120571.05124909537\n",
      "episode: 245   score: 260  move: 50   memory length: 5000   epsilon: 0.7598217798809199  loss: 304572.20513526915\n",
      "episode: 246   score: 1096  move: 120   memory length: 5000   epsilon: 0.7589105360444917  loss: 127617.29852794012\n",
      "episode: 247   score: 908  move: 109   memory length: 5000   epsilon: 0.75808377009567  loss: 141181.6954879411\n",
      "episode: 248   score: 728  move: 95   memory length: 5000   epsilon: 0.7573639288935788  loss: 162698.7579196729\n",
      "episode: 249   score: 1316  move: 135   memory length: 5000   epsilon: 0.7563421723216524  loss: 115214.23423882943\n",
      "episode: 250   score: 1344  move: 135   memory length: 5000   epsilon: 0.7553217941973285  loss: 115912.78425646182\n",
      "episode: 251   score: 1792  move: 170   memory length: 5000   epsilon: 0.754038831559599  loss: 92749.37718552983\n",
      "episode: 252   score: 1016  move: 108   memory length: 5000   epsilon: 0.7532249051512542  loss: 146688.8445555016\n",
      "episode: 253   score: 668  move: 90   memory length: 5000   epsilon: 0.752547304314726  loss: 176701.79854181077\n",
      "episode: 254   score: 564  move: 75   memory length: 5000   epsilon: 0.7519831026175628  loss: 212735.22855860394\n",
      "episode: 255   score: 1280  move: 137   memory length: 5000   epsilon: 0.750953585999299  loss: 117147.72375301723\n",
      "episode: 256   score: 1676  move: 157   memory length: 5000   epsilon: 0.7497755080120937  loss: 102914.15408240154\n",
      "episode: 257   score: 1160  move: 118   memory length: 5000   epsilon: 0.748891290282607  loss: 137601.1709663585\n",
      "episode: 258   score: 1784  move: 169   memory length: 5000   epsilon: 0.7476267265365498  loss: 96749.88256016567\n",
      "episode: 259   score: 1128  move: 120   memory length: 5000   epsilon: 0.7467301080602906  loss: 136945.28468135197\n",
      "episode: 260   score: 1228  move: 126   memory length: 5000   epsilon: 0.745789815931113  loss: 131120.5986671145\n",
      "episode: 261   score: 1956  move: 184   memory length: 5000   epsilon: 0.7444188175201473  loss: 90476.11821160109\n",
      "episode: 262   score: 740  move: 98   memory length: 5000   epsilon: 0.7436896407880486  loss: 170569.2377212291\n",
      "episode: 263   score: 684  move: 90   memory length: 5000   epsilon: 0.7430206178716945  loss: 186404.48621474372\n",
      "episode: 264   score: 884  move: 108   memory length: 5000   epsilon: 0.7422185847700574  loss: 156031.90563728192\n",
      "episode: 265   score: 1260  move: 127   memory length: 5000   epsilon: 0.741276560769133  loss: 133377.92580663125\n",
      "episode: 266   score: 1148  move: 124   memory length: 5000   epsilon: 0.7403579429014704  loss: 137304.6434901145\n",
      "episode: 267   score: 572  move: 78   memory length: 5000   epsilon: 0.7397806859791873  loss: 218977.7960563562\n",
      "episode: 268   score: 1368  move: 142   memory length: 5000   epsilon: 0.7387309376540553  loss: 120967.25259778198\n",
      "episode: 269   score: 1176  move: 132   memory length: 5000   epsilon: 0.7377564512464405  loss: 130811.02169005077\n",
      "episode: 270   score: 964  move: 115   memory length: 5000   epsilon: 0.7369085147447598  loss: 150827.0259780552\n",
      "episode: 271   score: 2044  move: 169   memory length: 5000   epsilon: 0.735664184888079  loss: 103313.0159586393\n",
      "episode: 272   score: 2272  move: 189   memory length: 5000   epsilon: 0.7342750857453316  loss: 93056.62279443892\n",
      "Weights save... Top reward = 280\n",
      "episode: 273   score: 780  move: 97   memory length: 5000   epsilon: 0.7335631806824057  loss: 182007.71681531926\n",
      "episode: 274   score: 548  move: 79   memory length: 5000   epsilon: 0.732983891722487  loss: 224175.4032085274\n",
      "episode: 275   score: 1260  move: 132   memory length: 5000   epsilon: 0.7320169864487595  loss: 134865.86627905298\n",
      "episode: 276   score: 676  move: 88   memory length: 5000   epsilon: 0.7313730916364788  loss: 203006.39993307806\n",
      "episode: 277   score: 812  move: 106   memory length: 5000   epsilon: 0.7305982430274133  loss: 169239.1325501136\n",
      "episode: 278   score: 1180  move: 127   memory length: 5000   epsilon: 0.729670967566939  loss: 141952.41740396456\n",
      "episode: 279   score: 528  move: 73   memory length: 5000   epsilon: 0.7291384994727733  loss: 247650.1042905311\n",
      "episode: 280   score: 904  move: 111   memory length: 5000   epsilon: 0.7283296007157262  loss: 163575.9059826619\n",
      "episode: 281   score: 752  move: 91   memory length: 5000   epsilon: 0.7276671189415881  loss: 200221.72730016185\n",
      "episode: 282   score: 1184  move: 122   memory length: 5000   epsilon: 0.7267799019328111  loss: 150030.96430484584\n",
      "episode: 283   score: 1608  move: 160   memory length: 5000   epsilon: 0.7256179780670653  loss: 115080.3007544756\n",
      "episode: 284   score: 1488  move: 146   memory length: 5000   epsilon: 0.7245593435171811  loss: 126794.59468175287\n",
      "episode: 285   score: 1116  move: 121   memory length: 5000   epsilon: 0.7236831525330153  loss: 153680.13335112896\n",
      "episode: 286   score: 888  move: 94   memory length: 5000   epsilon: 0.7230032065945606  loss: 198511.02512461075\n",
      "episode: 287   score: 480  move: 72   memory length: 5000   epsilon: 0.7224828290423215  loss: 259854.49579901167\n",
      "episode: 288   score: 1428  move: 147   memory length: 5000   epsilon: 0.7214215542053656  loss: 127945.59022628369\n",
      "episode: 289   score: 724  move: 95   memory length: 5000   epsilon: 0.720736525743765  loss: 198668.4091297752\n",
      "episode: 290   score: 1960  move: 164   memory length: 5000   epsilon: 0.7195554806579981  loss: 115754.59759495898\n",
      "Weights save... Top reward = 284\n",
      "episode: 291   score: 612  move: 82   memory length: 5000   epsilon: 0.7189656840645251  loss: 232177.46579002752\n",
      "episode: 292   score: 1044  move: 114   memory length: 5000   epsilon: 0.7181465260976553  loss: 167697.5297933545\n",
      "episode: 293   score: 1220  move: 134   memory length: 5000   epsilon: 0.7171848494115768  loss: 143331.88222506508\n",
      "episode: 294   score: 1464  move: 142   memory length: 5000   epsilon: 0.716167164564232  loss: 135906.8309082515\n",
      "episode: 295   score: 1484  move: 149   memory length: 5000   epsilon: 0.7151008647481667  loss: 130181.29707318505\n",
      "episode: 296   score: 952  move: 112   memory length: 5000   epsilon: 0.7143003961234083  loss: 173843.54490487915\n",
      "episode: 297   score: 888  move: 108   memory length: 5000   epsilon: 0.7135293642725771  loss: 180946.1164108912\n",
      "episode: 298   score: 520  move: 70   memory length: 5000   epsilon: 0.7130300659958776  loss: 279825.76019096375\n",
      "episode: 299   score: 600  move: 80   memory length: 5000   epsilon: 0.7124598672020128  loss: 245512.63730111122\n",
      "episode: 300   score: 1352  move: 140   memory length: 5000   epsilon: 0.7114631162926115  loss: 140960.78515028273\n",
      "episode: 301   score: 716  move: 94   memory length: 5000   epsilon: 0.7107946518484818  loss: 210598.32323070284\n",
      "episode: 302   score: 672  move: 92   memory length: 5000   epsilon: 0.7101410182181834  loss: 215817.42545903247\n",
      "episode: 303   score: 1444  move: 149   memory length: 5000   epsilon: 0.7090836907189995  loss: 133893.94131031932\n",
      "episode: 304   score: 1340  move: 140   memory length: 5000   epsilon: 0.7080916631731663  loss: 143138.1029729843\n",
      "episode: 305   score: 580  move: 80   memory length: 5000   epsilon: 0.7075254135414301  loss: 251117.01695809365\n",
      "episode: 306   score: 2320  move: 193   memory length: 5000   epsilon: 0.7061611995621759  loss: 104709.33460288962\n",
      "Weights save... Top reward = 324\n",
      "episode: 307   score: 1264  move: 127   memory length: 5000   epsilon: 0.7052649396029684  loss: 159769.31210918876\n",
      "episode: 308   score: 532  move: 75   memory length: 5000   epsilon: 0.7047361865616749  loss: 271177.65814641316\n",
      "episode: 309   score: 1268  move: 129   memory length: 5000   epsilon: 0.7038276584649801  loss: 158307.8525820296\n",
      "episode: 310   score: 636  move: 89   memory length: 5000   epsilon: 0.7032015273879479  loss: 230085.92161358608\n",
      "episode: 311   score: 920  move: 108   memory length: 5000   epsilon: 0.7024424759046901  loss: 190227.76818271918\n",
      "episode: 312   score: 1212  move: 136   memory length: 5000   epsilon: 0.701487798691723  loss: 151699.5668569733\n",
      "episode: 313   score: 1504  move: 154   memory length: 5000   epsilon: 0.7004083334859551  loss: 134597.62426671115\n",
      "episode: 314   score: 712  move: 96   memory length: 5000   epsilon: 0.699736260771961  loss: 216530.57740485668\n",
      "episode: 315   score: 1296  move: 134   memory length: 5000   epsilon: 0.698799237443247  loss: 155739.90526355914\n",
      "episode: 316   score: 1032  move: 109   memory length: 5000   epsilon: 0.6980379574410054  loss: 192060.92653792494\n",
      "episode: 317   score: 712  move: 93   memory length: 5000   epsilon: 0.697389080670665  loss: 225695.4968716611\n",
      "episode: 318   score: 2272  move: 187   memory length: 5000   epsilon: 0.6960861751715992  loss: 112837.61056006528\n",
      "episode: 319   score: 1328  move: 138   memory length: 5000   epsilon: 0.6951262339619315  loss: 153506.80389396005\n",
      "episode: 320   score: 944  move: 96   memory length: 5000   epsilon: 0.6944592296555974  loss: 221255.89909287295\n",
      "episode: 321   score: 2780  move: 226   memory length: 5000   epsilon: 0.6928915161415475  loss: 94598.67074215307\n",
      "episode: 322   score: 976  move: 105   memory length: 5000   epsilon: 0.6921643582385134  loss: 204234.67397159396\n",
      "episode: 323   score: 1668  move: 166   memory length: 5000   epsilon: 0.6910163128049462  loss: 129816.99582122895\n",
      "episode: 324   score: 1412  move: 143   memory length: 5000   epsilon: 0.6900288607368705  loss: 151332.94990008694\n",
      "episode: 325   score: 652  move: 86   memory length: 5000   epsilon: 0.6894356880515848  loss: 252281.02803948868\n",
      "episode: 326   score: 1356  move: 138   memory length: 5000   epsilon: 0.6884849182302856  loss: 157860.6174235966\n",
      "episode: 327   score: 1152  move: 125   memory length: 5000   epsilon: 0.6876248454396138  loss: 174920.60837075807\n",
      "episode: 328   score: 652  move: 89   memory length: 5000   epsilon: 0.6870131285229919  loss: 246314.92992739732\n",
      "episode: 329   score: 1488  move: 153   memory length: 5000   epsilon: 0.6859627968932805  loss: 143911.38468177646\n",
      "episode: 330   score: 2392  move: 200   memory length: 5000   epsilon: 0.6845922354649663  loss: 110730.06860437393\n",
      "episode: 331   score: 1344  move: 143   memory length: 5000   epsilon: 0.6836139633081851  loss: 155508.54467978844\n",
      "episode: 332   score: 1320  move: 134   memory length: 5000   epsilon: 0.6826985294978125  loss: 166579.56479920913\n",
      "episode: 333   score: 1296  move: 132   memory length: 5000   epsilon: 0.6817979574443311  loss: 169717.51755006384\n",
      "episode: 334   score: 928  move: 112   memory length: 5000   epsilon: 0.6810347673822547  loss: 200647.02342513629\n",
      "episode: 335   score: 1424  move: 148   memory length: 5000   epsilon: 0.6800275763957476  loss: 152448.1334753552\n",
      "episode: 336   score: 1248  move: 130   memory length: 5000   epsilon: 0.6791441105063507  loss: 174178.95646212652\n",
      "episode: 337   score: 452  move: 74   memory length: 5000   epsilon: 0.6786417272573855  loss: 306606.814084285\n",
      "episode: 338   score: 1152  move: 128   memory length: 5000   epsilon: 0.6777736172148954  loss: 177882.17112269998\n",
      "episode: 339   score: 708  move: 95   memory length: 5000   epsilon: 0.6771300348106716  loss: 240302.45731767354\n",
      "episode: 340   score: 1632  move: 160   memory length: 5000   epsilon: 0.6760474876109388  loss: 143313.9336858034\n",
      "episode: 341   score: 424  move: 69   memory length: 5000   epsilon: 0.6755811734098146  loss: 332952.4128699372\n",
      "episode: 342   score: 804  move: 102   memory length: 5000   epsilon: 0.6748924284888338  loss: 225860.21796899685\n",
      "episode: 343   score: 572  move: 80   memory length: 5000   epsilon: 0.6743527277566139  loss: 288602.2018843174\n",
      "episode: 344   score: 844  move: 102   memory length: 5000   epsilon: 0.6736652352176383  loss: 226992.1617613026\n",
      "episode: 345   score: 604  move: 85   memory length: 5000   epsilon: 0.6730928601996705  loss: 273019.0039549435\n",
      "episode: 346   score: 580  move: 80   memory length: 5000   epsilon: 0.6725545985535665  loss: 290734.0724894047\n",
      "episode: 347   score: 804  move: 100   memory length: 5000   epsilon: 0.671882376760817  loss: 233255.4029860306\n",
      "episode: 348   score: 428  move: 72   memory length: 5000   epsilon: 0.6713987931426229  loss: 324587.0293869972\n",
      "episode: 349   score: 1028  move: 111   memory length: 5000   epsilon: 0.6706539502223152  loss: 211192.20287525762\n",
      "episode: 350   score: 3048  move: 249   memory length: 5000   epsilon: 0.6689860908935682  loss: 94793.90148921186\n",
      "episode: 351   score: 656  move: 89   memory length: 5000   epsilon: 0.6683909551716722  loss: 265844.30129546265\n",
      "episode: 352   score: 1072  move: 117   memory length: 5000   epsilon: 0.6676093911504076  loss: 202866.44337284056\n",
      "episode: 353   score: 636  move: 89   memory length: 5000   epsilon: 0.6670154801523236  loss: 267334.70067146386\n",
      "episode: 354   score: 648  move: 91   memory length: 5000   epsilon: 0.6664087691272123  loss: 262111.36665415502\n",
      "episode: 355   score: 1120  move: 121   memory length: 5000   epsilon: 0.6656028981374827  loss: 197797.6832791478\n",
      "episode: 356   score: 696  move: 93   memory length: 5000   epsilon: 0.6649841721007846  loss: 258015.89794647053\n",
      "episode: 357   score: 1536  move: 157   memory length: 5000   epsilon: 0.6639409608696276  loss: 153514.0242310785\n",
      "episode: 358   score: 700  move: 94   memory length: 5000   epsilon: 0.6633171464860299  loss: 257072.4669743396\n",
      "episode: 359   score: 1364  move: 136   memory length: 5000   epsilon: 0.6624156438200575  loss: 178359.72474280527\n",
      "episode: 360   score: 1280  move: 131   memory length: 5000   epsilon: 0.6615484431311149  loss: 185847.9987111856\n",
      "episode: 361   score: 1288  move: 135   memory length: 5000   epsilon: 0.6606559508382691  loss: 181041.71028320878\n",
      "episode: 362   score: 1348  move: 143   memory length: 5000   epsilon: 0.6597118832774128  loss: 171608.27717464953\n",
      "episode: 363   score: 1032  move: 109   memory length: 5000   epsilon: 0.658993185492599  loss: 225793.57525932242\n",
      "episode: 364   score: 620  move: 88   memory length: 5000   epsilon: 0.6584135236796596  loss: 280338.5255788023\n",
      "episode: 365   score: 320  move: 59   memory length: 5000   epsilon: 0.6580251723338425  loss: 418786.26676740486\n",
      "episode: 366   score: 564  move: 76   memory length: 5000   epsilon: 0.6575252606937942  loss: 325775.6807952178\n",
      "episode: 367   score: 556  move: 79   memory length: 5000   epsilon: 0.657006018269395  loss: 314054.7339588117\n",
      "episode: 368   score: 620  move: 84   memory length: 5000   epsilon: 0.6564543621837596  loss: 296051.05868734635\n",
      "episode: 369   score: 380  move: 62   memory length: 5000   epsilon: 0.6560474845899043  loss: 401756.0883905349\n",
      "episode: 370   score: 1160  move: 128   memory length: 5000   epsilon: 0.655208276821139  loss: 195266.70267382264\n",
      "episode: 371   score: 656  move: 87   memory length: 5000   epsilon: 0.6546384906642893  loss: 287972.2742062711\n",
      "episode: 372   score: 956  move: 115   memory length: 5000   epsilon: 0.6538860853539707  loss: 218523.69504145745\n",
      "episode: 373   score: 3088  move: 251   memory length: 5000   epsilon: 0.6522468811455868  loss: 100804.26392472407\n",
      "episode: 374   score: 248  move: 49   memory length: 5000   epsilon: 0.6519273568660444  loss: 517069.0103072342\n",
      "episode: 375   score: 824  move: 107   memory length: 5000   epsilon: 0.6512301641728414  loss: 237497.1027340399\n",
      "episode: 376   score: 964  move: 102   memory length: 5000   epsilon: 0.6505662447422572  loss: 249831.80515382803\n",
      "episode: 377   score: 792  move: 106   memory length: 5000   epsilon: 0.6498770064374739  loss: 241115.29184121906\n",
      "episode: 378   score: 428  move: 69   memory length: 5000   epsilon: 0.6494287437301358  loss: 371140.8508374311\n",
      "episode: 379   score: 600  move: 85   memory length: 5000   epsilon: 0.6488769610798978  loss: 301990.0419665617\n",
      "episode: 380   score: 572  move: 79   memory length: 5000   epsilon: 0.6483645481483364  loss: 325639.89705826965\n",
      "episode: 381   score: 1240  move: 132   memory length: 5000   epsilon: 0.6475092672779343  loss: 195617.05687311923\n",
      "episode: 382   score: 1116  move: 122   memory length: 5000   epsilon: 0.646719783707336  loss: 212377.27762131614\n",
      "episode: 383   score: 1060  move: 114   memory length: 5000   epsilon: 0.6459829395506556  loss: 227991.40437146238\n",
      "episode: 384   score: 1452  move: 152   memory length: 5000   epsilon: 0.645001786442038  loss: 171703.64675072618\n",
      "episode: 385   score: 868  move: 93   memory length: 5000   epsilon: 0.6444022106287339  loss: 281348.622604083\n",
      "episode: 386   score: 1284  move: 133   memory length: 5000   epsilon: 0.6435457210979388  loss: 197466.99014984933\n",
      "episode: 387   score: 1116  move: 121   memory length: 5000   epsilon: 0.642767497804334  loss: 217785.74748939325\n",
      "episode: 388   score: 1616  move: 165   memory length: 5000   epsilon: 0.6417078006250599  loss: 160452.09185266207\n",
      "episode: 389   score: 1288  move: 130   memory length: 5000   epsilon: 0.640874118326737  loss: 204409.52818782514\n",
      "episode: 390   score: 1080  move: 117   memory length: 5000   epsilon: 0.640124730338811  loss: 227875.7165137723\n",
      "episode: 391   score: 1460  move: 153   memory length: 5000   epsilon: 0.6391460834639244  loss: 175036.1361911001\n",
      "episode: 392   score: 692  move: 91   memory length: 5000   epsilon: 0.638564722180666  loss: 295066.90209378256\n",
      "episode: 393   score: 1452  move: 149   memory length: 5000   epsilon: 0.6376139644812098  loss: 180987.18495631378\n",
      "episode: 394   score: 1300  move: 132   memory length: 5000   epsilon: 0.63677286509032  loss: 205102.16473588077\n",
      "episode: 395   score: 680  move: 90   memory length: 5000   epsilon: 0.6362000244644818  loss: 301599.2572576311\n",
      "episode: 396   score: 920  move: 107   memory length: 5000   epsilon: 0.6355196511010983  loss: 254448.61494164154\n",
      "episode: 397   score: 864  move: 102   memory length: 5000   epsilon: 0.6348717483040591  loss: 267679.2530342925\n",
      "episode: 398   score: 556  move: 85   memory length: 5000   epsilon: 0.6343323339045238  loss: 321981.82651856367\n",
      "episode: 399   score: 832  move: 99   memory length: 5000   epsilon: 0.6337046525091055  loss: 277213.0796168549\n",
      "episode: 400   score: 1264  move: 130   memory length: 5000   epsilon: 0.6328813675955565  loss: 211889.8920014895\n",
      "episode: 401   score: 644  move: 84   memory length: 5000   epsilon: 0.6323499678089319  loss: 328697.24883946916\n",
      "episode: 402   score: 1436  move: 149   memory length: 5000   epsilon: 0.6314084632444583  loss: 186080.49979428796\n",
      "episode: 403   score: 696  move: 92   memory length: 5000   epsilon: 0.6308278316865835  loss: 302131.59738478455\n",
      "episode: 404   score: 792  move: 96   memory length: 5000   epsilon: 0.6302225245355466  loss: 290324.8881259362\n",
      "episode: 405   score: 1180  move: 128   memory length: 5000   epsilon: 0.6294163517339372  loss: 218512.23842921853\n",
      "episode: 406   score: 2860  move: 234   memory length: 5000   epsilon: 0.6279452319966439  loss: 120308.71180876707\n",
      "episode: 407   score: 1312  move: 135   memory length: 5000   epsilon: 0.6270980736581947  loss: 209314.94548941718\n",
      "episode: 408   score: 956  move: 116   memory length: 5000   epsilon: 0.6263710580082701  loss: 244369.07953739166\n",
      "episode: 409   score: 1328  move: 135   memory length: 5000   epsilon: 0.625526023381496  loss: 210753.51964441934\n",
      "episode: 410   score: 1288  move: 129   memory length: 5000   epsilon: 0.6247196110270675  loss: 221330.7632230123\n",
      "episode: 411   score: 1320  move: 136   memory length: 5000   epsilon: 0.6238705655926027  loss: 210713.782640934\n",
      "episode: 412   score: 256  move: 48   memory length: 5000   epsilon: 0.62357117808293  loss: 597798.5705481371\n",
      "episode: 413   score: 876  move: 106   memory length: 5000   epsilon: 0.6229105395312573  loss: 271464.93909745844\n",
      "episode: 414   score: 1252  move: 126   memory length: 5000   epsilon: 0.6221261625908066  loss: 229128.67296409607\n",
      "episode: 415   score: 604  move: 92   memory length: 5000   epsilon: 0.6215540668651277  loss: 314591.0488721184\n",
      "episode: 416   score: 1492  move: 148   memory length: 5000   epsilon: 0.6206348426437566  loss: 196343.34179061168\n",
      "episode: 417   score: 984  move: 105   memory length: 5000   epsilon: 0.6199835148092935  loss: 277502.02388033184\n",
      "episode: 418   score: 708  move: 94   memory length: 5000   epsilon: 0.6194010012170837  loss: 310713.94915954105\n",
      "episode: 419   score: 492  move: 67   memory length: 5000   epsilon: 0.6189861394661635  loss: 436655.65615508804\n",
      "episode: 420   score: 1104  move: 118   memory length: 5000   epsilon: 0.6182561629425591  loss: 248692.77343326504\n",
      "episode: 421   score: 620  move: 86   memory length: 5000   epsilon: 0.6177246885517989  loss: 341974.46938434866\n",
      "episode: 422   score: 1352  move: 138   memory length: 5000   epsilon: 0.6168728121521212  loss: 213856.3554275347\n",
      "episode: 423   score: 1340  move: 138   memory length: 5000   epsilon: 0.6160221105369617  loss: 214588.7093695212\n",
      "episode: 424   score: 612  move: 84   memory length: 5000   epsilon: 0.6155048666507353  loss: 353274.17642561597\n",
      "episode: 425   score: 684  move: 95   memory length: 5000   epsilon: 0.6149204117651673  loss: 313141.01109028864\n",
      "episode: 426   score: 644  move: 84   memory length: 5000   epsilon: 0.6144040929219626  loss: 354894.90186841146\n",
      "episode: 427   score: 436  move: 66   memory length: 5000   epsilon: 0.6139987179822032  loss: 452418.8442482804\n",
      "episode: 428   score: 1336  move: 136   memory length: 5000   epsilon: 0.6131642431248943  loss: 220302.6121100538\n",
      "episode: 429   score: 1352  move: 135   memory length: 5000   epsilon: 0.6123370257579432  loss: 222663.65260385585\n",
      "episode: 430   score: 932  move: 115   memory length: 5000   epsilon: 0.6116332394140981  loss: 262120.11320551997\n",
      "episode: 431   score: 920  move: 112   memory length: 5000   epsilon: 0.6109485902378134  loss: 269880.0932460853\n",
      "episode: 432   score: 504  move: 67   memory length: 5000   epsilon: 0.6105393897338262  loss: 451880.6953556004\n",
      "episode: 433   score: 628  move: 86   memory length: 5000   epsilon: 0.6100145489483348  loss: 352780.31161805085\n",
      "episode: 434   score: 1432  move: 148   memory length: 5000   epsilon: 0.6091123906668993  loss: 205723.0312229105\n",
      "episode: 435   score: 1324  move: 136   memory length: 5000   epsilon: 0.608284556731093  loss: 224607.00761113447\n",
      "episode: 436   score: 596  move: 83   memory length: 5000   epsilon: 0.6077798874923646  loss: 368782.71374461165\n",
      "episode: 437   score: 2680  move: 215   memory length: 5000   epsilon: 0.606474557939699  loss: 143120.47996182108\n",
      "episode: 438   score: 512  move: 68   memory length: 5000   epsilon: 0.606062293364817  loss: 453286.0813628365\n",
      "episode: 439   score: 820  move: 96   memory length: 5000   epsilon: 0.6054807498410211  loss: 321840.613432765\n",
      "episode: 440   score: 1104  move: 119   memory length: 5000   epsilon: 0.6047606526910048  loss: 260378.7465627013\n",
      "episode: 441   score: 1416  move: 146   memory length: 5000   epsilon: 0.603878341970074  loss: 212983.25820141623\n",
      "episode: 442   score: 404  move: 67   memory length: 5000   epsilon: 0.6034738769695334  loss: 464867.3117678628\n",
      "episode: 443   score: 716  move: 95   memory length: 5000   epsilon: 0.6029008461539901  loss: 328587.57710334373\n",
      "episode: 444   score: 684  move: 89   memory length: 5000   epsilon: 0.6023645004284335  loss: 351478.41809549223\n",
      "episode: 445   score: 1344  move: 138   memory length: 5000   epsilon: 0.601533806574961  loss: 227417.05687804843\n",
      "episode: 446   score: 1260  move: 133   memory length: 5000   epsilon: 0.600734294408099  loss: 236693.5499610901\n",
      "episode: 447   score: 1444  move: 151   memory length: 5000   epsilon: 0.599827865617362  loss: 209220.04963727028\n",
      "episode: 448   score: 304  move: 56   memory length: 5000   epsilon: 0.5994920543694843  loss: 564875.4213886942\n",
      "episode: 449   score: 652  move: 86   memory length: 5000   epsilon: 0.5989767102557354  loss: 368574.80676398164\n",
      "episode: 450   score: 376  move: 64   memory length: 5000   epsilon: 0.5985934858899266  loss: 496016.6698215604\n",
      "episode: 451   score: 576  move: 80   memory length: 5000   epsilon: 0.5981148002075872  loss: 397544.5422003269\n",
      "episode: 452   score: 652  move: 86   memory length: 5000   epsilon: 0.5976006400291726  loss: 370563.2271230387\n",
      "episode: 453   score: 680  move: 89   memory length: 5000   epsilon: 0.5970690094121082  loss: 358812.0579530952\n",
      "episode: 454   score: 1404  move: 144   memory length: 5000   epsilon: 0.5962098444899355  loss: 222497.8445751667\n",
      "episode: 455   score: 392  move: 65   memory length: 5000   epsilon: 0.5958224320766276  loss: 493675.801967034\n",
      "episode: 456   score: 1396  move: 143   memory length: 5000   epsilon: 0.594971010653056  loss: 225150.99754357504\n",
      "episode: 457   score: 712  move: 95   memory length: 5000   epsilon: 0.594406053765161  loss: 339655.0203984712\n",
      "episode: 458   score: 1100  move: 121   memory length: 5000   epsilon: 0.5936872538077772  loss: 267402.0863144614\n",
      "episode: 459   score: 896  move: 92   memory length: 5000   epsilon: 0.5931413099772227  loss: 352430.3781541327\n",
      "episode: 460   score: 1004  move: 120   memory length: 5000   epsilon: 0.5924299637416193  loss: 270919.54412069323\n",
      "episode: 461   score: 1372  move: 143   memory length: 5000   epsilon: 0.5915833901050114  loss: 228056.06476483645\n",
      "episode: 462   score: 1484  move: 155   memory length: 5000   epsilon: 0.5906671415451774  loss: 211110.02790992492\n",
      "episode: 463   score: 596  move: 82   memory length: 5000   epsilon: 0.5901829905973712  loss: 399764.8940666478\n",
      "episode: 464   score: 592  move: 82   memory length: 5000   epsilon: 0.5896992364925984  loss: 400459.08226706344\n",
      "episode: 465   score: 936  move: 116   memory length: 5000   epsilon: 0.5890155785582378  loss: 283778.8334323291\n",
      "episode: 466   score: 1016  move: 122   memory length: 5000   epsilon: 0.5882974141309493  loss: 270522.4426070979\n",
      "episode: 467   score: 1560  move: 159   memory length: 5000   epsilon: 0.5873627598162953  loss: 208247.05842208862\n",
      "episode: 468   score: 1736  move: 162   memory length: 5000   epsilon: 0.5864119977168121  loss: 205068.61070790704\n",
      "episode: 469   score: 2472  move: 214   memory length: 5000   epsilon: 0.5851584115893312  loss: 155924.37628054395\n",
      "episode: 470   score: 1108  move: 119   memory length: 5000   epsilon: 0.5844624837590826  loss: 281103.6830268988\n",
      "episode: 471   score: 1092  move: 114   memory length: 5000   epsilon: 0.5837965728393829  loss: 294131.0741592206\n",
      "episode: 472   score: 1300  move: 131   memory length: 5000   epsilon: 0.5830322962180621  loss: 256640.21980358445\n",
      "episode: 473   score: 1064  move: 115   memory length: 5000   epsilon: 0.5823621911111706  loss: 293022.7449599888\n",
      "episode: 474   score: 828  move: 108   memory length: 5000   epsilon: 0.5817335763147863  loss: 312684.2898713924\n",
      "episode: 475   score: 708  move: 95   memory length: 5000   epsilon: 0.5811811890808292  loss: 356139.90086143895\n",
      "episode: 476   score: 936  move: 115   memory length: 5000   epsilon: 0.5805132115342021  loss: 294884.42815090675\n",
      "episode: 477   score: 1272  move: 128   memory length: 5000   epsilon: 0.5797706262664682  loss: 265593.9043804705\n",
      "episode: 478   score: 1860  move: 179   memory length: 5000   epsilon: 0.5787337599333374  loss: 190572.60650116904\n",
      "episode: 479   score: 1380  move: 137   memory length: 5000   epsilon: 0.5779414335880682  loss: 249648.39976682453\n",
      "episode: 480   score: 1280  move: 134   memory length: 5000   epsilon: 0.5771675068441479  loss: 255884.44287579096\n",
      "episode: 481   score: 1408  move: 145   memory length: 5000   epsilon: 0.5763312162349848  loss: 237121.72866645025\n",
      "episode: 482   score: 956  move: 119   memory length: 5000   epsilon: 0.5756457865720506  loss: 289550.9198363809\n",
      "episode: 483   score: 916  move: 96   memory length: 5000   epsilon: 0.5750934290291939  loss: 359545.56029816467\n",
      "episode: 484   score: 1796  move: 171   memory length: 5000   epsilon: 0.5741108546931668  loss: 202473.78854381273\n",
      "episode: 485   score: 2580  move: 215   memory length: 5000   epsilon: 0.572877836160374  loss: 161650.36052198187\n",
      "episode: 486   score: 2080  move: 176   memory length: 5000   epsilon: 0.5718704528891313  loss: 198077.84960705583\n",
      "episode: 487   score: 1432  move: 147   memory length: 5000   epsilon: 0.5710304167010684  loss: 237770.67404021698\n",
      "episode: 488   score: 720  move: 95   memory length: 5000   epsilon: 0.5704881926912649  loss: 368530.1081814816\n",
      "episode: 489   score: 2228  move: 187   memory length: 5000   epsilon: 0.5694223712954175  loss: 187838.57074604952\n",
      "episode: 490   score: 308  move: 59   memory length: 5000   epsilon: 0.5690865095060138  loss: 595961.7278812861\n",
      "episode: 491   score: 1024  move: 122   memory length: 5000   epsilon: 0.5683926438392044  loss: 288827.2679407401\n",
      "episode: 492   score: 632  move: 88   memory length: 5000   epsilon: 0.5678926758309725  loss: 401032.2321789915\n",
      "episode: 493   score: 1520  move: 164   memory length: 5000   epsilon: 0.5669620904782444  loss: 215793.77009836058\n",
      "episode: 494   score: 1056  move: 115   memory length: 5000   epsilon: 0.5663104555779008  loss: 308351.7258344899\n",
      "episode: 495   score: 676  move: 88   memory length: 5000   epsilon: 0.5658123190985058  loss: 403555.3918452263\n",
      "episode: 496   score: 1016  move: 109   memory length: 5000   epsilon: 0.5651959165890701  loss: 326422.6908330305\n",
      "episode: 497   score: 752  move: 102   memory length: 5000   epsilon: 0.5646197077895483  loss: 349442.48224464117\n",
      "episode: 498   score: 804  move: 107   memory length: 5000   epsilon: 0.5640158847860122  loss: 333731.91788593185\n",
      "episode: 499   score: 524  move: 77   memory length: 5000   epsilon: 0.5635817575445264  loss: 464377.7265992103\n",
      "episode: 500   score: 692  move: 92   memory length: 5000   epsilon: 0.5630634981721528  loss: 389257.87153281335\n",
      "episode: 501   score: 1032  move: 109   memory length: 5000   epsilon: 0.562450090260149  loss: 329147.64262505627\n",
      "episode: 502   score: 1324  move: 136   memory length: 5000   epsilon: 0.5616856742360312  loss: 264412.0493813963\n",
      "episode: 503   score: 580  move: 79   memory length: 5000   epsilon: 0.5612421155643339  loss: 455825.85190500185\n",
      "episode: 504   score: 388  move: 64   memory length: 5000   epsilon: 0.5608830337334052  loss: 563287.789440453\n",
      "episode: 505   score: 1540  move: 158   memory length: 5000   epsilon: 0.5599975338417326  loss: 228789.88544466527\n",
      "episode: 506   score: 1216  move: 126   memory length: 5000   epsilon: 0.5592923777649305  loss: 287514.6423561762\n",
      "episode: 507   score: 1068  move: 110   memory length: 5000   epsilon: 0.5586774913244983  loss: 329964.27591486846\n",
      "episode: 508   score: 808  move: 98   memory length: 5000   epsilon: 0.5581302528374621  loss: 371009.4314863633\n",
      "episode: 509   score: 1448  move: 151   memory length: 5000   epsilon: 0.5572881079243742  loss: 241417.3886196566\n",
      "episode: 510   score: 1396  move: 143   memory length: 5000   epsilon: 0.5564917514788216  loss: 255564.87424466325\n",
      "episode: 511   score: 932  move: 100   memory length: 5000   epsilon: 0.5559355351007994  loss: 366105.18449298857\n",
      "episode: 512   score: 548  move: 76   memory length: 5000   epsilon: 0.555513182496677  loss: 482351.3925992564\n",
      "episode: 513   score: 584  move: 80   memory length: 5000   epsilon: 0.5550689474472156  loss: 458869.4766405582\n",
      "episode: 514   score: 552  move: 75   memory length: 5000   epsilon: 0.5546527997307904  loss: 490110.51716130576\n",
      "episode: 515   score: 3120  move: 261   memory length: 5000   epsilon: 0.5532070362367576  loss: 141519.45750767793\n",
      "episode: 516   score: 1020  move: 110   memory length: 5000   epsilon: 0.5525988400251567  loss: 336485.91190452577\n",
      "episode: 517   score: 456  move: 74   memory length: 5000   epsilon: 0.5521900661046714  loss: 500900.38745514123\n",
      "episode: 518   score: 1200  move: 129   memory length: 5000   epsilon: 0.5514781966145864  loss: 288049.89377910405\n",
      "episode: 519   score: 1008  move: 110   memory length: 5000   epsilon: 0.550871901090504  loss: 338523.8844040264\n",
      "episode: 520   score: 1188  move: 130   memory length: 5000   epsilon: 0.5501562293281613  loss: 287161.40622667165\n",
      "episode: 521   score: 528  move: 79   memory length: 5000   epsilon: 0.5497217753666305  loss: 473268.3155334569\n",
      "episode: 522   score: 548  move: 75   memory length: 5000   epsilon: 0.5493096365457868  loss: 499225.6731521098\n",
      "episode: 523   score: 968  move: 118   memory length: 5000   epsilon: 0.5486618302165305  loss: 318030.50575194927\n",
      "episode: 524   score: 1144  move: 125   memory length: 5000   epsilon: 0.5479764279673975  loss: 300934.6015021057\n",
      "episode: 525   score: 1392  move: 145   memory length: 5000   epsilon: 0.547182433961641  loss: 260151.35225969512\n",
      "episode: 526   score: 1032  move: 110   memory length: 5000   epsilon: 0.546580861202094  loss: 343662.9082576752\n",
      "episode: 527   score: 728  move: 96   memory length: 5000   epsilon: 0.546056392738138  loss: 394524.7192728122\n",
      "episode: 528   score: 1048  move: 113   memory length: 5000   epsilon: 0.5454396944310157  loss: 335912.951616034\n",
      "episode: 529   score: 1196  move: 131   memory length: 5000   epsilon: 0.5447256326735682  loss: 290499.8418426805\n",
      "episode: 530   score: 620  move: 85   memory length: 5000   epsilon: 0.544262810299057  loss: 448454.35443855735\n",
      "episode: 531   score: 832  move: 102   memory length: 5000   epsilon: 0.5437079424889012  loss: 374449.74644578673\n",
      "episode: 532   score: 812  move: 96   memory length: 5000   epsilon: 0.5431862307172693  loss: 398595.06400954723\n",
      "episode: 533   score: 1996  move: 163   memory length: 5000   epsilon: 0.5423015539452577  loss: 235504.29275692897\n",
      "episode: 534   score: 652  move: 85   memory length: 5000   epsilon: 0.5418407911725086  loss: 452388.77740141924\n",
      "episode: 535   score: 1148  move: 122   memory length: 5000   epsilon: 0.541180145180044  loss: 315924.25209336204\n",
      "episode: 536   score: 1296  move: 137   memory length: 5000   epsilon: 0.5404392323177765  loss: 282068.4343735354\n",
      "episode: 537   score: 1368  move: 144   memory length: 5000   epsilon: 0.5396615559961888  loss: 269103.4163997703\n",
      "episode: 538   score: 2084  move: 175   memory length: 5000   epsilon: 0.5387179694343134  loss: 222170.72158423287\n",
      "episode: 539   score: 736  move: 96   memory length: 5000   epsilon: 0.5382010457620988  loss: 405743.0667764743\n",
      "episode: 540   score: 1488  move: 155   memory length: 5000   epsilon: 0.5373674761566483  loss: 252034.04816394928\n",
      "episode: 541   score: 336  move: 62   memory length: 5000   epsilon: 0.5370344099173026  loss: 630816.042066328\n",
      "episode: 542   score: 1640  move: 167   memory length: 5000   epsilon: 0.5361383064268972  loss: 234927.0952452928\n",
      "episode: 543   score: 1908  move: 156   memory length: 5000   epsilon: 0.535302578527477  loss: 252233.01361683087\n",
      "episode: 544   score: 748  move: 97   memory length: 5000   epsilon: 0.5347835841842818  loss: 406408.928407846\n",
      "episode: 545   score: 2468  move: 214   memory length: 5000   epsilon: 0.5336403652785506  loss: 184968.36919547463\n",
      "Weights save... Top reward = 328\n",
      "episode: 546   score: 1664  move: 173   memory length: 5000   epsilon: 0.5327179609443986  loss: 229573.073633205\n",
      "episode: 547   score: 772  move: 102   memory length: 5000   epsilon: 0.5321748629358145  loss: 390116.9089058147\n",
      "episode: 548   score: 2508  move: 219   memory length: 5000   epsilon: 0.5310106694222125  loss: 182437.58410708982\n",
      "episode: 549   score: 732  move: 94   memory length: 5000   epsilon: 0.5305117514265592  loss: 425764.50170464214\n",
      "episode: 550   score: 320  move: 58   memory length: 5000   epsilon: 0.5302041422879585  loss: 690761.7179979127\n",
      "episode: 551   score: 736  move: 97   memory length: 5000   epsilon: 0.5296900910548352  loss: 413781.18144135625\n",
      "episode: 552   score: 696  move: 88   memory length: 5000   epsilon: 0.5292241664819628  loss: 456826.1431789832\n",
      "episode: 553   score: 964  move: 108   memory length: 5000   epsilon: 0.5286529100598716  loss: 372969.5735368022\n",
      "episode: 554   score: 1284  move: 132   memory length: 5000   epsilon: 0.5279555450939001  loss: 305892.1171617508\n",
      "episode: 555   score: 1284  move: 137   memory length: 5000   epsilon: 0.5272327376192553  loss: 295442.8061934701\n",
      "episode: 556   score: 1332  move: 135   memory length: 5000   epsilon: 0.5265214500941359  loss: 300526.66065642744\n",
      "episode: 557   score: 840  move: 102   memory length: 5000   epsilon: 0.5259846693358591  loss: 398433.3992553786\n",
      "episode: 558   score: 1008  move: 107   memory length: 5000   epsilon: 0.5254221639212054  loss: 380487.1484040234\n",
      "episode: 559   score: 1468  move: 155   memory length: 5000   epsilon: 0.5246083863387886  loss: 263335.6890319086\n",
      "episode: 560   score: 1096  move: 118   memory length: 5000   epsilon: 0.5239897104400938  loss: 346596.10207473626\n",
      "episode: 561   score: 1132  move: 123   memory length: 5000   epsilon: 0.5233455960872129  loss: 333175.44229563273\n",
      "episode: 562   score: 1216  move: 126   memory length: 5000   epsilon: 0.5226865926005065  loss: 325932.1880356622\n",
      "episode: 563   score: 996  move: 118   memory length: 5000   epsilon: 0.5220701830923222  loss: 348704.86474108294\n",
      "episode: 564   score: 676  move: 88   memory length: 5000   epsilon: 0.5216109611223915  loss: 468243.7084952701\n",
      "episode: 565   score: 1224  move: 134   memory length: 5000   epsilon: 0.5209124670375695  loss: 308188.43604919093\n",
      "episode: 566   score: 612  move: 83   memory length: 5000   epsilon: 0.5204802869085907  loss: 498215.43405027274\n",
      "episode: 567   score: 1240  move: 133   memory length: 5000   epsilon: 0.5197885048051636  loss: 311588.86130325776\n",
      "episode: 568   score: 1300  move: 131   memory length: 5000   epsilon: 0.519108024273527  loss: 317022.93448030314\n",
      "episode: 569   score: 1152  move: 123   memory length: 5000   epsilon: 0.5184699107333786  loss: 338310.7110485604\n",
      "episode: 570   score: 2276  move: 187   memory length: 5000   epsilon: 0.5175012731155584  loss: 223201.79191917786\n",
      "episode: 571   score: 1236  move: 131   memory length: 5000   epsilon: 0.5168237869106945  loss: 319289.3705180219\n",
      "episode: 572   score: 1672  move: 164   memory length: 5000   epsilon: 0.5159768863139631  loss: 255716.6063146126\n",
      "episode: 573   score: 1504  move: 154   memory length: 5000   epsilon: 0.515182889473541  loss: 272986.16238594055\n",
      "episode: 574   score: 736  move: 100   memory length: 5000   epsilon: 0.5146679615163151  loss: 421052.85894031526\n",
      "episode: 575   score: 1468  move: 156   memory length: 5000   epsilon: 0.513865701410628  loss: 270562.01442124293\n",
      "episode: 576   score: 740  move: 98   memory length: 5000   epsilon: 0.513362357185477  loss: 431334.7779303181\n",
      "episode: 577   score: 1132  move: 121   memory length: 5000   epsilon: 0.5127415612865621  loss: 349999.73784785625\n",
      "episode: 578   score: 1064  move: 116   memory length: 5000   epsilon: 0.5121471229441709  loss: 365722.5226665694\n",
      "episode: 579   score: 912  move: 111   memory length: 5000   epsilon: 0.511578952189953  loss: 382814.70813252905\n",
      "episode: 580   score: 796  move: 104   memory length: 5000   epsilon: 0.5110471839882279  loss: 409218.9126424423\n",
      "episode: 581   score: 1796  move: 179   memory length: 5000   epsilon: 0.5101332231980255  loss: 238389.59406636414\n",
      "episode: 582   score: 1332  move: 139   memory length: 5000   epsilon: 0.5094246270632002  loss: 307629.96204153926\n",
      "episode: 583   score: 1216  move: 126   memory length: 5000   epsilon: 0.5087831530392302  loss: 340007.28471946716\n",
      "episode: 584   score: 620  move: 85   memory length: 5000   epsilon: 0.508350868944492  loss: 504642.40354852116\n",
      "episode: 585   score: 980  move: 119   memory length: 5000   epsilon: 0.5077462881844399  loss: 361089.4612343732\n",
      "episode: 586   score: 2460  move: 212   memory length: 5000   epsilon: 0.5066710008843189  loss: 203295.61528657516\n",
      "episode: 587   score: 1364  move: 141   memory length: 5000   epsilon: 0.5059570946257269  loss: 306281.2847529472\n",
      "episode: 588   score: 400  move: 66   memory length: 5000   epsilon: 0.5056232714479233  loss: 654964.669288693\n",
      "episode: 589   score: 380  move: 62   memory length: 5000   epsilon: 0.5053098806138678  loss: 697857.3804284988\n",
      "episode: 590   score: 248  move: 49   memory length: 5000   epsilon: 0.5050623381875015  loss: 883627.9760123272\n",
      "episode: 591   score: 1060  move: 115   memory length: 5000   epsilon: 0.5044818474422836  loss: 377170.1248364324\n",
      "episode: 592   score: 2064  move: 168   memory length: 5000   epsilon: 0.5036350252342952  loss: 258857.90536891847\n",
      "episode: 593   score: 1236  move: 133   memory length: 5000   epsilon: 0.5029656325485785  loss: 327648.75935435476\n",
      "episode: 594   score: 592  move: 82   memory length: 5000   epsilon: 0.5025533677202432  loss: 532099.1033550821\n",
      "episode: 595   score: 1648  move: 166   memory length: 5000   epsilon: 0.5017198170005801  loss: 263486.52367421804\n",
      "episode: 596   score: 328  move: 60   memory length: 5000   epsilon: 0.5014188738976221  loss: 729634.7435519536\n",
      "episode: 597   score: 1444  move: 150   memory length: 5000   epsilon: 0.5006673056460405  loss: 292521.285738856\n",
      "episode: 598   score: 1356  move: 144   memory length: 5000   epsilon: 0.4999468599690597  loss: 305389.8330376148\n",
      "episode: 599   score: 1204  move: 128   memory length: 5000   epsilon: 0.4993073341744934  loss: 344249.6537026465\n",
      "episode: 600   score: 1364  move: 142   memory length: 5000   epsilon: 0.4985988173833556  loss: 310998.76407454046\n",
      "episode: 601   score: 1464  move: 152   memory length: 5000   epsilon: 0.49784151908694946  loss: 291241.62289079867\n",
      "episode: 602   score: 956  move: 106   memory length: 5000   epsilon: 0.4973140840295063  loss: 418337.45332095306\n",
      "episode: 603   score: 544  move: 75   memory length: 5000   epsilon: 0.496941236437569  loss: 591942.4049441019\n",
      "episode: 604   score: 612  move: 83   memory length: 5000   epsilon: 0.4965289442747801  loss: 535586.3150901794\n",
      "episode: 605   score: 396  move: 66   memory length: 5000   epsilon: 0.4962013416543014  loss: 674251.2927248983\n",
      "episode: 606   score: 764  move: 101   memory length: 5000   epsilon: 0.4957004287982387  loss: 441292.6601700358\n",
      "episode: 607   score: 3016  move: 245   memory length: 5000   epsilon: 0.4944874431968608  loss: 182634.66368690023\n",
      "episode: 608   score: 1108  move: 133   memory length: 5000   epsilon: 0.4938302087690113  loss: 337165.34819010686\n",
      "episode: 609   score: 612  move: 83   memory length: 5000   epsilon: 0.49342049770079055  loss: 541022.4024469306\n",
      "episode: 610   score: 836  move: 103   memory length: 5000   epsilon: 0.49291253369470833  loss: 436693.6260407457\n",
      "episode: 611   score: 1272  move: 128   memory length: 5000   epsilon: 0.4922820061226735  loss: 352106.0476666987\n",
      "episode: 612   score: 884  move: 107   memory length: 5000   epsilon: 0.49175554345156525  loss: 421903.251936761\n",
      "episode: 613   score: 676  move: 88   memory length: 5000   epsilon: 0.4913229867633999  loss: 513690.196097504\n",
      "episode: 614   score: 1440  move: 145   memory length: 5000   epsilon: 0.49061108112937923  loss: 312472.59453201294\n",
      "episode: 615   score: 2200  move: 185   memory length: 5000   epsilon: 0.48970428514022357  loss: 245625.2195569219\n",
      "episode: 616   score: 1352  move: 143   memory length: 5000   epsilon: 0.48900450497563636  loss: 318517.0195123899\n",
      "episode: 617   score: 1048  move: 113   memory length: 5000   epsilon: 0.488452239212605  loss: 403821.86104067235\n",
      "episode: 618   score: 840  move: 100   memory length: 5000   epsilon: 0.4879640286782896  loss: 457089.11994007113\n",
      "episode: 619   score: 860  move: 105   memory length: 5000   epsilon: 0.48745193278508897  loss: 436101.2721696036\n",
      "episode: 620   score: 436  move: 71   memory length: 5000   epsilon: 0.48710596301676273  loss: 645720.3986032513\n",
      "episode: 621   score: 804  move: 103   memory length: 5000   epsilon: 0.4866044996654963  loss: 445883.8536482505\n",
      "episode: 622   score: 420  move: 70   memory length: 5000   epsilon: 0.48626399400408654  loss: 656877.1274316516\n",
      "episode: 623   score: 588  move: 81   memory length: 5000   epsilon: 0.4858702776769992  loss: 568485.9817413047\n",
      "episode: 624   score: 620  move: 83   memory length: 5000   epsilon: 0.4854671706435514  loss: 555606.2462708347\n",
      "episode: 625   score: 2704  move: 230   memory length: 5000   epsilon: 0.4843518736577784  loss: 201307.5224319624\n",
      "episode: 626   score: 1816  move: 184   memory length: 5000   epsilon: 0.48346148117058096  loss: 252434.10388392987\n",
      "episode: 627   score: 932  move: 94   memory length: 5000   epsilon: 0.4830072386345056  loss: 494929.3900823796\n",
      "episode: 628   score: 940  move: 102   memory length: 5000   epsilon: 0.48251481996521745  loss: 456934.017155853\n",
      "episode: 629   score: 524  move: 71   memory length: 5000   epsilon: 0.4821723543204031  loss: 657271.1980533331\n",
      "episode: 630   score: 1352  move: 143   memory length: 5000   epsilon: 0.48148333717331143  loss: 327166.4695324931\n",
      "episode: 631   score: 712  move: 92   memory length: 5000   epsilon: 0.48104057399158734  loss: 509360.90388111444\n",
      "episode: 632   score: 2124  move: 168   memory length: 5000   epsilon: 0.480233100257765  loss: 279755.7481007576\n",
      "episode: 633   score: 432  move: 70   memory length: 5000   epsilon: 0.4798970530375963  loss: 672262.7174772535\n",
      "episode: 634   score: 1188  move: 130   memory length: 5000   epsilon: 0.4792735890906956  loss: 362803.19283579313\n",
      "episode: 635   score: 1080  move: 113   memory length: 5000   epsilon: 0.4787323131071683  loss: 418195.3127861698\n",
      "episode: 636   score: 1364  move: 141   memory length: 5000   epsilon: 0.4780577728356298  loss: 335968.04697621125\n",
      "episode: 637   score: 292  move: 56   memory length: 5000   epsilon: 0.47779013409049004  loss: 846768.9097723961\n",
      "episode: 638   score: 360  move: 61   memory length: 5000   epsilon: 0.47749876952709736  loss: 778191.6555554124\n",
      "episode: 639   score: 1980  move: 161   memory length: 5000   epsilon: 0.4767306112007464  loss: 295669.05734643876\n",
      "episode: 640   score: 812  move: 95   memory length: 5000   epsilon: 0.4762779299143541  loss: 501929.66396343836\n",
      "episode: 641   score: 756  move: 95   memory length: 5000   epsilon: 0.4758256784731242  loss: 502771.93259136804\n",
      "episode: 642   score: 668  move: 93   memory length: 5000   epsilon: 0.4753833640886394  loss: 514411.9550025284\n",
      "episode: 643   score: 1128  move: 119   memory length: 5000   epsilon: 0.47481799152190535  loss: 402871.9179055671\n",
      "episode: 644   score: 736  move: 98   memory length: 5000   epsilon: 0.4743528954990066  loss: 490021.27224657487\n",
      "episode: 645   score: 1464  move: 154   memory length: 5000   epsilon: 0.4736229505920515  loss: 312650.17656195007\n",
      "episode: 646   score: 964  move: 115   memory length: 5000   epsilon: 0.47307859454180995  loss: 419512.088699374\n",
      "episode: 647   score: 1656  move: 156   memory length: 5000   epsilon: 0.47234116359285916  loss: 310062.0997971021\n",
      "episode: 648   score: 824  move: 106   memory length: 5000   epsilon: 0.47184074472621  loss: 457114.0185908551\n",
      "episode: 649   score: 504  move: 73   memory length: 5000   epsilon: 0.471496424952968  loss: 664571.9712447597\n",
      "episode: 650   score: 676  move: 91   memory length: 5000   epsilon: 0.4710675562267814  loss: 533933.4210197113\n",
      "episode: 651   score: 580  move: 80   memory length: 5000   epsilon: 0.4706908510004541  loss: 608176.3892035007\n",
      "episode: 652   score: 1392  move: 145   memory length: 5000   epsilon: 0.470008840433604  loss: 336345.093347089\n",
      "episode: 653   score: 344  move: 57   memory length: 5000   epsilon: 0.4697410103942184  loss: 856437.2930253012\n",
      "episode: 654   score: 676  move: 91   memory length: 5000   epsilon: 0.46931373837665125  loss: 537258.8621932229\n",
      "episode: 655   score: 360  move: 61   memory length: 5000   epsilon: 0.46902754286376885  loss: 802302.7634155399\n",
      "episode: 656   score: 1308  move: 136   memory length: 5000   epsilon: 0.46839009578050567  loss: 360684.8948910938\n",
      "episode: 657   score: 1028  move: 122   memory length: 5000   epsilon: 0.4678190054441393  loss: 402905.9452663797\n",
      "episode: 658   score: 1292  move: 134   memory length: 5000   epsilon: 0.46719254466699855  loss: 367632.61683441274\n",
      "episode: 659   score: 1412  move: 146   memory length: 5000   epsilon: 0.4665109378378103  loss: 338230.67848281335\n",
      "episode: 660   score: 2568  move: 225   memory length: 5000   epsilon: 0.4654624629618598  loss: 220292.39179316204\n",
      "episode: 661   score: 624  move: 86   memory length: 5000   epsilon: 0.4650623353226189  loss: 577170.6333002934\n",
      "episode: 662   score: 1836  move: 173   memory length: 5000   epsilon: 0.4642584690080304  loss: 287712.62716985715\n",
      "episode: 663   score: 684  move: 90   memory length: 5000   epsilon: 0.4638408222669127  loss: 553847.3874371423\n",
      "episode: 664   score: 1112  move: 120   memory length: 5000   epsilon: 0.46328454433231503  loss: 416192.55653804145\n",
      "episode: 665   score: 1844  move: 176   memory length: 5000   epsilon: 0.46246987657886535  loss: 284570.14571426134\n",
      "episode: 666   score: 1396  move: 146   memory length: 5000   epsilon: 0.46179515984853964  loss: 343894.4685971247\n",
      "episode: 667   score: 1460  move: 151   memory length: 5000   epsilon: 0.46109837188053776  loss: 333320.3229710914\n",
      "episode: 668   score: 1296  move: 131   memory length: 5000   epsilon: 0.4604947254698655  loss: 384992.05887298\n",
      "episode: 669   score: 500  move: 75   memory length: 5000   epsilon: 0.46014948218196156  loss: 673257.6741075134\n",
      "episode: 670   score: 1544  move: 150   memory length: 5000   epsilon: 0.45945977192215104  loss: 337422.21141227725\n",
      "episode: 671   score: 1064  move: 114   memory length: 5000   epsilon: 0.4589362836097484  loss: 444757.3709244644\n",
      "episode: 672   score: 644  move: 87   memory length: 5000   epsilon: 0.458537180682439  loss: 583557.3858662309\n",
      "episode: 673   score: 1512  move: 155   memory length: 5000   epsilon: 0.457826995037511  loss: 328316.0802375301\n",
      "episode: 674   score: 1140  move: 112   memory length: 5000   epsilon: 0.45731451328401174  loss: 455152.04706454277\n",
      "episode: 675   score: 604  move: 82   memory length: 5000   epsilon: 0.45693966721677853  loss: 622466.0825123205\n",
      "episode: 676   score: 1308  move: 136   memory length: 5000   epsilon: 0.4563186485526796  loss: 376075.319452987\n",
      "episode: 677   score: 1364  move: 143   memory length: 5000   epsilon: 0.4556665759679012  loss: 358444.17021373933\n",
      "episode: 678   score: 1652  move: 170   memory length: 5000   epsilon: 0.4548925969873921  loss: 302242.6392654643\n",
      "episode: 679   score: 1612  move: 170   memory length: 5000   epsilon: 0.4541199326599516  loss: 302977.43430940964\n",
      "episode: 680   score: 768  move: 102   memory length: 5000   epsilon: 0.45365696416786483  loss: 505671.796710033\n",
      "episode: 681   score: 496  move: 75   memory length: 5000   epsilon: 0.4533168473039206  loss: 688427.4085549418\n",
      "episode: 682   score: 1144  move: 124   memory length: 5000   epsilon: 0.4527550799721522  loss: 417085.84833123605\n",
      "episode: 683   score: 892  move: 111   memory length: 5000   epsilon: 0.4522527981399611  loss: 466613.23174406175\n",
      "episode: 684   score: 1156  move: 123   memory length: 5000   epsilon: 0.4516968663867058  loss: 421767.8267124145\n",
      "episode: 685   score: 776  move: 103   memory length: 5000   epsilon: 0.4512318558108305  loss: 504356.71526703326\n",
      "episode: 686   score: 656  move: 87   memory length: 5000   epsilon: 0.45083945285429594  loss: 597783.6526894843\n",
      "episode: 687   score: 1164  move: 124   memory length: 5000   epsilon: 0.45028075560315173  loss: 420073.4344252617\n",
      "episode: 688   score: 1584  move: 164   memory length: 5000   epsilon: 0.4495428966843582  loss: 318295.4279202019\n",
      "episode: 689   score: 760  move: 102   memory length: 5000   epsilon: 0.4490845944121212  loss: 512439.37524073734\n",
      "episode: 690   score: 556  move: 76   memory length: 5000   epsilon: 0.4487434180779138  loss: 688423.1127293737\n",
      "episode: 691   score: 1416  move: 147   memory length: 5000   epsilon: 0.44808424656724055  loss: 356584.37543630274\n",
      "episode: 692   score: 956  move: 116   memory length: 5000   epsilon: 0.44756476759987807  loss: 452545.30378897436\n",
      "episode: 693   score: 1048  move: 110   memory length: 5000   epsilon: 0.4470727145740311  loss: 477894.91515853186\n",
      "episode: 694   score: 272  move: 52   memory length: 5000   epsilon: 0.44684029603441655  loss: 1011602.7544817558\n",
      "episode: 695   score: 972  move: 103   memory length: 5000   epsilon: 0.4463802851757065  loss: 511380.4275656765\n",
      "episode: 696   score: 1148  move: 125   memory length: 5000   epsilon: 0.4458226556221662  loss: 422058.9656329651\n",
      "episode: 697   score: 552  move: 79   memory length: 5000   epsilon: 0.4454705930469378  loss: 668500.9675662366\n",
      "episode: 698   score: 952  move: 118   memory length: 5000   epsilon: 0.4449452451366258  loss: 448244.6460787563\n",
      "episode: 699   score: 1332  move: 137   memory length: 5000   epsilon: 0.44433608447531475  loss: 386778.9541161809\n",
      "episode: 700   score: 1452  move: 152   memory length: 5000   epsilon: 0.4436612032921408  loss: 349293.9521276825\n",
      "episode: 701   score: 1480  move: 151   memory length: 5000   epsilon: 0.4429917770720289  loss: 352278.6446154512\n",
      "episode: 702   score: 1340  move: 142   memory length: 5000   epsilon: 0.4423631720207725  loss: 375262.4325371595\n",
      "episode: 703   score: 1400  move: 144   memory length: 5000   epsilon: 0.44172662429468024  loss: 370706.47155160375\n",
      "episode: 704   score: 1384  move: 141   memory length: 5000   epsilon: 0.44110422553666934  loss: 379278.03628770006\n",
      "episode: 705   score: 1356  move: 139   memory length: 5000   epsilon: 0.4404915135331056  loss: 385394.0080840022\n",
      "episode: 706   score: 1204  move: 127   memory length: 5000   epsilon: 0.43993244160137795  loss: 422473.30300005217\n",
      "episode: 707   score: 2460  move: 211   memory length: 5000   epsilon: 0.43900515814126023  loss: 254953.96354619248\n",
      "episode: 708   score: 1448  move: 152   memory length: 5000   epsilon: 0.4383383738514006  loss: 354575.47736049956\n",
      "episode: 709   score: 692  move: 91   memory length: 5000   epsilon: 0.437939665377522  loss: 592943.1491070841\n",
      "episode: 710   score: 1004  move: 108   memory length: 5000   epsilon: 0.4374669434910705  loss: 500273.578477259\n",
      "episode: 711   score: 552  move: 81   memory length: 5000   epsilon: 0.43711273696881664  loss: 667699.7565939161\n",
      "episode: 712   score: 2304  move: 197   memory length: 5000   epsilon: 0.43625246821857927  loss: 275203.45977823867\n",
      "episode: 713   score: 732  move: 96   memory length: 5000   epsilon: 0.4358338647178992  loss: 565423.3213916222\n",
      "episode: 714   score: 416  move: 70   memory length: 5000   epsilon: 0.43552888624262304  loss: 776116.6898065294\n",
      "episode: 715   score: 1020  move: 109   memory length: 5000   epsilon: 0.4350544160175154  loss: 499096.58073764766\n",
      "episode: 716   score: 1412  move: 146   memory length: 5000   epsilon: 0.4344196968542684  loss: 373282.75310205435\n",
      "episode: 717   score: 2224  move: 183   memory length: 5000   epsilon: 0.4336254318118712  loss: 298478.55499828316\n",
      "episode: 718   score: 1328  move: 137   memory length: 5000   epsilon: 0.43303176875402005  loss: 399400.3277640517\n",
      "episode: 719   score: 636  move: 87   memory length: 5000   epsilon: 0.4326551930665009  loss: 629628.0064794167\n",
      "episode: 720   score: 816  move: 102   memory length: 5000   epsilon: 0.4322141075559966  loss: 537735.2392544092\n",
      "episode: 721   score: 728  move: 96   memory length: 5000   epsilon: 0.4317993790406373  loss: 572026.7937992811\n",
      "episode: 722   score: 1432  move: 149   memory length: 5000   epsilon: 0.4311564738346603  loss: 369249.88172239263\n",
      "episode: 723   score: 2272  move: 186   memory length: 5000   epsilon: 0.43035526414327946  loss: 296484.78503461037\n",
      "episode: 724   score: 928  move: 96   memory length: 5000   epsilon: 0.4299423192702292  loss: 575145.5860750278\n",
      "episode: 725   score: 1304  move: 132   memory length: 5000   epsilon: 0.42937516697589395  loss: 418989.6079653249\n",
      "episode: 726   score: 1448  move: 150   memory length: 5000   epsilon: 0.42873158381555465  loss: 369431.00751823426\n",
      "episode: 727   score: 764  move: 103   memory length: 5000   epsilon: 0.4282902154211249  loss: 538719.3119209438\n",
      "episode: 728   score: 896  move: 109   memory length: 5000   epsilon: 0.42782363108805  loss: 509782.9832737424\n",
      "episode: 729   score: 3004  move: 247   memory length: 5000   epsilon: 0.42676820542940846  loss: 225689.21856005277\n",
      "episode: 730   score: 1236  move: 127   memory length: 5000   epsilon: 0.4262265511235273  loss: 439664.90104197705\n",
      "episode: 731   score: 1276  move: 129   memory length: 5000   epsilon: 0.4256770706163003  loss: 433582.52217246953\n",
      "episode: 732   score: 1504  move: 157   memory length: 5000   epsilon: 0.42500927863035004  loss: 357004.69011569174\n",
      "episode: 733   score: 908  move: 109   memory length: 5000   epsilon: 0.4245462685879062  loss: 514939.92723898933\n",
      "episode: 734   score: 3116  move: 260   memory length: 5000   epsilon: 0.42344387650833365  loss: 216584.05967637576\n",
      "episode: 735   score: 924  move: 116   memory length: 5000   epsilon: 0.42295296394135606  loss: 486162.361699762\n",
      "episode: 736   score: 1372  move: 143   memory length: 5000   epsilon: 0.42234857042530866  loss: 395082.28817612975\n",
      "episode: 737   score: 740  move: 98   memory length: 5000   epsilon: 0.4219348695043467  loss: 577220.7932049887\n",
      "episode: 738   score: 1228  move: 129   memory length: 5000   epsilon: 0.42139092172469583  loss: 439224.9067857432\n",
      "episode: 739   score: 1924  move: 176   memory length: 5000   epsilon: 0.42064992226825976  loss: 322658.12626138603\n",
      "episode: 740   score: 1076  move: 118   memory length: 5000   epsilon: 0.42015384562238073  loss: 482004.986126043\n",
      "episode: 741   score: 444  move: 63   memory length: 5000   epsilon: 0.4198892307390037  loss: 903555.9982041253\n",
      "episode: 742   score: 768  move: 101   memory length: 5000   epsilon: 0.4194653545900633  loss: 564372.24487384\n",
      "episode: 743   score: 872  move: 105   memory length: 5000   epsilon: 0.4190251449172164  loss: 543626.4284873236\n",
      "episode: 744   score: 444  move: 73   memory length: 5000   epsilon: 0.41871936665517906  loss: 782686.9127066103\n",
      "episode: 745   score: 1240  move: 133   memory length: 5000   epsilon: 0.4181628372889449  loss: 430363.75056689844\n",
      "episode: 746   score: 1276  move: 127   memory length: 5000   epsilon: 0.41763210491831476  loss: 451465.4519551495\n",
      "episode: 747   score: 1088  move: 131   memory length: 5000   epsilon: 0.41708536232174653  loss: 438446.06553256785\n",
      "episode: 748   score: 1876  move: 180   memory length: 5000   epsilon: 0.4163352801955905  loss: 319857.3618956884\n",
      "episode: 749   score: 692  move: 94   memory length: 5000   epsilon: 0.415944106956565  loss: 613257.4861000954\n",
      "episode: 750   score: 996  move: 106   memory length: 5000   epsilon: 0.4155034375958653  loss: 544568.8971044073\n",
      "episode: 751   score: 764  move: 98   memory length: 5000   epsilon: 0.4150964416526253  loss: 589784.7431813843\n",
      "episode: 752   score: 2996  move: 239   memory length: 5000   epsilon: 0.41410554080076517  loss: 242592.90810067084\n",
      "episode: 753   score: 740  move: 98   memory length: 5000   epsilon: 0.41369991413217705  loss: 592411.0457532065\n",
      "episode: 754   score: 560  move: 80   memory length: 5000   epsilon: 0.4133690848960626  loss: 726482.075062418\n",
      "episode: 755   score: 604  move: 85   memory length: 5000   epsilon: 0.4130178687058459  loss: 684547.6104368771\n",
      "episode: 756   score: 1224  move: 127   memory length: 5000   epsilon: 0.41249366633054146  loss: 458930.17022888304\n",
      "episode: 757   score: 1088  move: 121   memory length: 5000   epsilon: 0.4119948483459304  loss: 482450.8680058314\n",
      "episode: 758   score: 812  move: 103   memory length: 5000   epsilon: 0.4115707100001862  loss: 567521.5177780078\n",
      "episode: 759   score: 676  move: 88   memory length: 5000   epsilon: 0.41120868527950116  loss: 665004.1438441277\n",
      "episode: 760   score: 1548  move: 160   memory length: 5000   epsilon: 0.41055127416513565  loss: 366508.0999764681\n",
      "episode: 761   score: 504  move: 73   memory length: 5000   epsilon: 0.4102516796023409  loss: 804041.9184894823\n",
      "episode: 762   score: 872  move: 102   memory length: 5000   epsilon: 0.4098334341393658  loss: 576197.2763646818\n",
      "episode: 763   score: 348  move: 63   memory length: 5000   epsilon: 0.4095753191000561  loss: 933641.1977740696\n",
      "episode: 764   score: 1520  move: 154   memory length: 5000   epsilon: 0.4089450553849434  loss: 382698.42239114834\n",
      "episode: 765   score: 1356  move: 140   memory length: 5000   epsilon: 0.40837293002797276  loss: 421706.0914737429\n",
      "episode: 766   score: 840  move: 101   memory length: 5000   epsilon: 0.40796067952893744  loss: 585302.9081190128\n",
      "episode: 767   score: 636  move: 88   memory length: 5000   epsilon: 0.4076018302535433  loss: 672508.3029984995\n",
      "episode: 768   score: 1708  move: 172   memory length: 5000   epsilon: 0.4069013541852344  loss: 344813.1992438782\n",
      "episode: 769   score: 704  move: 94   memory length: 5000   epsilon: 0.4065190447143536  loss: 631678.2266448407\n",
      "episode: 770   score: 720  move: 96   memory length: 5000   epsilon: 0.40612897174604384  loss: 619278.6109516224\n",
      "episode: 771   score: 1036  move: 112   memory length: 5000   epsilon: 0.40567435965491944  loss: 531551.5336569718\n",
      "episode: 772   score: 1088  move: 120   memory length: 5000   epsilon: 0.40518783996093205  loss: 496840.8172458967\n",
      "episode: 773   score: 628  move: 87   memory length: 5000   epsilon: 0.40483547807799974  loss: 686014.64223774\n",
      "episode: 774   score: 968  move: 116   memory length: 5000   epsilon: 0.40436613884611494  loss: 515241.3339092978\n",
      "episode: 775   score: 1308  move: 132   memory length: 5000   epsilon: 0.4038327250063534  loss: 453511.7354955095\n",
      "episode: 776   score: 1672  move: 171   memory length: 5000   epsilon: 0.4031427576869402  loss: 350785.9883006358\n",
      "episode: 777   score: 1144  move: 123   memory length: 5000   epsilon: 0.4026471944510357  loss: 488385.0494952008\n",
      "episode: 778   score: 1248  move: 130   memory length: 5000   epsilon: 0.40212409057391907  loss: 462803.3726906703\n",
      "episode: 779   score: 1696  move: 174   memory length: 5000   epsilon: 0.4014249995464382  loss: 346475.3499997238\n",
      "episode: 780   score: 720  move: 94   memory length: 5000   epsilon: 0.4010478354559374  loss: 642047.1092352766\n",
      "episode: 781   score: 1060  move: 120   memory length: 5000   epsilon: 0.4005668642889499  loss: 503653.59272502264\n",
      "episode: 782   score: 1072  move: 117   memory length: 5000   epsilon: 0.40009847277823796  loss: 517256.96592663496\n",
      "episode: 783   score: 980  move: 125   memory length: 5000   epsilon: 0.39959865963649155  loss: 484832.38323062134\n",
      "episode: 784   score: 2068  move: 174   memory length: 5000   epsilon: 0.39890395905999354  loss: 348989.4620555352\n",
      "episode: 785   score: 1640  move: 167   memory length: 5000   epsilon: 0.3982383420651622  loss: 364326.44219580095\n",
      "episode: 786   score: 1252  move: 130   memory length: 5000   epsilon: 0.39772096600090145  loss: 468738.52641897934\n",
      "episode: 787   score: 1336  move: 139   memory length: 5000   epsilon: 0.39716851513820334  loss: 439102.51463935355\n",
      "episode: 788   score: 1468  move: 144   memory length: 5000   epsilon: 0.3965970012076206  loss: 424566.2217113972\n",
      "episode: 789   score: 2244  move: 217   memory length: 5000   epsilon: 0.3957373145139757  loss: 282445.3956033909\n",
      "episode: 790   score: 536  move: 80   memory length: 5000   epsilon: 0.39542084968284996  loss: 766840.0404448032\n",
      "episode: 791   score: 1668  move: 160   memory length: 5000   epsilon: 0.39478867903388454  loss: 384152.1004180193\n",
      "episode: 792   score: 1528  move: 159   memory length: 5000   epsilon: 0.3941614606688666  loss: 387296.6711037354\n",
      "episode: 793   score: 860  move: 104   memory length: 5000   epsilon: 0.39375174379089095  loss: 592831.6589225256\n",
      "episode: 794   score: 1212  move: 126   memory length: 5000   epsilon: 0.39325592654508834  loss: 490035.2711936406\n",
      "episode: 795   score: 956  move: 116   memory length: 5000   epsilon: 0.3928000118723547  loss: 532993.1931056648\n",
      "episode: 796   score: 784  move: 97   memory length: 5000   epsilon: 0.39241917869062487  loss: 638106.7431243032\n",
      "episode: 797   score: 1064  move: 117   memory length: 5000   epsilon: 0.3919603144451627  loss: 529740.743488703\n",
      "episode: 798   score: 804  move: 103   memory length: 5000   epsilon: 0.39155680114873814  loss: 602453.9396731553\n",
      "episode: 799   score: 768  move: 103   memory length: 5000   epsilon: 0.39115370325911447  loss: 603166.3052731486\n",
      "episode: 800   score: 2364  move: 199   memory length: 5000   epsilon: 0.3903760774957556  loss: 312906.25883547147\n",
      "episode: 801   score: 516  move: 68   memory length: 5000   epsilon: 0.3901107106711695  loss: 916419.4088855631\n",
      "episode: 802   score: 1496  move: 157   memory length: 5000   epsilon: 0.389498714338263  loss: 397647.02559290116\n",
      "episode: 803   score: 1340  move: 138   memory length: 5000   epsilon: 0.38896157413875526  loss: 453101.3271406146\n",
      "episode: 804   score: 852  move: 103   memory length: 5000   epsilon: 0.38856114797013813  loss: 607770.2460980832\n",
      "episode: 805   score: 596  move: 80   memory length: 5000   epsilon: 0.38825042180516817  loss: 783188.3909601688\n",
      "episode: 806   score: 160  move: 40   memory length: 5000   epsilon: 0.3880951519161442  loss: 1567037.4562428475\n",
      "episode: 807   score: 576  move: 79   memory length: 5000   epsilon: 0.38778867628756386  loss: 794150.1812545679\n",
      "episode: 808   score: 312  move: 57   memory length: 5000   epsilon: 0.3875676986218085  loss: 1101353.9302157352\n",
      "episode: 809   score: 708  move: 94   memory length: 5000   epsilon: 0.38720355433900744  loss: 668567.1047157531\n",
      "episode: 810   score: 1060  move: 130   memory length: 5000   epsilon: 0.38670051425006746  loss: 484125.63789171074\n",
      "episode: 811   score: 2496  move: 212   memory length: 5000   epsilon: 0.38588157344912144  loss: 297577.60492960014\n",
      "episode: 812   score: 1412  move: 145   memory length: 5000   epsilon: 0.38532244783602343  loss: 435810.93591574306\n",
      "episode: 813   score: 1020  move: 108   memory length: 5000   epsilon: 0.38490652215302745  loss: 585848.0378885976\n",
      "episode: 814   score: 1556  move: 162   memory length: 5000   epsilon: 0.38428347527613393  loss: 391293.33348509704\n",
      "episode: 815   score: 1300  move: 135   memory length: 5000   epsilon: 0.3837650400148721  loss: 470267.47001537745\n",
      "episode: 816   score: 1064  move: 114   memory length: 5000   epsilon: 0.3833277949600634  loss: 557616.416928375\n",
      "episode: 817   score: 1448  move: 151   memory length: 5000   epsilon: 0.3827494038928715  loss: 421722.8129271703\n",
      "episode: 818   score: 1188  move: 130   memory length: 5000   epsilon: 0.3822521504662991  loss: 490552.24333792465\n",
      "episode: 819   score: 672  move: 94   memory length: 5000   epsilon: 0.38189300047605057  loss: 679136.1214163355\n",
      "episode: 820   score: 720  move: 96   memory length: 5000   epsilon: 0.38152655728425133  loss: 665700.9068417946\n",
      "episode: 821   score: 1280  move: 140   memory length: 5000   epsilon: 0.38099279115869034  loss: 457203.67543196\n",
      "episode: 822   score: 1316  move: 135   memory length: 5000   epsilon: 0.3804787953458826  loss: 474859.04490483605\n",
      "episode: 823   score: 1084  move: 119   memory length: 5000   epsilon: 0.3800262926094331  loss: 539428.6551551177\n",
      "episode: 824   score: 264  move: 50   memory length: 5000   epsilon: 0.37983632600890255  loss: 1284563.2707840728\n",
      "episode: 825   score: 1492  move: 151   memory length: 5000   epsilon: 0.3792632031077012  loss: 426082.31855170144\n",
      "episode: 826   score: 1576  move: 155   memory length: 5000   epsilon: 0.3786757975627557  loss: 415808.49565973587\n",
      "episode: 827   score: 860  move: 114   memory length: 5000   epsilon: 0.37824435096758474  loss: 566053.1919286962\n",
      "episode: 828   score: 636  move: 88   memory length: 5000   epsilon: 0.3779116406891741  loss: 733995.3772630258\n",
      "episode: 829   score: 1152  move: 124   memory length: 5000   epsilon: 0.3774433183329747  loss: 521618.121359456\n",
      "episode: 830   score: 1768  move: 167   memory length: 5000   epsilon: 0.37681351087791715  loss: 388008.9610262431\n",
      "episode: 831   score: 872  move: 104   memory length: 5000   epsilon: 0.37642182657932044  loss: 623736.5221723777\n",
      "episode: 832   score: 1396  move: 143   memory length: 5000   epsilon: 0.3758839253688326  loss: 454335.8753257965\n",
      "episode: 833   score: 648  move: 91   memory length: 5000   epsilon: 0.3755420248755617  loss: 714658.8961022765\n",
      "episode: 834   score: 692  move: 90   memory length: 5000   epsilon: 0.3752041874136471  loss: 723305.5151674482\n",
      "episode: 835   score: 2892  move: 236   memory length: 5000   epsilon: 0.37431974516149485  loss: 276539.41118772153\n",
      "episode: 836   score: 1044  move: 112   memory length: 5000   epsilon: 0.3739007396387776  loss: 583446.1384401663\n",
      "episode: 837   score: 1612  move: 170   memory length: 5000   epsilon: 0.3732656451891525  loss: 385113.86064123263\n",
      "episode: 838   score: 732  move: 96   memory length: 5000   epsilon: 0.3729074803255871  loss: 682670.5476785103\n",
      "episode: 839   score: 856  move: 111   memory length: 5000   epsilon: 0.3724937805997502  loss: 591128.405928775\n",
      "episode: 840   score: 1168  move: 124   memory length: 5000   epsilon: 0.3720321722600812  loss: 529846.2511450552\n",
      "episode: 841   score: 784  move: 96   memory length: 5000   epsilon: 0.3716751909682399  loss: 685084.0789142052\n",
      "episode: 842   score: 1420  move: 146   memory length: 5000   epsilon: 0.37113293841884504  loss: 451139.88931350183\n",
      "episode: 843   score: 2208  move: 182   memory length: 5000   epsilon: 0.370458087397377  loss: 362606.62193946\n",
      "episode: 844   score: 752  move: 98   memory length: 5000   epsilon: 0.37009521449412625  loss: 674111.196004634\n",
      "episode: 845   score: 700  move: 93   memory length: 5000   epsilon: 0.3697511842233661  loss: 711064.5842211733\n",
      "episode: 846   score: 788  move: 99   memory length: 5000   epsilon: 0.3693853098593052  loss: 668672.7024309948\n",
      "episode: 847   score: 4704  move: 321   memory length: 5000   epsilon: 0.3682014781618999  loss: 206901.51526464778\n",
      "Weights save... Top reward = 520\n",
      "episode: 848   score: 376  move: 67   memory length: 5000   epsilon: 0.3679548645632434  loss: 991970.7362559873\n",
      "episode: 849   score: 1356  move: 139   memory length: 5000   epsilon: 0.3674437600459078  loss: 478837.74656482396\n",
      "episode: 850   score: 868  move: 90   memory length: 5000   epsilon: 0.3671132077799359  loss: 740239.0798036787\n",
      "episode: 851   score: 656  move: 87   memory length: 5000   epsilon: 0.366793956587316  loss: 766456.9949276365\n",
      "episode: 852   score: 556  move: 78   memory length: 5000   epsilon: 0.3665079674215055  loss: 855606.6649563619\n",
      "episode: 853   score: 1144  move: 134   memory length: 5000   epsilon: 0.36601717319675736  loss: 498751.6630120633\n",
      "episode: 854   score: 1236  move: 124   memory length: 5000   epsilon: 0.3655635909132152  loss: 539683.1738009606\n",
      "episode: 855   score: 1360  move: 135   memory length: 5000   epsilon: 0.36507041057121187  loss: 496377.17934991344\n",
      "episode: 856   score: 712  move: 92   memory length: 5000   epsilon: 0.36473469856612656  loss: 729052.335372137\n",
      "episode: 857   score: 888  move: 108   memory length: 5000   epsilon: 0.36434099576094275  loss: 621720.3007893385\n",
      "episode: 858   score: 1140  move: 136   memory length: 5000   epsilon: 0.3638458263223995  loss: 494395.02323344175\n",
      "episode: 859   score: 1000  move: 105   memory length: 5000   epsilon: 0.36346398679639486  loss: 641043.7878036136\n",
      "episode: 860   score: 608  move: 82   memory length: 5000   epsilon: 0.36316606700143106  loss: 821539.930318181\n",
      "episode: 861   score: 828  move: 98   memory length: 5000   epsilon: 0.3628103368133798  loss: 688083.8080225185\n",
      "episode: 862   score: 1528  move: 150   memory length: 5000   epsilon: 0.3622665265487699  loss: 450237.71143404645\n",
      "episode: 863   score: 2024  move: 188   memory length: 5000   epsilon: 0.3615861018763338  loss: 359930.264498873\n",
      "episode: 864   score: 564  move: 78   memory length: 5000   epsilon: 0.36130417327367487  loss: 868264.6125005576\n",
      "episode: 865   score: 900  move: 110   memory length: 5000   epsilon: 0.36090695520697125  loss: 616396.9828454105\n",
      "episode: 866   score: 552  move: 76   memory length: 5000   epsilon: 0.3606327687541303  loss: 892867.2468529249\n",
      "episode: 867   score: 368  move: 66   memory length: 5000   epsilon: 0.3603948284659825  loss: 1028867.3102965499\n",
      "episode: 868   score: 780  move: 97   memory length: 5000   epsilon: 0.3600454132290799  loss: 700787.1992051036\n",
      "episode: 869   score: 1644  move: 167   memory length: 5000   epsilon: 0.35944463617356737  loss: 407773.18547023844\n",
      "episode: 870   score: 612  move: 84   memory length: 5000   epsilon: 0.3591428279473407  loss: 811412.9919116156\n",
      "episode: 871   score: 1148  move: 124   memory length: 5000   epsilon: 0.3586977646116635  loss: 550398.8875871781\n",
      "episode: 872   score: 2232  move: 188   memory length: 5000   epsilon: 0.35802404294238627  loss: 363748.8957023824\n",
      "episode: 873   score: 276  move: 53   memory length: 5000   epsilon: 0.35783433952695487  loss: 1291014.6198123717\n",
      "episode: 874   score: 1332  move: 135   memory length: 5000   epsilon: 0.3573515866863132  loss: 507565.74112201267\n",
      "episode: 875   score: 916  move: 111   memory length: 5000   epsilon: 0.35695514450899213  loss: 618043.065418862\n",
      "episode: 876   score: 1548  move: 160   memory length: 5000   epsilon: 0.3563844700856865  loss: 429502.2731427431\n",
      "episode: 877   score: 524  move: 80   memory length: 5000   epsilon: 0.3560994750978369  loss: 859735.3485208988\n",
      "episode: 878   score: 1212  move: 126   memory length: 5000   epsilon: 0.3556510700716776  loss: 546589.1853455135\n",
      "episode: 879   score: 2328  move: 191   memory length: 5000   epsilon: 0.35497242145034424  loss: 361312.7083682115\n",
      "episode: 880   score: 708  move: 95   memory length: 5000   epsilon: 0.35463535609603214  loss: 727171.0036439996\n",
      "episode: 881   score: 1428  move: 153   memory length: 5000   epsilon: 0.3540931761637182  loss: 452260.43601393857\n",
      "episode: 882   score: 652  move: 89   memory length: 5000   epsilon: 0.35377817185961813  loss: 778234.1939647974\n",
      "episode: 883   score: 1668  move: 175   memory length: 5000   epsilon: 0.3531595983756585  loss: 396539.2763988604\n",
      "episode: 884   score: 2304  move: 190   memory length: 5000   epsilon: 0.35248922883962414  loss: 365980.1686309212\n",
      "episode: 885   score: 1616  move: 161   memory length: 5000   epsilon: 0.35192217494679334  loss: 432630.8530202593\n",
      "episode: 886   score: 1204  move: 126   memory length: 5000   epsilon: 0.3514790300305595  loss: 553567.7520765577\n",
      "episode: 887   score: 984  move: 114   memory length: 5000   epsilon: 0.3510785702394751  loss: 612579.9965324068\n",
      "episode: 888   score: 1224  move: 123   memory length: 5000   epsilon: 0.3506470069061218  loss: 568528.7252784357\n",
      "episode: 889   score: 892  move: 103   memory length: 5000   epsilon: 0.35028602462188624  loss: 679657.6249483349\n",
      "episode: 890   score: 692  move: 97   memory length: 5000   epsilon: 0.34994641021954354  loss: 722449.8115749162\n",
      "episode: 891   score: 936  move: 112   memory length: 5000   epsilon: 0.34955468768705006  loss: 626422.831033877\n",
      "episode: 892   score: 1068  move: 117   memory length: 5000   epsilon: 0.34914594581936576  loss: 600398.6933634506\n",
      "episode: 893   score: 1356  move: 140   memory length: 5000   epsilon: 0.348657481058009  loss: 502492.1697199413\n",
      "episode: 894   score: 2132  move: 202   memory length: 5000   epsilon: 0.3479539002841892  loss: 348994.42473800585\n",
      "episode: 895   score: 720  move: 95   memory length: 5000   epsilon: 0.34762349939218606  loss: 742806.0047641554\n",
      "episode: 896   score: 1440  move: 148   memory length: 5000   epsilon: 0.34710939457396706  loss: 477546.3370166727\n",
      "episode: 897   score: 760  move: 102   memory length: 5000   epsilon: 0.3467555217279685  loss: 693653.8383548587\n",
      "episode: 898   score: 756  move: 99   memory length: 5000   epsilon: 0.34641240191818784  loss: 715397.6017630605\n",
      "episode: 899   score: 380  move: 64   memory length: 5000   epsilon: 0.3461907678032707  loss: 1107356.2458565831\n",
      "episode: 900   score: 1276  move: 128   memory length: 5000   epsilon: 0.34574792488619616  loss: 554440.75208655\n",
      "episode: 901   score: 540  move: 80   memory length: 5000   epsilon: 0.3454714357742315  loss: 887881.9356619358\n",
      "episode: 902   score: 1444  move: 151   memory length: 5000   epsilon: 0.3449501649583683  loss: 471141.1874811286\n",
      "episode: 903   score: 2828  move: 232   memory length: 5000   epsilon: 0.344150804195884  loss: 307402.89899636956\n",
      "episode: 904   score: 1424  move: 149   memory length: 5000   epsilon: 0.3436383987724431  loss: 479408.80595461954\n",
      "episode: 905   score: 784  move: 101   memory length: 5000   epsilon: 0.34329149746982235  loss: 708001.3297350666\n",
      "episode: 906   score: 1260  move: 137   memory length: 5000   epsilon: 0.34282150778478354  loss: 522725.6635191145\n",
      "episode: 907   score: 1484  move: 155   memory length: 5000   epsilon: 0.34229054339659803  loss: 462778.74801707116\n",
      "episode: 908   score: 1484  move: 154   memory length: 5000   epsilon: 0.3417638190080217  loss: 466543.09671369777\n",
      "episode: 909   score: 1052  move: 112   memory length: 5000   epsilon: 0.34138125589325075  loss: 642258.0093273775\n",
      "episode: 910   score: 2476  move: 216   memory length: 5000   epsilon: 0.3406446645026517  loss: 333789.27425139036\n",
      "episode: 911   score: 492  move: 73   memory length: 5000   epsilon: 0.3403960833978005  loss: 988419.4345321133\n",
      "episode: 912   score: 824  move: 108   memory length: 5000   epsilon: 0.34002865223911394  loss: 668820.6483981168\n",
      "episode: 913   score: 3384  move: 281   memory length: 5000   epsilon: 0.3390745081558731  loss: 257814.00842682915\n",
      "episode: 914   score: 624  move: 86   memory length: 5000   epsilon: 0.3387830279758994  loss: 843163.2232355961\n",
      "episode: 915   score: 1208  move: 125   memory length: 5000   epsilon: 0.3383598116401626  loss: 580866.9840314026\n",
      "episode: 916   score: 1344  move: 135   memory length: 5000   epsilon: 0.3379033318052643  loss: 538604.1343475624\n",
      "episode: 917   score: 1436  move: 147   memory length: 5000   epsilon: 0.33740697633638267  loss: 495411.5092095875\n",
      "episode: 918   score: 752  move: 101   memory length: 5000   epsilon: 0.33706636562459225  loss: 721792.6941853514\n",
      "episode: 919   score: 736  move: 99   memory length: 5000   epsilon: 0.33673283338066345  loss: 737135.6453831606\n",
      "episode: 920   score: 940  move: 109   memory length: 5000   epsilon: 0.33636599272255324  loss: 670280.6045637568\n",
      "episode: 921   score: 1424  move: 145   memory length: 5000   epsilon: 0.3358786130318745  loss: 504642.36617550027\n",
      "episode: 922   score: 3060  move: 251   memory length: 5000   epsilon: 0.3350366106581892  loss: 292316.24220228766\n",
      "episode: 923   score: 1012  move: 121   memory length: 5000   epsilon: 0.3346314594994185  loss: 607168.9095634586\n",
      "episode: 924   score: 876  move: 113   memory length: 5000   epsilon: 0.33425353762664584  loss: 650937.0017261674\n",
      "episode: 925   score: 1056  move: 124   memory length: 5000   epsilon: 0.3338393180381095  loss: 593954.6313451029\n",
      "episode: 926   score: 564  move: 75   memory length: 5000   epsilon: 0.33358903116745414  loss: 982775.9853147888\n",
      "episode: 927   score: 2456  move: 211   memory length: 5000   epsilon: 0.3328858968635775  loss: 350108.0090844936\n",
      "episode: 928   score: 1408  move: 142   memory length: 5000   epsilon: 0.3324135319866415  loss: 521031.2343343009\n",
      "episode: 929   score: 1944  move: 180   memory length: 5000   epsilon: 0.33181572282966826  loss: 411844.90823340946\n",
      "episode: 930   score: 744  move: 100   memory length: 5000   epsilon: 0.33148407130198126  loss: 742152.170387764\n",
      "episode: 931   score: 736  move: 101   memory length: 5000   epsilon: 0.33114943973419547  loss: 735633.1532818256\n",
      "episode: 932   score: 704  move: 94   memory length: 5000   epsilon: 0.3308383039618885  loss: 791229.8062103352\n",
      "episode: 933   score: 568  move: 78   memory length: 5000   epsilon: 0.3305803494103781  loss: 954327.9600840348\n",
      "episode: 934   score: 788  move: 102   memory length: 5000   epsilon: 0.3302433276791726  loss: 730590.8929744421\n",
      "episode: 935   score: 616  move: 84   memory length: 5000   epsilon: 0.3299660383752866  loss: 887957.4518907184\n",
      "episode: 936   score: 1048  move: 126   memory length: 5000   epsilon: 0.3295505409078197  loss: 592810.262975935\n",
      "episode: 937   score: 768  move: 104   memory length: 5000   epsilon: 0.3292079847925497  loss: 719024.1035152215\n",
      "episode: 938   score: 1072  move: 118   memory length: 5000   epsilon: 0.3288197465349228  loss: 634499.0900570174\n",
      "episode: 939   score: 576  move: 79   memory length: 5000   epsilon: 0.3285600802185277  loss: 948539.3120374558\n",
      "episode: 940   score: 656  move: 90   memory length: 5000   epsilon: 0.3282645076960541  loss: 833410.9588699765\n",
      "episode: 941   score: 2744  move: 233   memory length: 5000   epsilon: 0.32750053794366  loss: 322730.48641019827\n",
      "episode: 942   score: 1352  move: 137   memory length: 5000   epsilon: 0.3270521671689317  loss: 549665.8152979552\n",
      "episode: 943   score: 236  move: 47   memory length: 5000   epsilon: 0.3268984879993996  loss: 1603014.2695861978\n",
      "episode: 944   score: 1156  move: 126   memory length: 5000   epsilon: 0.3264868532307088  loss: 598789.0911270928\n",
      "episode: 945   score: 312  move: 57   memory length: 5000   epsilon: 0.32630080782211807  loss: 1324506.2519234775\n",
      "episode: 946   score: 2704  move: 225   memory length: 5000   epsilon: 0.3255674526716698  loss: 336402.580163659\n",
      "episode: 947   score: 1016  move: 107   memory length: 5000   epsilon: 0.3252192800620116  loss: 708255.4669921376\n",
      "episode: 948   score: 748  move: 100   memory length: 5000   epsilon: 0.3248942217129192  loss: 758701.7102840042\n",
      "episode: 949   score: 512  move: 74   memory length: 5000   epsilon: 0.32465388772172477  loss: 1026164.5003780159\n",
      "episode: 950   score: 1824  move: 169   memory length: 5000   epsilon: 0.32410568327368694  loss: 450222.3146652357\n",
      "episode: 951   score: 400  move: 67   memory length: 5000   epsilon: 0.32388860411013726  loss: 1136532.2991372293\n",
      "episode: 952   score: 1172  move: 126   memory length: 5000   epsilon: 0.3234807594258427  loss: 605232.4037879157\n",
      "episode: 953   score: 1144  move: 124   memory length: 5000   epsilon: 0.323079889870295  loss: 615903.5841381012\n",
      "episode: 954   score: 1404  move: 146   memory length: 5000   epsilon: 0.3226085350470583  loss: 524001.5582360307\n",
      "episode: 955   score: 1188  move: 130   memory length: 5000   epsilon: 0.3221894143433757  loss: 589377.7003212855\n",
      "episode: 956   score: 2012  move: 188   memory length: 5000   epsilon: 0.3215842642379939  loss: 408429.2516704519\n",
      "episode: 957   score: 1136  move: 122   memory length: 5000   epsilon: 0.32119216870205447  loss: 630269.8234034366\n",
      "episode: 958   score: 1440  move: 154   memory length: 5000   epsilon: 0.3206979109671008  loss: 500179.89947442885\n",
      "episode: 959   score: 1484  move: 154   memory length: 5000   epsilon: 0.32020441380706877  loss: 501059.85746282106\n",
      "episode: 960   score: 1240  move: 128   memory length: 5000   epsilon: 0.3197948123102692  loss: 603716.9553362429\n",
      "episode: 961   score: 676  move: 93   memory length: 5000   epsilon: 0.3194975399015536  loss: 831786.2818028029\n",
      "episode: 962   score: 1672  move: 157   memory length: 5000   epsilon: 0.3189963198185265  loss: 493574.0814474555\n",
      "episode: 963   score: 1500  move: 149   memory length: 5000   epsilon: 0.31852136685505855  loss: 520913.8280776107\n",
      "episode: 964   score: 2364  move: 199   memory length: 5000   epsilon: 0.31788813644209546  loss: 390871.37494734186\n",
      "episode: 965   score: 2392  move: 206   memory length: 5000   epsilon: 0.3172339576456292  loss: 378443.6486473639\n",
      "episode: 966   score: 1360  move: 145   memory length: 5000   epsilon: 0.3167742994414845  loss: 538519.2757195046\n",
      "episode: 967   score: 1236  move: 127   memory length: 5000   epsilon: 0.3163722494267405  loss: 615667.2441527899\n",
      "episode: 968   score: 368  move: 63   memory length: 5000   epsilon: 0.31617299668454135  loss: 1241946.6882966661\n",
      "episode: 969   score: 1600  move: 158   memory length: 5000   epsilon: 0.31567383529531157  loss: 496065.6057133976\n",
      "episode: 970   score: 680  move: 89   memory length: 5000   epsilon: 0.3153930091639324  loss: 881512.5757304416\n",
      "episode: 971   score: 756  move: 92   memory length: 5000   epsilon: 0.3151029795794185  loss: 853606.6001217469\n",
      "episode: 972   score: 612  move: 81   memory length: 5000   epsilon: 0.3148478482324465  loss: 970381.0597483788\n",
      "episode: 973   score: 736  move: 97   memory length: 5000   epsilon: 0.3145425923664104  loss: 811171.3982615126\n",
      "episode: 974   score: 500  move: 73   memory length: 5000   epsilon: 0.3143130589162174  loss: 1078731.0081062317\n",
      "episode: 975   score: 1124  move: 129   memory length: 5000   epsilon: 0.31390785445725955  loss: 611310.8632657842\n",
      "episode: 976   score: 1536  move: 160   memory length: 5000   epsilon: 0.31340600097071036  loss: 493712.5181302309\n",
      "episode: 977   score: 760  move: 96   memory length: 5000   epsilon: 0.31310527407814703  loss: 823693.2691601515\n",
      "episode: 978   score: 984  move: 116   memory length: 5000   epsilon: 0.3127422807220985  loss: 682550.3375582531\n",
      "episode: 979   score: 1000  move: 105   memory length: 5000   epsilon: 0.3124140720260154  loss: 754931.6844623748\n",
      "episode: 980   score: 1400  move: 143   memory length: 5000   epsilon: 0.3119676369479984  loss: 555158.7680221504\n",
      "episode: 981   score: 1228  move: 127   memory length: 5000   epsilon: 0.31157168755041265  loss: 625951.3878367567\n",
      "episode: 982   score: 2328  move: 192   memory length: 5000   epsilon: 0.3109740408465139  loss: 414876.1354339321\n",
      "episode: 983   score: 808  move: 103   memory length: 5000   epsilon: 0.3106539008841248  loss: 774182.8961734587\n",
      "episode: 984   score: 992  move: 104   memory length: 5000   epsilon: 0.31033098715687873  loss: 767559.6031349256\n",
      "episode: 985   score: 1456  move: 149   memory length: 5000   epsilon: 0.30986893598936105  loss: 536566.7923638517\n",
      "episode: 986   score: 1376  move: 143   memory length: 5000   epsilon: 0.30942613787301426  loss: 559882.1397759764\n",
      "episode: 987   score: 1068  move: 116   memory length: 5000   epsilon: 0.3090674098619119  loss: 690998.2846489281\n",
      "episode: 988   score: 1576  move: 162   memory length: 5000   epsilon: 0.3085671234978699  loss: 495594.58771724463\n",
      "episode: 989   score: 1584  move: 157   memory length: 5000   epsilon: 0.30808305079012144  loss: 512174.271295754\n",
      "episode: 990   score: 1336  move: 139   memory length: 5000   epsilon: 0.3076551106970876  loss: 579299.7399141875\n",
      "episode: 991   score: 1568  move: 164   memory length: 5000   epsilon: 0.3071509673054024  loss: 491754.5477774318\n",
      "episode: 992   score: 528  move: 80   memory length: 5000   epsilon: 0.30690534356603427  loss: 1008849.4433599949\n",
      "episode: 993   score: 2312  move: 217   memory length: 5000   epsilon: 0.3062400777186662  loss: 372680.82881939795\n",
      "episode: 994   score: 1152  move: 116   memory length: 5000   epsilon: 0.30588504341304823  loss: 697922.9926646331\n",
      "episode: 995   score: 620  move: 85   memory length: 5000   epsilon: 0.3056251502969025  loss: 953257.7147035935\n",
      "episode: 996   score: 2452  move: 210   memory length: 5000   epsilon: 0.3049840077108999  loss: 386617.14058338344\n",
      "episode: 997   score: 1336  move: 138   memory length: 5000   epsilon: 0.3045634179509909  loss: 589112.2362223363\n",
      "episode: 998   score: 1324  move: 137   memory length: 5000   epsilon: 0.3041464496720437  loss: 594188.4029776301\n",
      "episode: 999   score: 1068  move: 116   memory length: 5000   epsilon: 0.30379384257904063  loss: 702531.4875166334\n",
      "episode: 1000   score: 764  move: 98   memory length: 5000   epsilon: 0.3034962689603331  loss: 832347.0920296883\n",
      "episode: 1001   score: 832  move: 99   memory length: 5000   epsilon: 0.3031959548325123  loss: 824734.116085669\n",
      "episode: 1002   score: 564  move: 79   memory length: 5000   epsilon: 0.30295652341889756  loss: 1034325.9283978909\n",
      "episode: 1003   score: 1424  move: 146   memory length: 5000   epsilon: 0.3025145274203166  loss: 560458.4981931137\n",
      "episode: 1004   score: 872  move: 109   memory length: 5000   epsilon: 0.30218496458198957  loss: 751469.2448225459\n",
      "episode: 1005   score: 360  move: 59   memory length: 5000   epsilon: 0.30200672714691207  loss: 1389057.6114293116\n",
      "episode: 1006   score: 484  move: 78   memory length: 5000   epsilon: 0.30177125256938775  loss: 1051462.448546043\n",
      "episode: 1007   score: 1476  move: 154   memory length: 5000   epsilon: 0.301306880177085  loss: 533350.8819850823\n",
      "episode: 1008   score: 812  move: 105   memory length: 5000   epsilon: 0.3009906724099885  loss: 783039.8470472427\n",
      "episode: 1009   score: 1184  move: 128   memory length: 5000   epsilon: 0.300605648891805  loss: 643147.1447722018\n",
      "episode: 1010   score: 616  move: 86   memory length: 5000   epsilon: 0.30034723787436607  loss: 958036.0199871063\n",
      "episode: 1011   score: 900  move: 115   memory length: 5000   epsilon: 0.30000203535429004  loss: 717241.7873754419\n",
      "episode: 1012   score: 2452  move: 210   memory length: 5000   epsilon: 0.29937268897829267  loss: 393581.9578422365\n",
      "episode: 1013   score: 1012  move: 121   memory length: 5000   epsilon: 0.29901066528301484  loss: 683857.2156736831\n",
      "episode: 1014   score: 1488  move: 159   memory length: 5000   epsilon: 0.2985356137160329  loss: 521206.9255951935\n",
      "episode: 1015   score: 1424  move: 151   memory length: 5000   epsilon: 0.29808516286304937  loss: 549612.5352331755\n",
      "episode: 1016   score: 1028  move: 111   memory length: 5000   epsilon: 0.29775447024716317  loss: 748428.4299384109\n",
      "episode: 1017   score: 824  move: 104   memory length: 5000   epsilon: 0.2974449650211931  loss: 799587.7120351425\n",
      "episode: 1018   score: 1556  move: 156   memory length: 5000   epsilon: 0.29698131030219516  loss: 533830.2908729407\n",
      "episode: 1019   score: 328  move: 61   memory length: 5000   epsilon: 0.2968002060398047  loss: 1366001.3618187201\n",
      "episode: 1020   score: 1460  move: 152   memory length: 5000   epsilon: 0.29634941016430233  loss: 549010.8847332252\n",
      "episode: 1021   score: 652  move: 89   memory length: 5000   epsilon: 0.29608577520603885  loss: 938412.595529149\n",
      "episode: 1022   score: 1152  move: 121   memory length: 5000   epsilon: 0.29572772629107225  loss: 691048.2880946703\n",
      "episode: 1023   score: 1444  move: 151   memory length: 5000   epsilon: 0.2952815121697468  loss: 554565.5436818963\n",
      "episode: 1024   score: 1072  move: 121   memory length: 5000   epsilon: 0.29492443582939043  loss: 692875.5852733328\n",
      "episode: 1025   score: 776  move: 105   memory length: 5000   epsilon: 0.2946149261452404  loss: 799272.7815780276\n",
      "episode: 1026   score: 792  move: 106   memory length: 5000   epsilon: 0.2943027982199118  loss: 792547.7430254738\n",
      "episode: 1027   score: 1692  move: 168   memory length: 5000   epsilon: 0.2938087821385216  loss: 500873.1678427969\n",
      "episode: 1028   score: 1524  move: 161   memory length: 5000   epsilon: 0.2933361282245056  loss: 523441.62889992376\n",
      "episode: 1029   score: 716  move: 96   memory length: 5000   epsilon: 0.2930546592607839  loss: 878625.8752932945\n",
      "episode: 1030   score: 1000  move: 117   memory length: 5000   epsilon: 0.2927119841001318  loss: 721707.1085308434\n",
      "episode: 1031   score: 752  move: 101   memory length: 5000   epsilon: 0.2924164927669752  loss: 836815.8392532273\n",
      "episode: 1032   score: 672  move: 88   memory length: 5000   epsilon: 0.292159278158293  loss: 961224.9182328745\n",
      "episode: 1033   score: 1704  move: 164   memory length: 5000   epsilon: 0.29168052723142185  loss: 516563.46944178606\n",
      "episode: 1034   score: 3108  move: 257   memory length: 5000   epsilon: 0.2909318669736352  loss: 330422.95043952734\n",
      "episode: 1035   score: 700  move: 93   memory length: 5000   epsilon: 0.2906614247602588  loss: 913882.3415010924\n",
      "episode: 1036   score: 1852  move: 186   memory length: 5000   epsilon: 0.29012129428661126  loss: 457714.9323057154\n",
      "episode: 1037   score: 764  move: 100   memory length: 5000   epsilon: 0.2898313165554655  loss: 852082.7703868485\n",
      "episode: 1038   score: 832  move: 84   memory length: 5000   epsilon: 0.2895879592571463  loss: 1015104.8006183533\n",
      "episode: 1039   score: 952  move: 119   memory length: 5000   epsilon: 0.2892435528260664  loss: 717273.2373456233\n",
      "episode: 1040   score: 684  move: 89   memory length: 5000   epsilon: 0.28898623929898704  loss: 959796.1738801163\n",
      "episode: 1041   score: 900  move: 108   memory length: 5000   epsilon: 0.2886743010778118  loss: 791685.0283569406\n",
      "episode: 1042   score: 1176  move: 133   memory length: 5000   epsilon: 0.28829061754506696  loss: 643598.3408624462\n",
      "episode: 1043   score: 1304  move: 138   memory length: 5000   epsilon: 0.287893048890476  loss: 621026.4829357258\n",
      "episode: 1044   score: 2208  move: 193   memory length: 5000   epsilon: 0.28733794837491905  loss: 444802.68517459615\n",
      "episode: 1045   score: 284  move: 54   memory length: 5000   epsilon: 0.28718282699373154  loss: 1590500.6435657784\n",
      "episode: 1046   score: 1596  move: 160   memory length: 5000   epsilon: 0.2867236995747855  loss: 537557.9428725481\n",
      "episode: 1047   score: 600  move: 84   memory length: 5000   epsilon: 0.28648295159171083  loss: 1024677.6945174536\n",
      "episode: 1048   score: 1040  move: 108   memory length: 5000   epsilon: 0.2861737154753709  loss: 797707.6944186246\n",
      "episode: 1049   score: 416  move: 70   memory length: 5000   epsilon: 0.28597346296982895  loss: 1231500.2554925645\n",
      "episode: 1050   score: 1288  move: 133   memory length: 5000   epsilon: 0.2855933691820067  loss: 648936.9723089978\n",
      "episode: 1051   score: 484  move: 78   memory length: 5000   epsilon: 0.28537069209601174  loss: 1107291.3121481186\n",
      "episode: 1052   score: 812  move: 104   memory length: 5000   epsilon: 0.2850740593688218  loss: 831247.3414220443\n",
      "episode: 1053   score: 568  move: 83   memory length: 5000   epsilon: 0.28483754488406154  loss: 1042326.4027396053\n",
      "episode: 1054   score: 1384  move: 143   memory length: 5000   epsilon: 0.28443051625456395  loss: 605751.766894494\n",
      "episode: 1055   score: 1612  move: 160   memory length: 5000   epsilon: 0.28397578903370474  loss: 542150.9951165437\n",
      "episode: 1056   score: 1684  move: 158   memory length: 5000   epsilon: 0.2835274593191233  loss: 549790.0437379909\n",
      "episode: 1057   score: 588  move: 82   memory length: 5000   epsilon: 0.2832950609368476  loss: 1060135.3615546343\n",
      "episode: 1058   score: 1344  move: 139   memory length: 5000   epsilon: 0.2829015523864021  loss: 626165.4175166123\n",
      "episode: 1059   score: 1024  move: 111   memory length: 5000   epsilon: 0.28258770431191743  loss: 784910.9964271408\n",
      "episode: 1060   score: 620  move: 86   memory length: 5000   epsilon: 0.28234478214310244  loss: 1013863.4835342141\n",
      "episode: 1061   score: 688  move: 89   memory length: 5000   epsilon: 0.2820936058211554  loss: 980465.9395075166\n",
      "episode: 1062   score: 740  move: 99   memory length: 5000   epsilon: 0.28181446995076664  loss: 882197.8623961246\n",
      "episode: 1063   score: 1372  move: 140   memory length: 5000   epsilon: 0.281420203772225  loss: 624590.7314314978\n",
      "episode: 1064   score: 964  move: 115   memory length: 5000   epsilon: 0.2810967549393673  loss: 761104.8522101693\n",
      "episode: 1065   score: 664  move: 91   memory length: 5000   epsilon: 0.2808410719673533  loss: 962546.7362133068\n",
      "episode: 1066   score: 860  move: 104   memory length: 5000   epsilon: 0.28054914761985755  loss: 842935.9745059747\n",
      "episode: 1067   score: 1152  move: 122   memory length: 5000   epsilon: 0.2802070846502841  loss: 719300.9037247017\n",
      "episode: 1068   score: 444  move: 73   memory length: 5000   epsilon: 0.28000260709948743  loss: 1202852.1208582316\n",
      "episode: 1069   score: 1040  move: 113   memory length: 5000   epsilon: 0.27968638127357576  loss: 777800.9013900419\n",
      "episode: 1070   score: 1352  move: 141   memory length: 5000   epsilon: 0.2792922993985804  loss: 624060.4674129892\n",
      "episode: 1071   score: 1136  move: 126   memory length: 5000   epsilon: 0.278940610953144  loss: 699062.1741218264\n",
      "episode: 1072   score: 320  move: 59   memory length: 5000   epsilon: 0.2787760837103541  loss: 1493650.6482060966\n",
      "episode: 1073   score: 1328  move: 138   memory length: 5000   epsilon: 0.27839163612244183  loss: 639313.5545295217\n",
      "episode: 1074   score: 732  move: 97   memory length: 5000   epsilon: 0.2781217258135136  loss: 910282.2188511878\n",
      "episode: 1075   score: 744  move: 99   memory length: 5000   epsilon: 0.27784652017819594  loss: 892630.2337250757\n",
      "episode: 1076   score: 1508  move: 158   memory length: 5000   epsilon: 0.2774078671102261  loss: 560025.9854272045\n",
      "episode: 1077   score: 920  move: 115   memory length: 5000   epsilon: 0.27708902983543354  loss: 770165.2528531613\n",
      "episode: 1078   score: 1328  move: 138   memory length: 5000   epsilon: 0.27670690878781984  loss: 642530.6232296764\n",
      "episode: 1079   score: 1008  move: 108   memory length: 5000   epsilon: 0.2764082251511056  loss: 821715.4570591184\n",
      "episode: 1080   score: 1300  move: 143   memory length: 5000   epsilon: 0.2760132418945587  loss: 621322.8559695424\n",
      "episode: 1081   score: 776  move: 101   memory length: 5000   epsilon: 0.2757346078609473  loss: 880421.742474131\n",
      "episode: 1082   score: 616  move: 84   memory length: 5000   epsilon: 0.27550308688516134  loss: 1059323.5418848763\n",
      "episode: 1083   score: 1056  move: 115   memory length: 5000   epsilon: 0.27518643885951466  loss: 774486.9408374621\n",
      "episode: 1084   score: 2796  move: 228   memory length: 5000   epsilon: 0.27455972537021656  loss: 391359.94943647215\n",
      "episode: 1085   score: 684  move: 90   memory length: 5000   epsilon: 0.27431273154630614  loss: 992197.3739653269\n",
      "episode: 1086   score: 508  move: 73   memory length: 5000   epsilon: 0.2741125553246057  loss: 1224009.003827918\n",
      "episode: 1087   score: 1064  move: 116   memory length: 5000   epsilon: 0.2737947675240479  loss: 771026.2528335637\n",
      "episode: 1088   score: 2072  move: 196   memory length: 5000   epsilon: 0.2732586526633168  loss: 457077.53383568354\n",
      "episode: 1089   score: 912  move: 110   memory length: 5000   epsilon: 0.27295823190499197  loss: 815208.3189743388\n",
      "episode: 1090   score: 1004  move: 105   memory length: 5000   epsilon: 0.27267177474553184  loss: 854798.8401403881\n",
      "episode: 1091   score: 1148  move: 122   memory length: 5000   epsilon: 0.2723393163589009  loss: 736462.6872034854\n",
      "episode: 1092   score: 596  move: 82   memory length: 5000   epsilon: 0.27211608853926095  loss: 1096478.6890104807\n",
      "episode: 1093   score: 1076  move: 112   memory length: 5000   epsilon: 0.27181148760545515  loss: 803547.2250967367\n",
      "episode: 1094   score: 816  move: 103   memory length: 5000   epsilon: 0.27153166450773925  loss: 874516.2171514196\n",
      "episode: 1095   score: 1384  move: 140   memory length: 5000   epsilon: 0.27115178425624914  loss: 644168.7013577325\n",
      "episode: 1096   score: 692  move: 91   memory length: 5000   epsilon: 0.27090514713629893  loss: 991798.2127908979\n",
      "episode: 1097   score: 1232  move: 136   memory length: 5000   epsilon: 0.27053696471607486  loss: 664385.7062038253\n",
      "episode: 1098   score: 1768  move: 182   memory length: 5000   epsilon: 0.27004503277448744  loss: 497245.31207453547\n",
      "episode: 1099   score: 532  move: 74   memory length: 5000   epsilon: 0.2698452723718965  loss: 1223734.4172547315\n",
      "episode: 1100   score: 824  move: 109   memory length: 5000   epsilon: 0.269551299799305  loss: 831580.4332629913\n",
      "episode: 1101   score: 1416  move: 144   memory length: 5000   epsilon: 0.2691634233262963  loss: 630240.6430127091\n",
      "episode: 1102   score: 3464  move: 272   memory length: 5000   epsilon: 0.2684322899513393  loss: 334464.56802464934\n",
      "episode: 1103   score: 720  move: 94   memory length: 5000   epsilon: 0.2681800808945669  loss: 968659.0966091156\n",
      "episode: 1104   score: 1032  move: 124   memory length: 5000   epsilon: 0.26784774202524514  loss: 735147.2692961232\n",
      "episode: 1105   score: 1564  move: 164   memory length: 5000   epsilon: 0.2674088295403723  loss: 556695.8723101034\n",
      "episode: 1106   score: 1672  move: 170   memory length: 5000   epsilon: 0.266954618447915  loss: 537921.469861311\n",
      "episode: 1107   score: 2804  move: 224   memory length: 5000   epsilon: 0.26635730635532995  loss: 409119.75958151475\n",
      "episode: 1108   score: 1404  move: 145   memory length: 5000   epsilon: 0.26597136620564144  loss: 632923.2280249497\n",
      "episode: 1109   score: 804  move: 92   memory length: 5000   epsilon: 0.2657267838509542  loss: 998455.5559628113\n",
      "episode: 1110   score: 836  move: 104   memory length: 5000   epsilon: 0.2654505702706383  loss: 884160.960782748\n",
      "episode: 1111   score: 1144  move: 124   memory length: 5000   epsilon: 0.26512161391381145  loss: 742480.4557083191\n",
      "episode: 1112   score: 1788  move: 173   memory length: 5000   epsilon: 0.26466334774494027  loss: 533100.819757649\n",
      "episode: 1113   score: 1100  move: 121   memory length: 5000   epsilon: 0.2643432971635657  loss: 763178.5717517758\n",
      "episode: 1114   score: 812  move: 103   memory length: 5000   epsilon: 0.26407116238028466  loss: 897481.8947915753\n",
      "episode: 1115   score: 2332  move: 196   memory length: 5000   epsilon: 0.2635540872158363  loss: 472543.93432907184\n",
      "episode: 1116   score: 620  move: 87   memory length: 5000   epsilon: 0.26332489372761403  loss: 1065531.7982825355\n",
      "episode: 1117   score: 1284  move: 132   memory length: 5000   epsilon: 0.2629775324399728  loss: 703234.7098034079\n",
      "episode: 1118   score: 956  move: 114   memory length: 5000   epsilon: 0.26267790737360186  loss: 815239.5772283789\n",
      "episode: 1119   score: 368  move: 60   memory length: 5000   epsilon: 0.2625203471141804  loss: 1549933.4015740077\n",
      "episode: 1120   score: 4448  move: 306   memory length: 5000   epsilon: 0.2617182586627688  loss: 304886.50880208984\n",
      "episode: 1121   score: 1404  move: 152   memory length: 5000   epsilon: 0.2613207471073588  loss: 614800.3558322756\n",
      "episode: 1122   score: 1172  move: 127   memory length: 5000   epsilon: 0.26098907875417265  loss: 736823.0447749641\n",
      "episode: 1123   score: 824  move: 104   memory length: 5000   epsilon: 0.2607177898505052  loss: 900785.5364622336\n",
      "episode: 1124   score: 2420  move: 208   memory length: 5000   epsilon: 0.2601760577356666  loss: 451352.6913159627\n",
      "episode: 1125   score: 3028  move: 250   memory length: 5000   epsilon: 0.2595264267202902  loss: 376489.4623267364\n",
      "episode: 1126   score: 3324  move: 282   memory length: 5000   epsilon: 0.2587955895075482  loss: 334746.7748348831\n",
      "episode: 1127   score: 964  move: 124   memory length: 5000   epsilon: 0.2584748802538423  loss: 762279.3458849076\n",
      "episode: 1128   score: 828  move: 105   memory length: 5000   epsilon: 0.2582036227084201  loss: 901197.4925068084\n",
      "episode: 1129   score: 672  move: 90   memory length: 5000   epsilon: 0.25797134282820755  loss: 1052402.1754593318\n",
      "episode: 1130   score: 1024  move: 113   memory length: 5000   epsilon: 0.2576799983946948  loss: 839208.5184387275\n",
      "episode: 1131   score: 1256  move: 131   memory length: 5000   epsilon: 0.2573426569169998  loss: 724892.9077121938\n",
      "episode: 1132   score: 716  move: 96   memory length: 5000   epsilon: 0.25709572527785174  loss: 990160.3550607761\n",
      "episode: 1133   score: 3108  move: 257   memory length: 5000   epsilon: 0.2564358342875642  loss: 370867.57161639916\n",
      "episode: 1134   score: 1336  move: 139   memory length: 5000   epsilon: 0.25607963431323694  loss: 686711.2631692406\n",
      "episode: 1135   score: 600  move: 81   memory length: 5000   epsilon: 0.25587229275740125  loss: 1179433.785173063\n",
      "episode: 1136   score: 564  move: 77   memory length: 5000   epsilon: 0.25567534594149827  loss: 1241688.7035770663\n",
      "episode: 1137   score: 528  move: 75   memory length: 5000   epsilon: 0.2554836603646903  loss: 1275755.141839447\n",
      "episode: 1138   score: 1164  move: 125   memory length: 5000   epsilon: 0.25516450370791754  loss: 766409.7928082581\n",
      "episode: 1139   score: 912  move: 110   memory length: 5000   epsilon: 0.25488397566990495  loss: 871907.301231419\n",
      "episode: 1140   score: 892  move: 109   memory length: 5000   epsilon: 0.2546063021076396  loss: 880927.4646776182\n",
      "episode: 1141   score: 908  move: 112   memory length: 5000   epsilon: 0.25432130125454394  loss: 858323.9393017973\n",
      "episode: 1142   score: 848  move: 102   memory length: 5000   epsilon: 0.25406202448451154  loss: 943437.4957319148\n",
      "episode: 1143   score: 2536  move: 218   memory length: 5000   epsilon: 0.2535087697716056  loss: 442422.3399608682\n",
      "episode: 1144   score: 736  move: 98   memory length: 5000   epsilon: 0.25326045163140054  loss: 985139.402958033\n",
      "episode: 1145   score: 1008  move: 118   memory length: 5000   epsilon: 0.25296177905658684  loss: 819147.8058033636\n",
      "episode: 1146   score: 780  move: 102   memory length: 5000   epsilon: 0.2527038882991399  loss: 948630.3491194856\n",
      "episode: 1147   score: 1584  move: 154   memory length: 5000   epsilon: 0.2523150218708288  loss: 629291.2942708251\n",
      "episode: 1148   score: 744  move: 99   memory length: 5000   epsilon: 0.25206535235762917  loss: 979834.6518772395\n",
      "episode: 1149   score: 840  move: 107   memory length: 5000   epsilon: 0.25179578532685076  loss: 907550.4282456514\n",
      "episode: 1150   score: 576  move: 83   memory length: 5000   epsilon: 0.25158688048800565  loss: 1170954.5038388264\n",
      "episode: 1151   score: 684  move: 90   memory length: 5000   epsilon: 0.2513605530265631  loss: 1080875.7957908206\n",
      "episode: 1152   score: 836  move: 99   memory length: 5000   epsilon: 0.2511118279746561  loss: 983625.6998391584\n",
      "episode: 1153   score: 1332  move: 138   memory length: 5000   epsilon: 0.25076553092048925  loss: 706685.1622970415\n",
      "episode: 1154   score: 396  move: 68   memory length: 5000   epsilon: 0.2505950674712868  loss: 1435189.492929178\n",
      "episode: 1155   score: 1512  move: 161   memory length: 5000   epsilon: 0.2501919320081082  loss: 607192.6090365818\n",
      "episode: 1156   score: 1500  move: 148   memory length: 5000   epsilon: 0.2498219199751188  loss: 661500.1514258771\n",
      "episode: 1157   score: 612  move: 84   memory length: 5000   epsilon: 0.24961215662646272  loss: 1166540.075837862\n",
      "episode: 1158   score: 2448  move: 207   memory length: 5000   epsilon: 0.24909599129684412  loss: 474410.668644062\n",
      "episode: 1159   score: 1568  move: 161   memory length: 5000   epsilon: 0.2486952674165191  loss: 610935.8159722986\n",
      "episode: 1160   score: 936  move: 115   memory length: 5000   epsilon: 0.24840943081735228  loss: 856285.5469558385\n",
      "episode: 1161   score: 1228  move: 126   memory length: 5000   epsilon: 0.2480966304761181  loss: 782475.44107313\n",
      "episode: 1162   score: 1560  move: 163   memory length: 5000   epsilon: 0.24769256035470386  loss: 605793.6947790275\n",
      "episode: 1163   score: 1280  move: 131   memory length: 5000   epsilon: 0.24736829392019333  loss: 754690.6712564075\n",
      "episode: 1164   score: 628  move: 86   memory length: 5000   epsilon: 0.24715564757522399  loss: 1150522.122975416\n",
      "episode: 1165   score: 1440  move: 149   memory length: 5000   epsilon: 0.24678765804067251  loss: 665031.9775043718\n",
      "episode: 1166   score: 1364  move: 135   memory length: 5000   epsilon: 0.24645471782282785  loss: 734948.7714605543\n",
      "episode: 1167   score: 2500  move: 207   memory length: 5000   epsilon: 0.24594508166415532  loss: 480263.7183479088\n",
      "episode: 1168   score: 1884  move: 180   memory length: 5000   epsilon: 0.2455027764997034  loss: 553266.2054793675\n",
      "episode: 1169   score: 2284  move: 192   memory length: 5000   epsilon: 0.24503186103775426  loss: 519651.92667684954\n",
      "episode: 1170   score: 1664  move: 169   memory length: 5000   epsilon: 0.2446181048462776  loss: 591351.3537317084\n",
      "episode: 1171   score: 1680  move: 172   memory length: 5000   epsilon: 0.24419772123756497  loss: 582005.0207942919\n",
      "episode: 1172   score: 552  move: 83   memory length: 5000   epsilon: 0.24399512020699066  loss: 1207035.257513437\n",
      "episode: 1173   score: 1412  move: 156   memory length: 5000   epsilon: 0.2436147826581994  loss: 643153.2111829367\n",
      "episode: 1174   score: 800  move: 105   memory length: 5000   epsilon: 0.2433591201044244  loss: 956492.6202394394\n",
      "episode: 1175   score: 596  move: 79   memory length: 5000   epsilon: 0.24316694135924677  loss: 1272227.5130362692\n",
      "episode: 1176   score: 1176  move: 128   memory length: 5000   epsilon: 0.2428558852374129  loss: 786130.5582214892\n",
      "episode: 1177   score: 544  move: 75   memory length: 5000   epsilon: 0.24267381069959795  loss: 1342583.2776971944\n",
      "episode: 1178   score: 1424  move: 145   memory length: 5000   epsilon: 0.24232218690482218  loss: 695370.6448837017\n",
      "episode: 1179   score: 2056  move: 192   memory length: 5000   epsilon: 0.2418573723466581  loss: 526099.8293626508\n",
      "episode: 1180   score: 944  move: 121   memory length: 5000   epsilon: 0.2415649004449428  loss: 835744.4708858837\n",
      "episode: 1181   score: 1456  move: 150   memory length: 5000   epsilon: 0.2412028229099275  loss: 675070.4679481252\n",
      "episode: 1182   score: 1212  move: 121   memory length: 5000   epsilon: 0.24091114253801615  loss: 837782.6307233385\n",
      "episode: 1183   score: 1388  move: 145   memory length: 5000   epsilon: 0.24056207277272595  loss: 700028.3808544554\n",
      "episode: 1184   score: 2648  move: 223   memory length: 5000   epsilon: 0.24002621437532717  loss: 456091.4125276745\n",
      "episode: 1185   score: 3088  move: 253   memory length: 5000   epsilon: 0.2394197125687461  loss: 402991.4689418657\n",
      "episode: 1186   score: 488  move: 79   memory length: 5000   epsilon: 0.23923064474210162  loss: 1291643.4400838055\n",
      "episode: 1187   score: 2472  move: 211   memory length: 5000   epsilon: 0.2387263977281391  loss: 484612.65394087875\n",
      "episode: 1188   score: 944  move: 97   memory length: 5000   epsilon: 0.23849494423816506  loss: 1055190.1774979818\n",
      "episode: 1189   score: 1480  move: 158   memory length: 5000   epsilon: 0.23811841787779067  loss: 648818.1680975081\n",
      "episode: 1190   score: 1672  move: 171   memory length: 5000   epsilon: 0.23771158129345107  loss: 600537.0652099297\n",
      "episode: 1191   score: 1144  move: 123   memory length: 5000   epsilon: 0.23741937433154583  loss: 835900.336245312\n",
      "episode: 1192   score: 764  move: 104   memory length: 5000   epsilon: 0.2371725853008349  loss: 989629.6554708114\n",
      "episode: 1193   score: 2548  move: 217   memory length: 5000   epsilon: 0.23665847623026806  loss: 475286.8034840421\n",
      "episode: 1194   score: 2368  move: 202   memory length: 5000   epsilon: 0.2361809062285234  loss: 511573.9755524928\n",
      "episode: 1195   score: 344  move: 57   memory length: 5000   epsilon: 0.23604632079953664  loss: 1813939.894962043\n",
      "episode: 1196   score: 2120  move: 202   memory length: 5000   epsilon: 0.23556998610985339  loss: 512900.2836114298\n",
      "episode: 1197   score: 720  move: 98   memory length: 5000   epsilon: 0.23533923945406032  loss: 1058242.1657318193\n",
      "episode: 1198   score: 2232  move: 187   memory length: 5000   epsilon: 0.23489956410248236  loss: 555621.2106862807\n",
      "episode: 1199   score: 588  move: 81   memory length: 5000   epsilon: 0.2347093715429812  loss: 1283786.143378599\n",
      "episode: 1200   score: 2448  move: 198   memory length: 5000   epsilon: 0.23424510444209562  loss: 526211.228049943\n",
      "episode: 1201   score: 1340  move: 141   memory length: 5000   epsilon: 0.2339150499376661  loss: 740020.6344744364\n",
      "episode: 1202   score: 1232  move: 137   memory length: 5000   epsilon: 0.23359480413648456  loss: 762688.1766229615\n",
      "episode: 1203   score: 1604  move: 169   memory length: 5000   epsilon: 0.23320036034415936  loss: 619318.0551253324\n",
      "episode: 1204   score: 2344  move: 197   memory length: 5000   epsilon: 0.23274140555840028  loss: 532323.4671058655\n",
      "episode: 1205   score: 1164  move: 127   memory length: 5000   epsilon: 0.23244601011217486  loss: 826807.9819375887\n",
      "episode: 1206   score: 1236  move: 127   memory length: 5000   epsilon: 0.2321509895819186  loss: 827911.2347259822\n",
      "episode: 1207   score: 1124  move: 119   memory length: 5000   epsilon: 0.23187489283397805  loss: 884627.3463844171\n",
      "episode: 1208   score: 2032  move: 170   memory length: 5000   epsilon: 0.23148103841799397  loss: 620307.4476818533\n",
      "episode: 1209   score: 924  move: 119   memory length: 5000   epsilon: 0.23120573844174938  loss: 887265.9020746376\n",
      "episode: 1210   score: 668  move: 89   memory length: 5000   epsilon: 0.23100005584845315  loss: 1187449.8176669432\n",
      "episode: 1211   score: 2576  move: 220   memory length: 5000   epsilon: 0.23049241180056787  loss: 481518.8182742899\n",
      "episode: 1212   score: 2776  move: 223   memory length: 5000   epsilon: 0.22997898384005683  loss: 476174.94153853273\n",
      "episode: 1213   score: 1472  move: 152   memory length: 5000   epsilon: 0.22962967957659058  loss: 699731.2763532589\n",
      "episode: 1214   score: 1908  move: 187   memory length: 5000   epsilon: 0.22920067117860812  loss: 569869.6724188698\n",
      "episode: 1215   score: 476  move: 67   memory length: 5000   epsilon: 0.22904715739420956  loss: 1591653.3049501448\n",
      "episode: 1216   score: 2328  move: 196   memory length: 5000   epsilon: 0.2285986623919213  loss: 545239.9129322013\n",
      "episode: 1217   score: 924  move: 113   memory length: 5000   epsilon: 0.22834049050714464  loss: 946889.5247123854\n",
      "episode: 1218   score: 516  move: 72   memory length: 5000   epsilon: 0.22817614370419378  loss: 1487278.8736134106\n",
      "episode: 1219   score: 1476  move: 149   memory length: 5000   epsilon: 0.22783641271385935  loss: 719846.1889637428\n",
      "episode: 1220   score: 1200  move: 122   memory length: 5000   epsilon: 0.22755862038915944  loss: 880309.9183206089\n",
      "episode: 1221   score: 1496  move: 157   memory length: 5000   epsilon: 0.2272016318795135  loss: 685274.1280794812\n",
      "episode: 1222   score: 1456  move: 150   memory length: 5000   epsilon: 0.22686108320430912  loss: 718421.755338262\n",
      "episode: 1223   score: 996  move: 115   memory length: 5000   epsilon: 0.2266003416100679  loss: 938231.0327235014\n",
      "episode: 1224   score: 540  move: 74   memory length: 5000   epsilon: 0.2264327185473429  loss: 1459186.5037390734\n",
      "episode: 1225   score: 2236  move: 188   memory length: 5000   epsilon: 0.2260074228132481  loss: 575518.9425364758\n",
      "episode: 1226   score: 1724  move: 172   memory length: 5000   epsilon: 0.22561902222426558  loss: 630261.7069752937\n",
      "episode: 1227   score: 760  move: 101   memory length: 5000   epsilon: 0.22539126091183606  loss: 1074554.363476026\n",
      "episode: 1228   score: 1692  move: 169   memory length: 5000   epsilon: 0.22501066946829068  loss: 643405.1059138055\n",
      "episode: 1229   score: 876  move: 109   memory length: 5000   epsilon: 0.2247655402326265  loss: 998824.0168581972\n",
      "episode: 1230   score: 1096  move: 116   memory length: 5000   epsilon: 0.22450496206762022  loss: 939813.5791327707\n",
      "episode: 1231   score: 600  move: 85   memory length: 5000   epsilon: 0.22431421297596527  loss: 1283786.8441085366\n",
      "episode: 1232   score: 640  move: 83   memory length: 5000   epsilon: 0.2241281084927166  loss: 1315934.6696154582\n",
      "episode: 1233   score: 1388  move: 143   memory length: 5000   epsilon: 0.22380783274792745  loss: 764993.2339747769\n",
      "episode: 1234   score: 776  move: 97   memory length: 5000   epsilon: 0.22359084332209947  loss: 1128932.5960443635\n",
      "episode: 1235   score: 2592  move: 205   memory length: 5000   epsilon: 0.2231329493055434  loss: 535374.2987802831\n",
      "episode: 1236   score: 1528  move: 160   memory length: 5000   epsilon: 0.2227762202623451  loss: 687163.9740052462\n",
      "episode: 1237   score: 1044  move: 111   memory length: 5000   epsilon: 0.2225290746133358  loss: 991723.1731151203\n",
      "episode: 1238   score: 1164  move: 128   memory length: 5000   epsilon: 0.22224441819352156  loss: 861245.3134442866\n",
      "episode: 1239   score: 1136  move: 121   memory length: 5000   epsilon: 0.2219756637329731  loss: 912301.3761341\n",
      "episode: 1240   score: 704  move: 93   memory length: 5000   epsilon: 0.2217693212980929  loss: 1188170.0810575178\n",
      "episode: 1241   score: 1428  move: 147   memory length: 5000   epsilon: 0.22144355826146228  loss: 752882.1466269201\n",
      "episode: 1242   score: 364  move: 62   memory length: 5000   epsilon: 0.22130630512194382  loss: 1786178.1180147356\n",
      "episode: 1243   score: 2176  move: 189   memory length: 5000   epsilon: 0.22088842913308332  loss: 587118.7084545358\n",
      "episode: 1244   score: 2512  move: 217   memory length: 5000   epsilon: 0.22040961854518798  loss: 512545.0970243287\n",
      "episode: 1245   score: 1028  move: 108   memory length: 5000   epsilon: 0.22017170346485176  loss: 1031044.6195595706\n",
      "episode: 1246   score: 3044  move: 246   memory length: 5000   epsilon: 0.21963074402245006  loss: 453827.8927563458\n",
      "episode: 1247   score: 2484  move: 216   memory length: 5000   epsilon: 0.2191568512343574  loss: 518056.94369996036\n",
      "episode: 1248   score: 728  move: 99   memory length: 5000   epsilon: 0.2189399922302588  loss: 1131468.0966478214\n",
      "episode: 1249   score: 1068  move: 120   memory length: 5000   epsilon: 0.21867742050126904  loss: 934580.2247280439\n",
      "episode: 1250   score: 1620  move: 156   memory length: 5000   epsilon: 0.21833654797062624  loss: 720020.4828277245\n",
      "episode: 1251   score: 820  move: 108   memory length: 5000   epsilon: 0.21810087060911346  loss: 1041136.5192217297\n",
      "episode: 1252   score: 908  move: 98   memory length: 5000   epsilon: 0.21788723538609692  loss: 1148508.6264170823\n",
      "episode: 1253   score: 632  move: 88   memory length: 5000   epsilon: 0.21769557800228678  loss: 1280147.9071941809\n",
      "episode: 1254   score: 1448  move: 151   memory length: 5000   epsilon: 0.2173671040973439  loss: 747181.7997652016\n",
      "episode: 1255   score: 272  move: 52   memory length: 5000   epsilon: 0.21725410202128853  loss: 2170789.3781753685\n",
      "episode: 1256   score: 1236  move: 127   memory length: 5000   epsilon: 0.21697836306432527  loss: 889961.8126409636\n",
      "episode: 1257   score: 624  move: 83   memory length: 5000   epsilon: 0.21679834484078742  loss: 1362825.6039629558\n",
      "episode: 1258   score: 1184  move: 130   memory length: 5000   epsilon: 0.21651668870037075  loss: 871207.9874747937\n",
      "episode: 1259   score: 892  move: 109   memory length: 5000   epsilon: 0.21628081290596912  loss: 1040112.4099408421\n",
      "episode: 1260   score: 840  move: 107   memory length: 5000   epsilon: 0.21604951504609246  loss: 1060598.8795504346\n",
      "episode: 1261   score: 1020  move: 127   memory length: 5000   epsilon: 0.21577530495119884  loss: 894616.1148976303\n",
      "episode: 1262   score: 848  move: 99   memory length: 5000   epsilon: 0.21556179203806258  loss: 1148685.1939008695\n",
      "episode: 1263   score: 1368  move: 144   memory length: 5000   epsilon: 0.21525160489493453  loss: 790761.6884966162\n",
      "episode: 1264   score: 1740  move: 175   memory length: 5000   epsilon: 0.2148752421180344  loss: 651684.1454726955\n",
      "episode: 1265   score: 1260  move: 142   memory length: 5000   epsilon: 0.21457033428548275  loss: 804146.1299972803\n",
      "episode: 1266   score: 2840  move: 229   memory length: 5000   epsilon: 0.21407952795367283  loss: 499667.5590421352\n",
      "episode: 1267   score: 572  move: 84   memory length: 5000   epsilon: 0.21389977575792193  loss: 1363224.3141750607\n",
      "episode: 1268   score: 552  move: 78   memory length: 5000   epsilon: 0.21373299815066474  loss: 1469128.2370154064\n",
      "episode: 1269   score: 1628  move: 164   memory length: 5000   epsilon: 0.21338276155502192  loss: 699764.0115454372\n",
      "episode: 1270   score: 608  move: 82   memory length: 5000   epsilon: 0.2132078585360692  loss: 1400555.6494872395\n",
      "episode: 1271   score: 700  move: 93   memory length: 5000   epsilon: 0.21300966641029248  loss: 1235933.4508117759\n",
      "episode: 1272   score: 880  move: 107   memory length: 5000   epsilon: 0.21278186682274813  loss: 1075291.7591605855\n",
      "episode: 1273   score: 2372  move: 195   memory length: 5000   epsilon: 0.21236734440054425  loss: 591088.6017951574\n",
      "episode: 1274   score: 1192  move: 121   memory length: 5000   epsilon: 0.21211053403137317  loss: 953628.240604779\n",
      "episode: 1275   score: 940  move: 123   memory length: 5000   epsilon: 0.21184979715687957  loss: 939153.1078681325\n",
      "episode: 1276   score: 288  move: 54   memory length: 5000   epsilon: 0.21173542857686733  loss: 2140208.7458578744\n",
      "episode: 1277   score: 2072  move: 176   memory length: 5000   epsilon: 0.2113631001060934  loss: 657720.7474300428\n",
      "episode: 1278   score: 2572  move: 222   memory length: 5000   epsilon: 0.2108943921386594  loss: 522501.9176534876\n",
      "episode: 1279   score: 924  move: 111   memory length: 5000   epsilon: 0.2106604280676459  loss: 1046102.5703528121\n",
      "episode: 1280   score: 1552  move: 162   memory length: 5000   epsilon: 0.21031943274998172  loss: 717854.1007299776\n",
      "episode: 1281   score: 2388  move: 203   memory length: 5000   epsilon: 0.20989291523066247  loss: 573935.6852523165\n",
      "episode: 1282   score: 556  move: 89   memory length: 5000   epsilon: 0.20970619270634255  loss: 1310153.933497954\n",
      "episode: 1283   score: 624  move: 86   memory length: 5000   epsilon: 0.2095259220067723  loss: 1356906.8599195702\n",
      "episode: 1284   score: 576  move: 79   memory length: 5000   epsilon: 0.20936046106675846  loss: 1478162.0996760598\n",
      "episode: 1285   score: 704  move: 95   memory length: 5000   epsilon: 0.20916166207921988  loss: 1230224.0458369607\n",
      "episode: 1286   score: 1352  move: 139   memory length: 5000   epsilon: 0.20887112788430182  loss: 841789.0418342481\n",
      "episode: 1287   score: 1644  move: 165   memory length: 5000   epsilon: 0.20852677297244507  loss: 710137.0131282229\n",
      "episode: 1288   score: 1432  move: 151   memory length: 5000   epsilon: 0.2082121335845806  loss: 776981.5708777067\n",
      "episode: 1289   score: 596  move: 83   memory length: 5000   epsilon: 0.20803938834916838  loss: 1414566.6050476166\n",
      "episode: 1290   score: 2368  move: 203   memory length: 5000   epsilon: 0.2076174946483383  loss: 579351.0170529558\n",
      "episode: 1291   score: 1112  move: 120   memory length: 5000   epsilon: 0.20736850183536254  loss: 981041.4314007123\n",
      "episode: 1292   score: 2500  move: 208   memory length: 5000   epsilon: 0.20693762146807113  loss: 566945.6305284684\n",
      "episode: 1293   score: 1644  move: 167   memory length: 5000   epsilon: 0.2065923223187629  loss: 707083.6816473178\n",
      "episode: 1294   score: 936  move: 101   memory length: 5000   epsilon: 0.2063837683679244  loss: 1170074.3211176277\n",
      "episode: 1295   score: 1504  move: 153   memory length: 5000   epsilon: 0.2060682410646225  loss: 773332.2430417179\n",
      "episode: 1296   score: 580  move: 81   memory length: 5000   epsilon: 0.20590139253789272  loss: 1461677.6199297963\n",
      "episode: 1297   score: 652  move: 89   memory length: 5000   epsilon: 0.20571822090614217  loss: 1331217.485792053\n",
      "episode: 1298   score: 996  move: 121   memory length: 5000   epsilon: 0.20546945115105006  loss: 980078.7588215031\n",
      "episode: 1299   score: 1348  move: 139   memory length: 5000   epsilon: 0.2051840455897394  loss: 854086.5487105829\n",
      "episode: 1300   score: 1184  move: 127   memory length: 5000   epsilon: 0.2049236259512144  loss: 935679.6684466085\n",
      "episode: 1301   score: 952  move: 122   memory length: 5000   epsilon: 0.20467377032119966  loss: 974945.552103668\n",
      "episode: 1302   score: 1312  move: 135   memory length: 5000   epsilon: 0.20439764577664638  loss: 881976.0248052808\n",
      "episode: 1303   score: 1352  move: 146   memory length: 5000   epsilon: 0.2040994414649088  loss: 816431.9695264477\n",
      "episode: 1304   score: 684  move: 96   memory length: 5000   epsilon: 0.20390359904129376  loss: 1242563.7606495619\n",
      "episode: 1305   score: 620  move: 84   memory length: 5000   epsilon: 0.20373239107946978  loss: 1420943.0284338905\n",
      "episode: 1306   score: 984  move: 106   memory length: 5000   epsilon: 0.20351654808270825  loss: 1126907.5572016374\n",
      "episode: 1307   score: 1816  move: 173   memory length: 5000   epsilon: 0.20316476707392875  loss: 691325.5253720366\n",
      "episode: 1308   score: 1480  move: 154   memory length: 5000   epsilon: 0.20285213255982432  loss: 777496.7157051037\n",
      "episode: 1309   score: 3232  move: 265   memory length: 5000   epsilon: 0.2023152833636478  loss: 452693.830212935\n",
      "episode: 1310   score: 408  move: 68   memory length: 5000   epsilon: 0.20217775504824503  loss: 1765049.0628395642\n",
      "episode: 1311   score: 1456  move: 152   memory length: 5000   epsilon: 0.20187067676379822  loss: 790494.4226762119\n",
      "episode: 1312   score: 3256  move: 270   memory length: 5000   epsilon: 0.20132635837544122  loss: 445879.56735055713\n",
      "episode: 1313   score: 1212  move: 131   memory length: 5000   epsilon: 0.20106279220167367  loss: 919844.8253487449\n",
      "episode: 1314   score: 1152  move: 125   memory length: 5000   epsilon: 0.2008116194712186  loss: 964837.5544693909\n",
      "episode: 1315   score: 620  move: 84   memory length: 5000   epsilon: 0.20064300769466395  loss: 1436594.9270595822\n",
      "episode: 1316   score: 1780  move: 181   memory length: 5000   epsilon: 0.20028017050326555  loss: 667558.899350435\n",
      "episode: 1317   score: 1064  move: 113   memory length: 5000   epsilon: 0.20005398060101  loss: 1070109.2793332327\n",
      "episode: 1318   score: 832  move: 109   memory length: 5000   epsilon: 0.19983603947194195  loss: 1110256.1540170722\n",
      "episode: 1319   score: 1360  move: 142   memory length: 5000   epsilon: 0.19955247225842526  loss: 853098.3025621495\n",
      "episode: 1320   score: 1040  move: 125   memory length: 5000   epsilon: 0.19930318625788088  loss: 969984.2232037659\n",
      "episode: 1321   score: 1516  move: 157   memory length: 5000   epsilon: 0.19899052419608668  loss: 773136.6483334341\n",
      "episode: 1322   score: 820  move: 105   memory length: 5000   epsilon: 0.19878169275721458  loss: 1156922.1171272278\n",
      "episode: 1323   score: 1644  move: 167   memory length: 5000   epsilon: 0.19845000271013577  loss: 728290.7429448888\n",
      "episode: 1324   score: 1216  move: 129   memory length: 5000   epsilon: 0.1981941659776259  loss: 943680.654572864\n",
      "episode: 1325   score: 1744  move: 176   memory length: 5000   epsilon: 0.1978456492875718  loss: 692532.1608242772\n",
      "episode: 1326   score: 2464  move: 209   memory length: 5000   epsilon: 0.1974325816212929  loss: 584033.6431538158\n",
      "episode: 1327   score: 1380  move: 139   memory length: 5000   epsilon: 0.19715833960398574  loss: 879007.296098366\n",
      "episode: 1328   score: 2604  move: 220   memory length: 5000   epsilon: 0.1967250658663525  loss: 556216.2882017136\n",
      "episode: 1329   score: 1276  move: 132   memory length: 5000   epsilon: 0.19646555879422065  loss: 927870.9298069405\n",
      "episode: 1330   score: 1048  move: 114   memory length: 5000   epsilon: 0.19624171455343278  loss: 1075243.007330811\n",
      "episode: 1331   score: 636  move: 83   memory length: 5000   epsilon: 0.19607890069338244  loss: 1477682.143167381\n",
      "episode: 1332   score: 872  move: 105   memory length: 5000   epsilon: 0.19587312486998754  loss: 1168938.351725442\n",
      "episode: 1333   score: 1496  move: 159   memory length: 5000   epsilon: 0.19556193250896917  loss: 772801.4733139374\n",
      "episode: 1334   score: 652  move: 86   memory length: 5000   epsilon: 0.19539382070488884  loss: 1429664.4707771568\n",
      "episode: 1335   score: 1292  move: 130   memory length: 5000   epsilon: 0.19513997250581047  loss: 946629.068507884\n",
      "episode: 1336   score: 1864  move: 190   memory length: 5000   epsilon: 0.19476955671240678  loss: 648558.7188255913\n",
      "episode: 1337   score: 1152  move: 140   memory length: 5000   epsilon: 0.19449706875664413  loss: 881061.0191847937\n",
      "episode: 1338   score: 1404  move: 144   memory length: 5000   epsilon: 0.1942171931370643  loss: 857461.122032298\n",
      "episode: 1339   score: 100  move: 34   memory length: 5000   epsilon: 0.19415117018582045  loss: 3632513.0401132246\n",
      "episode: 1340   score: 1256  move: 126   memory length: 5000   epsilon: 0.19390669254225704  loss: 981111.5542294033\n",
      "episode: 1341   score: 1012  move: 121   memory length: 5000   epsilon: 0.19367220616471592  loss: 1022593.3885151572\n",
      "episode: 1342   score: 1708  move: 171   memory length: 5000   epsilon: 0.19334130803621424  loss: 724542.6937371193\n",
      "episode: 1343   score: 660  move: 89   memory length: 5000   epsilon: 0.19316930996256718  loss: 1393032.7218643788\n",
      "episode: 1344   score: 924  move: 113   memory length: 5000   epsilon: 0.19295115083463438  loss: 1098139.265774786\n",
      "episode: 1345   score: 2356  move: 193   memory length: 5000   epsilon: 0.19257911238591735  loss: 643886.4376218528\n",
      "episode: 1346   score: 1420  move: 145   memory length: 5000   epsilon: 0.19230007362975135  loss: 857955.6860554925\n",
      "episode: 1347   score: 652  move: 92   memory length: 5000   epsilon: 0.19212323803467996  loss: 1353145.1310473317\n",
      "episode: 1348   score: 716  move: 96   memory length: 5000   epsilon: 0.19193888730691974  loss: 1297727.8800877333\n",
      "episode: 1349   score: 724  move: 97   memory length: 5000   epsilon: 0.191752795924686  loss: 1285275.6412550544\n",
      "episode: 1350   score: 2400  move: 201   memory length: 5000   epsilon: 0.19136775797246147  loss: 621183.626209259\n",
      "episode: 1351   score: 780  move: 103   memory length: 5000   epsilon: 0.19117074967339884  loss: 1213115.0794513666\n",
      "episode: 1352   score: 756  move: 94   memory length: 5000   epsilon: 0.19099113270382187  loss: 1330184.1975937295\n",
      "episode: 1353   score: 492  move: 70   memory length: 5000   epsilon: 0.19085748502483513  loss: 1787135.6961829595\n",
      "episode: 1354   score: 1268  move: 137   memory length: 5000   epsilon: 0.1905961879932008  loss: 914025.7220050505\n",
      "episode: 1355   score: 1128  move: 135   memory length: 5000   epsilon: 0.1903390554572602  loss: 928451.4659429762\n",
      "episode: 1356   score: 1204  move: 128   memory length: 5000   epsilon: 0.19009557610890349  loss: 980098.5269972384\n",
      "episode: 1357   score: 1440  move: 149   memory length: 5000   epsilon: 0.18981254319721838  loss: 842830.1421858256\n",
      "episode: 1358   score: 636  move: 88   memory length: 5000   epsilon: 0.18964558079862226  loss: 1427926.4207405178\n",
      "episode: 1359   score: 556  move: 77   memory length: 5000   epsilon: 0.18949960917783498  loss: 1632787.2917411607\n",
      "episode: 1360   score: 1384  move: 141   memory length: 5000   epsilon: 0.18923260167837955  loss: 892546.3246664765\n",
      "episode: 1361   score: 876  move: 94   memory length: 5000   epsilon: 0.1890548057210132  loss: 1339688.419544504\n",
      "episode: 1362   score: 840  move: 107   memory length: 5000   epsilon: 0.18885262425435823  loss: 1177819.8383234683\n",
      "episode: 1363   score: 1276  move: 129   memory length: 5000   epsilon: 0.18860916021981386  loss: 977888.4337956924\n",
      "episode: 1364   score: 748  move: 100   memory length: 5000   epsilon: 0.18842064439063844  loss: 1262403.7197893143\n",
      "episode: 1365   score: 1736  move: 177   memory length: 5000   epsilon: 0.18808743316293958  loss: 714171.5353868776\n",
      "episode: 1366   score: 2492  move: 216   memory length: 5000   epsilon: 0.18768160073495438  loss: 586177.6686214341\n",
      "episode: 1367   score: 2364  move: 195   memory length: 5000   epsilon: 0.1873159763849971  loss: 650262.3849881099\n",
      "episode: 1368   score: 1384  move: 141   memory length: 5000   epsilon: 0.18705204565353217  loss: 900264.042954384\n",
      "episode: 1369   score: 1220  move: 133   memory length: 5000   epsilon: 0.186803430555425  loss: 955344.1611363977\n",
      "episode: 1370   score: 732  move: 97   memory length: 5000   epsilon: 0.1866223181759286  loss: 1310818.5386464621\n",
      "episode: 1371   score: 1712  move: 169   memory length: 5000   epsilon: 0.18630719123983944  loss: 753289.1518958503\n",
      "episode: 1372   score: 892  move: 107   memory length: 5000   epsilon: 0.18610794816305232  loss: 1190695.54446486\n",
      "episode: 1373   score: 1772  move: 179   memory length: 5000   epsilon: 0.1857751112495628  loss: 712683.0396628992\n",
      "episode: 1374   score: 564  move: 79   memory length: 5000   epsilon: 0.18562840613429973  loss: 1615742.664468741\n",
      "episode: 1375   score: 620  move: 88   memory length: 5000   epsilon: 0.18546512417509026  loss: 1451453.918907729\n",
      "episode: 1376   score: 928  move: 113   memory length: 5000   epsilon: 0.18525566590369189  loss: 1131314.6458204489\n",
      "episode: 1377   score: 1308  move: 133   memory length: 5000   epsilon: 0.18500943841447817  loss: 962162.1559832867\n",
      "episode: 1378   score: 860  move: 104   memory length: 5000   epsilon: 0.18481712765590086  loss: 1231426.308432249\n",
      "episode: 1379   score: 1144  move: 128   memory length: 5000   epsilon: 0.18458071188879133  loss: 1001489.1638316214\n",
      "episode: 1380   score: 1568  move: 164   memory length: 5000   epsilon: 0.18427824609870447  loss: 782573.2776135002\n",
      "episode: 1381   score: 1256  move: 136   memory length: 5000   epsilon: 0.18402779677590506  loss: 944614.9816036505\n",
      "episode: 1382   score: 704  move: 93   memory length: 5000   epsilon: 0.18385672962812047  loss: 1382319.222384422\n",
      "episode: 1383   score: 1508  move: 150   memory length: 5000   epsilon: 0.18358114989225208  loss: 857973.190598882\n",
      "episode: 1384   score: 1024  move: 122   memory length: 5000   epsilon: 0.18335731633644697  loss: 1055815.6263997124\n",
      "episode: 1385   score: 1076  move: 118   memory length: 5000   epsilon: 0.18314108122579942  loss: 1092538.0386258464\n",
      "episode: 1386   score: 1404  move: 144   memory length: 5000   epsilon: 0.18287754654167135  loss: 896182.8694614039\n",
      "episode: 1387   score: 1472  move: 150   memory length: 5000   epsilon: 0.18260343448673513  loss: 861263.5914053599\n",
      "episode: 1388   score: 692  move: 95   memory length: 5000   epsilon: 0.18243004273113775  loss: 1360832.0272710298\n",
      "episode: 1389   score: 1460  move: 154   memory length: 5000   epsilon: 0.18214931527731423  loss: 840394.063309236\n",
      "episode: 1390   score: 776  move: 102   memory length: 5000   epsilon: 0.18196361676957717  loss: 1269752.7038387598\n",
      "episode: 1391   score: 664  move: 91   memory length: 5000   epsilon: 0.18179810437031774  loss: 1424165.3799517704\n",
      "episode: 1392   score: 716  move: 96   memory length: 5000   epsilon: 0.18162366106408928  loss: 1350920.9518641233\n",
      "episode: 1393   score: 1400  move: 142   memory length: 5000   epsilon: 0.1813659372040052  loss: 914220.0360312932\n",
      "episode: 1394   score: 3476  move: 280   memory length: 5000   epsilon: 0.18085882033917666  loss: 464582.9009514536\n",
      "episode: 1395   score: 2432  move: 205   memory length: 5000   epsilon: 0.1804884376775066  loss: 635532.809062325\n",
      "episode: 1396   score: 972  move: 118   memory length: 5000   epsilon: 0.18027558586405534  loss: 1105098.9723887362\n",
      "episode: 1397   score: 2188  move: 188   memory length: 5000   epsilon: 0.1799369844546775  loss: 694603.0224527603\n",
      "episode: 1398   score: 1408  move: 145   memory length: 5000   epsilon: 0.17967626359191904  loss: 901567.2522085519\n",
      "episode: 1399   score: 1424  move: 146   memory length: 5000   epsilon: 0.17941412634314377  loss: 896360.7652691619\n",
      "episode: 1400   score: 756  move: 103   memory length: 5000   epsilon: 0.17922942400753006  loss: 1271510.5844375833\n",
      "episode: 1401   score: 1284  move: 132   memory length: 5000   epsilon: 0.1789929960624726  loss: 993108.2620728521\n",
      "episode: 1402   score: 2788  move: 227   memory length: 5000   epsilon: 0.17858714075218812  loss: 578406.7036473783\n",
      "episode: 1403   score: 996  move: 105   memory length: 5000   epsilon: 0.1783997217295086  loss: 1251373.5895861308\n",
      "episode: 1404   score: 1232  move: 136   memory length: 5000   epsilon: 0.17815726180577543  loss: 967038.4406095673\n",
      "episode: 1405   score: 1208  move: 124   memory length: 5000   epsilon: 0.17793648260863093  loss: 1061537.5364772736\n",
      "episode: 1406   score: 1452  move: 151   memory length: 5000   epsilon: 0.17766799993291174  loss: 872651.3047880715\n",
      "episode: 1407   score: 884  move: 108   memory length: 5000   epsilon: 0.17747622111329286  loss: 1221042.0871603577\n",
      "episode: 1408   score: 2336  move: 197   memory length: 5000   epsilon: 0.17712693537068847  loss: 670327.6363998839\n",
      "episode: 1409   score: 792  move: 99   memory length: 5000   epsilon: 0.176951665601173  loss: 1334777.0762925968\n",
      "episode: 1410   score: 1088  move: 114   memory length: 5000   epsilon: 0.17675005463441765  loss: 1160064.940099783\n",
      "episode: 1411   score: 1928  move: 190   memory length: 5000   epsilon: 0.17641454668655407  loss: 696963.346684767\n",
      "episode: 1412   score: 2620  move: 221   memory length: 5000   epsilon: 0.17602509908924163  loss: 600133.6717722103\n",
      "episode: 1413   score: 1844  move: 171   memory length: 5000   epsilon: 0.17572435187821248  loss: 776577.3984295806\n",
      "episode: 1414   score: 1648  move: 165   memory length: 5000   epsilon: 0.17543464432353498  loss: 805783.4948363564\n",
      "episode: 1415   score: 444  move: 72   memory length: 5000   epsilon: 0.1753083762102566  loss: 1847571.6083168983\n",
      "episode: 1416   score: 780  move: 101   memory length: 5000   epsilon: 0.17513140325180704  loss: 1318067.0874112952\n",
      "episode: 1417   score: 668  move: 87   memory length: 5000   epsilon: 0.17497910442907758  loss: 1531152.1971181673\n",
      "episode: 1418   score: 1384  move: 146   memory length: 5000   epsilon: 0.17472382006312268  loss: 913382.4532862885\n",
      "episode: 1419   score: 2592  move: 221   memory length: 5000   epsilon: 0.17433810486449036  loss: 604410.892721133\n",
      "episode: 1420   score: 304  move: 56   memory length: 5000   epsilon: 0.17424050236900276  loss: 2386269.902365344\n",
      "episode: 1421   score: 956  move: 100   memory length: 5000   epsilon: 0.17406634808751537  loss: 1337335.1594505692\n",
      "episode: 1422   score: 684  move: 88   memory length: 5000   epsilon: 0.17391323631469985  loss: 1520702.4383169087\n",
      "episode: 1423   score: 824  move: 106   memory length: 5000   epsilon: 0.17372898503338036  loss: 1263495.0344409943\n",
      "episode: 1424   score: 1480  move: 155   memory length: 5000   epsilon: 0.1734599123464174  loss: 865061.1906367394\n",
      "episode: 1425   score: 920  move: 94   memory length: 5000   epsilon: 0.1732969358248942  loss: 1427477.4182705574\n",
      "episode: 1426   score: 1168  move: 127   memory length: 5000   epsilon: 0.17307698731352103  loss: 1057593.932317208\n",
      "episode: 1427   score: 1648  move: 163   memory length: 5000   epsilon: 0.17279510021516106  loss: 825090.639713147\n",
      "episode: 1428   score: 1312  move: 133   memory length: 5000   epsilon: 0.1725654343452029  loss: 1012244.7119566551\n",
      "episode: 1429   score: 1388  move: 147   memory length: 5000   epsilon: 0.17231194824721288  loss: 916925.5336298781\n",
      "episode: 1430   score: 1564  move: 159   memory length: 5000   epsilon: 0.1720381885773127  loss: 848786.9056011896\n",
      "episode: 1431   score: 1436  move: 148   memory length: 5000   epsilon: 0.17178375911031757  loss: 912877.3067918983\n",
      "episode: 1432   score: 872  move: 103   memory length: 5000   epsilon: 0.1716069120460709  loss: 1312733.8960244262\n",
      "episode: 1433   score: 676  move: 90   memory length: 5000   epsilon: 0.17145253453364226  loss: 1503386.7450397492\n",
      "episode: 1434   score: 380  move: 63   memory length: 5000   epsilon: 0.171344552914759  loss: 2148747.984814659\n",
      "episode: 1435   score: 1648  move: 169   memory length: 5000   epsilon: 0.17105522372571377  loss: 802092.8356849852\n",
      "episode: 1436   score: 764  move: 103   memory length: 5000   epsilon: 0.17087912667034227  loss: 1317130.3163569553\n",
      "episode: 1437   score: 1212  move: 135   memory length: 5000   epsilon: 0.17064859434100926  loss: 1005969.0183543169\n",
      "episode: 1438   score: 1448  move: 151   memory length: 5000   epsilon: 0.17039110812713856  loss: 900439.5044425561\n",
      "episode: 1439   score: 2228  move: 206   memory length: 5000   epsilon: 0.17004046198069636  loss: 661094.0838281761\n",
      "episode: 1440   score: 1312  move: 137   memory length: 5000   epsilon: 0.1698076648862178  loss: 995092.2310353578\n",
      "episode: 1441   score: 1264  move: 136   memory length: 5000   epsilon: 0.1695768822758051  loss: 1003430.6837278535\n",
      "episode: 1442   score: 1232  move: 127   memory length: 5000   epsilon: 0.16936165525726424  loss: 1075575.4196026719\n",
      "episode: 1443   score: 664  move: 91   memory length: 5000   epsilon: 0.16920760548400826  loss: 1502139.3850076278\n",
      "episode: 1444   score: 580  move: 81   memory length: 5000   epsilon: 0.16907060213239705  loss: 1688613.637082559\n",
      "episode: 1445   score: 1056  move: 111   memory length: 5000   epsilon: 0.16888303694414133  loss: 1233251.2999431507\n",
      "episode: 1446   score: 924  move: 112   memory length: 5000   epsilon: 0.16869399288197917  loss: 1223296.8296823842\n",
      "episode: 1447   score: 728  move: 98   memory length: 5000   epsilon: 0.1685287529235588  loss: 1399090.2574754443\n",
      "episode: 1448   score: 2096  move: 197   memory length: 5000   epsilon: 0.16819707643052872  loss: 697041.7833025202\n",
      "episode: 1449   score: 644  move: 93   memory length: 5000   epsilon: 0.1680407250823369  loss: 1477630.9846209865\n",
      "episode: 1450   score: 1264  move: 137   memory length: 5000   epsilon: 0.16781066576529222  loss: 1004124.1343770549\n",
      "episode: 1451   score: 736  move: 96   memory length: 5000   epsilon: 0.16764964402385069  loss: 1434033.0505001147\n",
      "episode: 1452   score: 3188  move: 266   memory length: 5000   epsilon: 0.16720428633228596  loss: 518624.30685971194\n",
      "episode: 1453   score: 684  move: 95   memory length: 5000   epsilon: 0.16704551689384653  loss: 1453203.245792951\n",
      "episode: 1454   score: 816  move: 105   memory length: 5000   epsilon: 0.16687021027665466  loss: 1315853.8069689432\n",
      "episode: 1455   score: 752  move: 96   memory length: 5000   epsilon: 0.16671009094376874  loss: 1440236.8100959857\n",
      "episode: 1456   score: 528  move: 71   memory length: 5000   epsilon: 0.1665917681971301  loss: 1948407.2073018786\n",
      "episode: 1457   score: 3184  move: 260   memory length: 5000   epsilon: 0.1661591900322264  loss: 533105.7587991128\n",
      "episode: 1458   score: 1012  move: 119   memory length: 5000   epsilon: 0.16596157721097213  loss: 1165801.7732399371\n",
      "episode: 1459   score: 1120  move: 121   memory length: 5000   epsilon: 0.16576088414287338  loss: 1147553.4063139672\n",
      "episode: 1460   score: 2044  move: 199   memory length: 5000   epsilon: 0.16543134633460863  loss: 698790.8519148515\n",
      "episode: 1461   score: 1448  move: 148   memory length: 5000   epsilon: 0.16518668781070606  loss: 940553.8828260319\n",
      "episode: 1462   score: 1284  move: 131   memory length: 5000   epsilon: 0.16497043384567683  loss: 1063598.3591848183\n",
      "episode: 1463   score: 1204  move: 123   memory length: 5000   epsilon: 0.16476764393945548  loss: 1133765.2236054274\n",
      "episode: 1464   score: 1136  move: 122   memory length: 5000   epsilon: 0.16456674898021656  loss: 1144046.673107116\n",
      "episode: 1465   score: 976  move: 119   memory length: 5000   epsilon: 0.1643710300461969  loss: 1173849.5284489545\n",
      "episode: 1466   score: 2856  move: 231   memory length: 5000   epsilon: 0.16399176928531234  loss: 605673.5009701716\n",
      "episode: 1467   score: 2036  move: 196   memory length: 5000   epsilon: 0.1636706586032257  loss: 714813.8274286425\n",
      "episode: 1468   score: 3012  move: 243   memory length: 5000   epsilon: 0.16327341975729429  loss: 577532.1969011251\n",
      "episode: 1469   score: 1296  move: 140   memory length: 5000   epsilon: 0.1630449957616196  loss: 1003426.3557088852\n",
      "episode: 1470   score: 1544  move: 159   memory length: 5000   epsilon: 0.16278595891204187  loss: 884478.3058229123\n",
      "episode: 1471   score: 1468  move: 156   memory length: 5000   epsilon: 0.16253220952337502  loss: 902425.40705473\n",
      "episode: 1472   score: 1256  move: 135   memory length: 5000   epsilon: 0.16231293798574983  loss: 1043748.3626228898\n",
      "episode: 1473   score: 268  move: 51   memory length: 5000   epsilon: 0.1622301790788974  loss: 2763847.2786707412\n",
      "episode: 1474   score: 1700  move: 173   memory length: 5000   epsilon: 0.16194976209763237  loss: 815742.1788368225\n",
      "episode: 1475   score: 2892  move: 244   memory length: 5000   epsilon: 0.1615550844073199  loss: 579338.595491206\n",
      "episode: 1476   score: 1620  move: 164   memory length: 5000   epsilon: 0.1612903498868611  loss: 862898.4657368776\n",
      "episode: 1477   score: 764  move: 99   memory length: 5000   epsilon: 0.16113075065713034  loss: 1430443.4224790707\n",
      "episode: 1478   score: 1388  move: 140   memory length: 5000   epsilon: 0.16090532431433763  loss: 1012506.0152569634\n",
      "episode: 1479   score: 3280  move: 273   memory length: 5000   epsilon: 0.160466649648954  loss: 520193.0702778044\n",
      "episode: 1480   score: 2704  move: 229   memory length: 5000   epsilon: 0.1600995996186958  loss: 621062.7239891118\n",
      "episode: 1481   score: 1412  move: 147   memory length: 5000   epsilon: 0.15986442492712957  loss: 968423.6160908653\n",
      "episode: 1482   score: 3064  move: 251   memory length: 5000   epsilon: 0.1594636663791484  loss: 568074.9047274799\n",
      "episode: 1483   score: 420  move: 71   memory length: 5000   epsilon: 0.15935048679362832  loss: 2009157.1775468101\n",
      "episode: 1484   score: 2828  move: 240   memory length: 5000   epsilon: 0.15896850228016904  loss: 595293.1336666902\n",
      "episode: 1485   score: 1048  move: 126   memory length: 5000   epsilon: 0.15876832710326402  loss: 1134839.4517361172\n",
      "episode: 1486   score: 428  move: 70   memory length: 5000   epsilon: 0.15865722760815365  loss: 2043654.7023034778\n",
      "episode: 1487   score: 2136  move: 179   memory length: 5000   epsilon: 0.15837348377850477  loss: 800129.9878931525\n",
      "episode: 1488   score: 1208  move: 124   memory length: 5000   epsilon: 0.15817722138513848  loss: 1155929.0644796125\n",
      "episode: 1489   score: 756  move: 101   memory length: 5000   epsilon: 0.15801754224468328  loss: 1420061.076860069\n",
      "episode: 1490   score: 704  move: 93   memory length: 5000   epsilon: 0.15787065350980034  loss: 1543131.725094908\n",
      "episode: 1491   score: 332  move: 60   memory length: 5000   epsilon: 0.15777595905539904  loss: 2392741.465571912\n",
      "episode: 1492   score: 1368  move: 144   memory length: 5000   epsilon: 0.1575489240436237  loss: 997936.2115439574\n",
      "episode: 1493   score: 2512  move: 216   memory length: 5000   epsilon: 0.1572089839354738  loss: 666198.7825034283\n",
      "episode: 1494   score: 572  move: 77   memory length: 5000   epsilon: 0.15708797900569516  loss: 1869731.2981217124\n",
      "episode: 1495   score: 1028  move: 123   memory length: 5000   epsilon: 0.15689487860710571  loss: 1171406.2456812975\n",
      "episode: 1496   score: 1620  move: 162   memory length: 5000   epsilon: 0.15664091340129438  loss: 890322.6285821656\n",
      "episode: 1497   score: 820  move: 103   memory length: 5000   epsilon: 0.1564796555162684  loss: 1401229.6155690684\n",
      "episode: 1498   score: 1440  move: 148   memory length: 5000   epsilon: 0.1562482357618649  loss: 976109.6093914186\n",
      "episode: 1499   score: 1368  move: 144   memory length: 5000   epsilon: 0.15602339909943247  loss: 1004138.6246595648\n",
      "episode: 1500   score: 2672  move: 232   memory length: 5000   epsilon: 0.15566184257347887  loss: 624185.8175148306\n",
      "episode: 1501   score: 984  move: 107   memory length: 5000   epsilon: 0.15549537264686847  loss: 1354381.5407188986\n",
      "episode: 1502   score: 1360  move: 141   memory length: 5000   epsilon: 0.15527627757428503  loss: 1028786.3892613675\n",
      "episode: 1503   score: 1472  move: 157   memory length: 5000   epsilon: 0.15503268387161703  loss: 924931.3736058375\n",
      "episode: 1504   score: 1468  move: 153   memory length: 5000   epsilon: 0.15479566404659642  loss: 950082.1444589702\n",
      "episode: 1505   score: 636  move: 88   memory length: 5000   epsilon: 0.15465950310103316  loss: 1652844.2328788151\n",
      "episode: 1506   score: 1336  move: 140   memory length: 5000   epsilon: 0.1544431302111905  loss: 1039962.3080827168\n",
      "episode: 1507   score: 1332  move: 138   memory length: 5000   epsilon: 0.15423014462042903  loss: 1056035.134198092\n",
      "episode: 1508   score: 1312  move: 133   memory length: 5000   epsilon: 0.15402515385220764  loss: 1096749.1010360431\n",
      "episode: 1509   score: 3132  move: 256   memory length: 5000   epsilon: 0.1536313517710674  loss: 570828.3327197582\n",
      "episode: 1510   score: 820  move: 103   memory length: 5000   epsilon: 0.15347319215412997  loss: 1419736.2744406173\n",
      "episode: 1511   score: 1016  move: 107   memory length: 5000   epsilon: 0.15330906284271878  loss: 1367684.1929080642\n",
      "episode: 1512   score: 664  move: 94   memory length: 5000   epsilon: 0.15316501931449333  loss: 1557898.7716037263\n",
      "episode: 1513   score: 760  move: 95   memory length: 5000   epsilon: 0.15301958091313078  loss: 1542543.8873103494\n",
      "episode: 1514   score: 1368  move: 143   memory length: 5000   epsilon: 0.15280091820021255  loss: 1025830.5510018355\n",
      "episode: 1515   score: 1712  move: 173   memory length: 5000   epsilon: 0.15253679981940627  loss: 848992.3928253747\n",
      "episode: 1516   score: 876  move: 105   memory length: 5000   epsilon: 0.15237671943610198  loss: 1399852.9293630328\n",
      "episode: 1517   score: 2524  move: 212   memory length: 5000   epsilon: 0.15205402135823  loss: 694339.6998728086\n",
      "episode: 1518   score: 532  move: 79   memory length: 5000   epsilon: 0.15193394551717956  loss: 1864344.020932596\n",
      "episode: 1519   score: 716  move: 87   memory length: 5000   epsilon: 0.1518018198069684  loss: 1693959.2317047557\n",
      "episode: 1520   score: 3716  move: 302   memory length: 5000   epsilon: 0.1513440675761656  loss: 489010.8238272383\n",
      "episode: 1521   score: 600  move: 83   memory length: 5000   epsilon: 0.1512185034885612  loss: 1780390.8384574521\n",
      "episode: 1522   score: 2580  move: 225   memory length: 5000   epsilon: 0.1508786426432367  loss: 657775.4542290072\n",
      "episode: 1523   score: 1188  move: 134   memory length: 5000   epsilon: 0.15067659965091634  loss: 1105479.4614188636\n",
      "episode: 1524   score: 1744  move: 176   memory length: 5000   epsilon: 0.1504116407429693  loss: 842691.9593210437\n",
      "episode: 1525   score: 776  move: 99   memory length: 5000   epsilon: 0.15026280615973517  loss: 1499151.2123621546\n",
      "episode: 1526   score: 704  move: 98   memory length: 5000   epsilon: 0.15011562000676215  loss: 1515509.484255304\n",
      "episode: 1527   score: 1436  move: 147   memory length: 5000   epsilon: 0.14989511105659328  loss: 1011382.0962237144\n",
      "episode: 1528   score: 3508  move: 296   memory length: 5000   epsilon: 0.14945207532903895  loss: 503305.9476181881\n",
      "episode: 1529   score: 996  move: 119   memory length: 5000   epsilon: 0.14927433224878936  loss: 1252981.377596206\n",
      "episode: 1530   score: 672  move: 90   memory length: 5000   epsilon: 0.14914004511660311  loss: 1657750.6273917728\n",
      "episode: 1531   score: 664  move: 88   memory length: 5000   epsilon: 0.14900885895134788  loss: 1696516.4353102336\n",
      "episode: 1532   score: 1360  move: 140   memory length: 5000   epsilon: 0.14880039146776614  loss: 1067448.3773358208\n",
      "episode: 1533   score: 1200  move: 132   memory length: 5000   epsilon: 0.1486041035481165  loss: 1133191.4854217586\n",
      "episode: 1534   score: 2468  move: 212   memory length: 5000   epsilon: 0.14828939498399787  loss: 706662.5913784999\n",
      "episode: 1535   score: 1412  move: 149   memory length: 5000   epsilon: 0.14806860720927204  loss: 1006511.6589285063\n",
      "episode: 1536   score: 480  move: 74   memory length: 5000   epsilon: 0.1479590764236718  loss: 2027601.838372978\n",
      "episode: 1537   score: 1376  move: 140   memory length: 5000   epsilon: 0.1477520776146601  loss: 1072717.8783612114\n",
      "episode: 1538   score: 780  move: 101   memory length: 5000   epsilon: 0.14760292260645239  loss: 1487925.526852334\n",
      "episode: 1539   score: 2060  move: 193   memory length: 5000   epsilon: 0.14731832227048625  loss: 779634.3138170984\n",
      "episode: 1540   score: 1144  move: 138   memory length: 5000   epsilon: 0.1471151621826541  loss: 1091370.6348725748\n",
      "episode: 1541   score: 1004  move: 120   memory length: 5000   epsilon: 0.14693872898695756  loss: 1256041.0111505191\n",
      "episode: 1542   score: 712  move: 92   memory length: 5000   epsilon: 0.14680360684639376  loss: 1639290.1046154604\n",
      "episode: 1543   score: 312  move: 57   memory length: 5000   epsilon: 0.14671995221605244  loss: 2646830.269732358\n",
      "episode: 1544   score: 1236  move: 130   memory length: 5000   epsilon: 0.1465293392503785  loss: 1161448.65055721\n",
      "episode: 1545   score: 868  move: 109   memory length: 5000   epsilon: 0.14636970848701203  loss: 1386176.2453237062\n",
      "episode: 1546   score: 852  move: 110   memory length: 5000   epsilon: 0.1462087895247363  loss: 1374524.9129288066\n",
      "episode: 1547   score: 1928  move: 191   memory length: 5000   epsilon: 0.14592979586553612  loss: 792563.4458087102\n",
      "episode: 1548   score: 860  move: 111   memory length: 5000   epsilon: 0.14576790284990568  loss: 1364689.9028588715\n",
      "episode: 1549   score: 1120  move: 118   memory length: 5000   epsilon: 0.1455959973092303  loss: 1284646.9013655388\n",
      "episode: 1550   score: 1296  move: 135   memory length: 5000   epsilon: 0.14539957434607934  loss: 1123770.8406326012\n",
      "episode: 1551   score: 676  move: 91   memory length: 5000   epsilon: 0.14526732025689068  loss: 1668078.147783426\n",
      "episode: 1552   score: 2128  move: 179   memory length: 5000   epsilon: 0.14500752304251915  loss: 848973.4689289498\n",
      "episode: 1553   score: 3224  move: 267   memory length: 5000   epsilon: 0.1446208674376521  loss: 570145.3602246488\n",
      "episode: 1554   score: 1696  move: 168   memory length: 5000   epsilon: 0.14437810714229993  loss: 907087.2339916456\n",
      "episode: 1555   score: 1492  move: 153   memory length: 5000   epsilon: 0.14415737643676693  loss: 996970.3581769606\n",
      "episode: 1556   score: 2964  move: 237   memory length: 5000   epsilon: 0.14381612628951587  loss: 644548.1061869593\n",
      "episode: 1557   score: 2720  move: 229   memory length: 5000   epsilon: 0.14348716252276636  loss: 667982.3011916548\n",
      "episode: 1558   score: 948  move: 117   memory length: 5000   epsilon: 0.14331937987568938  loss: 1308313.9564521008\n",
      "episode: 1559   score: 2696  move: 233   memory length: 5000   epsilon: 0.14298583278610202  loss: 657885.6009746273\n",
      "episode: 1560   score: 3180  move: 264   memory length: 5000   epsilon: 0.14260884614393468  loss: 581559.8284116369\n",
      "episode: 1561   score: 976  move: 102   memory length: 5000   epsilon: 0.14246345855420534  loss: 1506141.1595272364\n",
      "episode: 1562   score: 1076  move: 133   memory length: 5000   epsilon: 0.1422741071541636  loss: 1156003.507771112\n",
      "episode: 1563   score: 656  move: 89   memory length: 5000   epsilon: 0.14214753889718354  loss: 1728448.028002664\n",
      "episode: 1564   score: 1840  move: 176   memory length: 5000   epsilon: 0.14189757800902436  loss: 874972.5243023309\n",
      "episode: 1565   score: 1268  move: 134   memory length: 5000   epsilon: 0.14170756164380766  loss: 1150133.6787686988\n",
      "episode: 1566   score: 1448  move: 155   memory length: 5000   epsilon: 0.141488083965013  loss: 995238.3071122939\n",
      "episode: 1567   score: 792  move: 104   memory length: 5000   epsilon: 0.14134101211294864  loss: 1484178.4036711545\n",
      "episode: 1568   score: 2496  move: 216   memory length: 5000   epsilon: 0.1410360434866291  loss: 715488.9513422118\n",
      "episode: 1569   score: 1536  move: 156   memory length: 5000   epsilon: 0.14081619768387127  loss: 991578.7579258895\n",
      "episode: 1570   score: 2132  move: 205   memory length: 5000   epsilon: 0.1405278187261482  loss: 755452.2089682416\n",
      "episode: 1571   score: 724  move: 99   memory length: 5000   epsilon: 0.14038876433361855  loss: 1565225.751091119\n",
      "episode: 1572   score: 908  move: 113   memory length: 5000   epsilon: 0.14023021383507123  loss: 1372236.1397974133\n",
      "episode: 1573   score: 404  move: 59   memory length: 5000   epsilon: 0.14014750199774045  loss: 2629022.5144992764\n",
      "episode: 1574   score: 2128  move: 199   memory length: 5000   epsilon: 0.13986888439213996  loss: 780402.3830286725\n",
      "episode: 1575   score: 2408  move: 225   memory length: 5000   epsilon: 0.13955453160999082  loss: 691133.2680338033\n",
      "episode: 1576   score: 1660  move: 171   memory length: 5000   epsilon: 0.1393160960892305  loss: 910308.7826990719\n",
      "episode: 1577   score: 1192  move: 131   memory length: 5000   epsilon: 0.13913371058001667  loss: 1189164.3884153003\n",
      "episode: 1578   score: 3140  move: 261   memory length: 5000   epsilon: 0.1387710432687841  loss: 597797.0425474233\n",
      "episode: 1579   score: 1400  move: 150   memory length: 5000   epsilon: 0.13856304170404635  loss: 1041130.7607435354\n",
      "episode: 1580   score: 1504  move: 150   memory length: 5000   epsilon: 0.13835535190932854  loss: 1042134.6330360158\n",
      "episode: 1581   score: 464  move: 74   memory length: 5000   epsilon: 0.13825300630972964  loss: 2113437.237315668\n",
      "episode: 1582   score: 1640  move: 171   memory length: 5000   epsilon: 0.13801679450653104  loss: 915558.88990661\n",
      "episode: 1583   score: 1724  move: 172   memory length: 5000   epsilon: 0.1377796084725127  loss: 911212.0054290461\n",
      "episode: 1584   score: 1404  move: 147   memory length: 5000   epsilon: 0.13757722022792113  loss: 1067129.312808212\n",
      "episode: 1585   score: 1248  move: 131   memory length: 5000   epsilon: 0.1373971111660693  loss: 1198429.8880649304\n",
      "episode: 1586   score: 1732  move: 174   memory length: 5000   epsilon: 0.13715824687052078  loss: 903231.0028771806\n",
      "episode: 1587   score: 644  move: 85   memory length: 5000   epsilon: 0.13704171131263118  loss: 1849944.854397628\n",
      "episode: 1588   score: 384  move: 63   memory length: 5000   epsilon: 0.13695540179330964  loss: 2496935.554418473\n",
      "episode: 1589   score: 564  move: 77   memory length: 5000   epsilon: 0.13684998619706343  loss: 2043918.8619696382\n",
      "episode: 1590   score: 1320  move: 135   memory length: 5000   epsilon: 0.13666536244165262  loss: 1166753.1625923722\n",
      "episode: 1591   score: 616  move: 85   memory length: 5000   epsilon: 0.13654924565961643  loss: 1854026.9521687676\n",
      "episode: 1592   score: 1308  move: 133   memory length: 5000   epsilon: 0.13636775497349468  loss: 1185892.7990233055\n",
      "episode: 1593   score: 3020  move: 261   memory length: 5000   epsilon: 0.13601229742960508  loss: 605285.9471230488\n",
      "episode: 1594   score: 1192  move: 130   memory length: 5000   epsilon: 0.1358355954406143  loss: 1216229.364028373\n",
      "episode: 1595   score: 1436  move: 150   memory length: 5000   epsilon: 0.13563199376887355  loss: 1055074.139231898\n",
      "episode: 1596   score: 624  move: 82   memory length: 5000   epsilon: 0.1355208205653595  loss: 1931051.7637599388\n",
      "episode: 1597   score: 1376  move: 144   memory length: 5000   epsilon: 0.13532581004996105  loss: 1100651.0540268421\n",
      "episode: 1598   score: 520  move: 80   memory length: 5000   epsilon: 0.13521759215376142  loss: 1982210.9493952275\n",
      "episode: 1599   score: 1028  move: 111   memory length: 5000   epsilon: 0.13506758314682626  loss: 1429606.6577672528\n",
      "episode: 1600   score: 752  move: 97   memory length: 5000   epsilon: 0.13493663045873158  loss: 1636923.8378927093\n",
      "episode: 1601   score: 1156  move: 117   memory length: 5000   epsilon: 0.13477884613400196  loss: 1358115.4209784158\n",
      "episode: 1602   score: 468  move: 67   memory length: 5000   epsilon: 0.1346885741002399  loss: 2372652.416666344\n",
      "episode: 1603   score: 1820  move: 180   memory length: 5000   epsilon: 0.134446351521467  loss: 884226.4960908042\n",
      "episode: 1604   score: 1024  move: 111   memory length: 5000   epsilon: 0.1342971981209624  loss: 1434945.8866177464\n",
      "episode: 1605   score: 1012  move: 109   memory length: 5000   epsilon: 0.13415089319415596  loss: 1462345.8251456514\n",
      "episode: 1606   score: 1596  move: 171   memory length: 5000   epsilon: 0.13392169004532092  loss: 933222.997611531\n",
      "episode: 1607   score: 968  move: 122   memory length: 5000   epsilon: 0.13375840439153847  loss: 1309091.3684523848\n",
      "episode: 1608   score: 936  move: 115   memory length: 5000   epsilon: 0.13360466987210656  loss: 1389847.3015382518\n",
      "episode: 1609   score: 1588  move: 159   memory length: 5000   epsilon: 0.13339240618004486  loss: 1006300.956094346\n",
      "episode: 1610   score: 1404  move: 145   memory length: 5000   epsilon: 0.13319912638639902  loss: 1104475.3014489799\n",
      "episode: 1611   score: 1784  move: 176   memory length: 5000   epsilon: 0.13296490093169258  loss: 910940.5401924524\n",
      "episode: 1612   score: 2032  move: 189   memory length: 5000   epsilon: 0.13271383334719716  loss: 849295.2801763343\n",
      "episode: 1613   score: 964  move: 118   memory length: 5000   epsilon: 0.13255732260079403  loss: 1361310.0689564398\n",
      "episode: 1614   score: 968  move: 109   memory length: 5000   epsilon: 0.13241291311457898  loss: 1474712.5574443361\n",
      "episode: 1615   score: 1752  move: 178   memory length: 5000   epsilon: 0.13217742659697884  loss: 904074.6649047552\n",
      "episode: 1616   score: 2788  move: 241   memory length: 5000   epsilon: 0.13185926095164874  loss: 668750.8593066995\n",
      "episode: 1617   score: 996  move: 120   memory length: 5000   epsilon: 0.13170112394899922  loss: 1344083.0625632287\n",
      "episode: 1618   score: 908  move: 118   memory length: 5000   epsilon: 0.13154580750088296  loss: 1367874.9310392283\n",
      "episode: 1619   score: 628  move: 84   memory length: 5000   epsilon: 0.1314353548669196  loss: 1922524.9709772835\n",
      "episode: 1620   score: 648  move: 84   memory length: 5000   epsilon: 0.1313249949746756  loss: 1923552.5880681446\n",
      "episode: 1621   score: 1764  move: 167   memory length: 5000   epsilon: 0.13110586416256934  loss: 968578.0965412848\n",
      "episode: 1622   score: 1692  move: 172   memory length: 5000   epsilon: 0.13088055477128482  loss: 941472.3215127324\n",
      "episode: 1623   score: 1460  move: 150   memory length: 5000   epsilon: 0.13068438012602088  loss: 1080623.9327869923\n",
      "episode: 1624   score: 1408  move: 146   memory length: 5000   epsilon: 0.13049371919407973  loss: 1111298.1285439322\n",
      "episode: 1625   score: 1056  move: 114   memory length: 5000   epsilon: 0.13034504037383357  loss: 1424318.5708560944\n",
      "episode: 1626   score: 656  move: 90   memory length: 5000   epsilon: 0.1302277820253768  loss: 1805181.96894349\n",
      "episode: 1627   score: 1824  move: 182   memory length: 5000   epsilon: 0.12999098183163005  loss: 893706.6927055317\n",
      "episode: 1628   score: 416  move: 67   memory length: 5000   epsilon: 0.12990391660858303  loss: 2428750.2763483417\n",
      "episode: 1629   score: 1264  move: 135   memory length: 5000   epsilon: 0.12972866376718126  loss: 1206440.6339863248\n",
      "episode: 1630   score: 1184  move: 130   memory length: 5000   epsilon: 0.1295601252353724  loss: 1253876.0809252518\n",
      "episode: 1631   score: 1604  move: 169   memory length: 5000   epsilon: 0.1293413524449378  loss: 965546.5306115912\n",
      "episode: 1632   score: 568  move: 87   memory length: 5000   epsilon: 0.12922887384120454  loss: 1876628.3322531602\n",
      "episode: 1633   score: 1392  move: 144   memory length: 5000   epsilon: 0.12904291725396583  loss: 1134850.2287531164\n",
      "episode: 1634   score: 1364  move: 143   memory length: 5000   epsilon: 0.1288585168380106  loss: 1143841.0154437353\n",
      "episode: 1635   score: 1648  move: 175   memory length: 5000   epsilon: 0.12863321050755114  loss: 935715.46503673\n",
      "episode: 1636   score: 3240  move: 274   memory length: 5000   epsilon: 0.12828123617592962  loss: 598716.8115756321\n",
      "episode: 1637   score: 1468  move: 152   memory length: 5000   epsilon: 0.1280863958389095  loss: 1080445.989078045\n",
      "episode: 1638   score: 1496  move: 155   memory length: 5000   epsilon: 0.12788801471853897  loss: 1060647.203815411\n",
      "episode: 1639   score: 1228  move: 131   memory length: 5000   epsilon: 0.12772059026909224  loss: 1256069.6160345005\n",
      "episode: 1640   score: 1900  move: 186   memory length: 5000   epsilon: 0.12748324957975427  loss: 885781.9380113541\n",
      "episode: 1641   score: 1008  move: 122   memory length: 5000   epsilon: 0.12732781407302732  loss: 1351594.5813300023\n",
      "episode: 1642   score: 3448  move: 283   memory length: 5000   epsilon: 0.12696798395981354  loss: 583784.8738611039\n",
      "episode: 1643   score: 2496  move: 212   memory length: 5000   epsilon: 0.12669909561173293  loss: 780448.8433424212\n",
      "episode: 1644   score: 2488  move: 213   memory length: 5000   epsilon: 0.1264295123982085  loss: 777929.8217433338\n",
      "episode: 1645   score: 720  move: 100   memory length: 5000   epsilon: 0.1263031454479807  loss: 1658106.380318184\n",
      "episode: 1646   score: 856  move: 112   memory length: 5000   epsilon: 0.12616176440633567  loss: 1481620.0768379825\n",
      "episode: 1647   score: 2112  move: 175   memory length: 5000   epsilon: 0.12594117328919252  loss: 949390.2527756392\n",
      "episode: 1648   score: 2480  move: 212   memory length: 5000   epsilon: 0.12567445948477568  loss: 784843.7844774678\n",
      "episode: 1649   score: 1748  move: 177   memory length: 5000   epsilon: 0.12545221132788842  loss: 941247.0917324993\n",
      "episode: 1650   score: 1512  move: 158   memory length: 5000   epsilon: 0.1252541523514892  loss: 1055643.3581323987\n",
      "episode: 1651   score: 3040  move: 247   memory length: 5000   epsilon: 0.1249451548192422  loss: 676408.9728826762\n",
      "episode: 1652   score: 2320  move: 202   memory length: 5000   epsilon: 0.12469301908865066  loss: 828197.7027884946\n",
      "episode: 1653   score: 760  move: 96   memory length: 5000   epsilon: 0.12457337063253084  loss: 1743792.5400494337\n",
      "episode: 1654   score: 604  move: 81   memory length: 5000   epsilon: 0.12447250655346445  loss: 2067882.3493014206\n",
      "episode: 1655   score: 1576  move: 155   memory length: 5000   epsilon: 0.12427972265050821  loss: 1081805.3439411041\n",
      "episode: 1656   score: 2964  move: 251   memory length: 5000   epsilon: 0.12396817015084717  loss: 669258.0898392058\n",
      "episode: 1657   score: 3104  move: 260   memory length: 5000   epsilon: 0.12364626995055115  loss: 647320.2231861554\n",
      "episode: 1658   score: 1744  move: 178   memory length: 5000   epsilon: 0.12342637425578833  loss: 946738.8372978682\n",
      "episode: 1659   score: 2000  move: 193   memory length: 5000   epsilon: 0.12318838989233534  loss: 874342.5450228557\n",
      "episode: 1660   score: 972  move: 113   memory length: 5000   epsilon: 0.12304926493653585  loss: 1494535.953713375\n",
      "episode: 1661   score: 2320  move: 194   memory length: 5000   epsilon: 0.1228107795757286  loss: 871696.953376475\n",
      "episode: 1662   score: 804  move: 108   memory length: 5000   epsilon: 0.12267821486878988  loss: 1566963.167483471\n",
      "episode: 1663   score: 1100  move: 118   memory length: 5000   epsilon: 0.12253353922728179  loss: 1435318.7369753628\n",
      "episode: 1664   score: 2868  move: 234   memory length: 5000   epsilon: 0.1222471445259984  loss: 724922.7692535433\n",
      "episode: 1665   score: 812  move: 101   memory length: 5000   epsilon: 0.12212373662446818  loss: 1680599.3575816012\n",
      "episode: 1666   score: 920  move: 119   memory length: 5000   epsilon: 0.1219784950875311  loss: 1427443.2295744119\n",
      "episode: 1667   score: 1268  move: 129   memory length: 5000   epsilon: 0.12182124349169589  loss: 1317842.0195498504\n",
      "episode: 1668   score: 1760  move: 179   memory length: 5000   epsilon: 0.12160337742481672  loss: 950798.2620502877\n",
      "episode: 1669   score: 1456  move: 152   memory length: 5000   epsilon: 0.12141867977341778  loss: 1120777.2179104905\n",
      "episode: 1670   score: 412  move: 63   memory length: 5000   epsilon: 0.1213422097134081  loss: 2705209.7813646225\n",
      "episode: 1671   score: 1244  move: 129   memory length: 5000   epsilon: 0.12118577840061062  loss: 1322278.387771163\n",
      "episode: 1672   score: 736  move: 95   memory length: 5000   epsilon: 0.12107070600381052  loss: 1796670.4792251186\n",
      "episode: 1673   score: 1472  move: 153   memory length: 5000   epsilon: 0.12088560853380927  loss: 1116741.1616770676\n",
      "episode: 1674   score: 1460  move: 151   memory length: 5000   epsilon: 0.1207032080999058  loss: 1132687.4157550381\n",
      "episode: 1675   score: 392  move: 64   memory length: 5000   epsilon: 0.12062598237546071  loss: 2673629.89455539\n",
      "episode: 1676   score: 1580  move: 157   memory length: 5000   epsilon: 0.12043674722541828  loss: 1091090.3409934316\n",
      "episode: 1677   score: 1416  move: 147   memory length: 5000   epsilon: 0.12025983438522736  loss: 1166524.508193373\n",
      "episode: 1678   score: 800  move: 107   memory length: 5000   epsilon: 0.1201312245379243  loss: 1603837.597370647\n",
      "episode: 1679   score: 2792  move: 236   memory length: 5000   epsilon: 0.11984804771221642  loss: 728412.545222735\n",
      "episode: 1680   score: 1396  move: 143   memory length: 5000   epsilon: 0.1196767866285412  loss: 1203353.490025367\n",
      "episode: 1681   score: 528  move: 78   memory length: 5000   epsilon: 0.11958347466480755  loss: 2207408.886358261\n",
      "episode: 1682   score: 1660  move: 154   memory length: 5000   epsilon: 0.11939945692376318  loss: 1119340.8526347023\n",
      "episode: 1683   score: 364  move: 62   memory length: 5000   epsilon: 0.11932545183439311  loss: 2781579.746281101\n",
      "episode: 1684   score: 2472  move: 211   memory length: 5000   epsilon: 0.11907393931248328  loss: 818580.1429620716\n",
      "episode: 1685   score: 836  move: 109   memory length: 5000   epsilon: 0.11894421878056284  loss: 1585838.6028253748\n",
      "episode: 1686   score: 1364  move: 141   memory length: 5000   epsilon: 0.11877662477565122  loss: 1227214.8801552253\n",
      "episode: 1687   score: 884  move: 107   memory length: 5000   epsilon: 0.11864960112179657  loss: 1618432.0398356002\n",
      "episode: 1688   score: 844  move: 104   memory length: 5000   epsilon: 0.11852626906375571  loss: 1666383.659816045\n",
      "episode: 1689   score: 768  move: 94   memory length: 5000   epsilon: 0.1184149061627844  loss: 1844949.4489423467\n",
      "episode: 1690   score: 1568  move: 157   memory length: 5000   epsilon: 0.11822913969611036  loss: 1105889.2505125059\n",
      "episode: 1691   score: 1816  move: 189   memory length: 5000   epsilon: 0.11800589653710743  loss: 919928.0797000662\n",
      "episode: 1692   score: 1784  move: 177   memory length: 5000   epsilon: 0.1177972097990486  loss: 983544.2769900607\n",
      "episode: 1693   score: 1252  move: 136   memory length: 5000   epsilon: 0.11763711368327574  loss: 1281310.0297345836\n",
      "episode: 1694   score: 1096  move: 117   memory length: 5000   epsilon: 0.11749955805822  loss: 1490638.7781092\n",
      "episode: 1695   score: 1324  move: 137   memory length: 5000   epsilon: 0.1173386930770277  loss: 1274247.3552385594\n",
      "episode: 1696   score: 700  move: 100   memory length: 5000   epsilon: 0.11722141244763525  loss: 1747018.169571724\n",
      "episode: 1697   score: 1076  move: 119   memory length: 5000   epsilon: 0.11708200123588872  loss: 1469348.4969961022\n",
      "episode: 1698   score: 688  move: 91   memory length: 5000   epsilon: 0.11697550454562346  loss: 1922708.3918861556\n",
      "episode: 1699   score: 632  move: 86   memory length: 5000   epsilon: 0.11687494835429277  loss: 2035749.5089106448\n",
      "episode: 1700   score: 1540  move: 152   memory length: 5000   epsilon: 0.11669743249144789  loss: 1153071.3336680813\n",
      "episode: 1701   score: 2356  move: 197   memory length: 5000   epsilon: 0.11646776369913253  loss: 890960.4687476183\n",
      "episode: 1702   score: 1056  move: 128   memory length: 5000   epsilon: 0.11631877958684976  loss: 1372537.083305508\n",
      "episode: 1703   score: 2956  move: 244   memory length: 5000   epsilon: 0.11603530632531073  loss: 721307.822199415\n",
      "episode: 1704   score: 1292  move: 132   memory length: 5000   epsilon: 0.11588224000162808  loss: 1334635.8121168253\n",
      "episode: 1705   score: 4096  move: 313   memory length: 5000   epsilon: 0.11552009383410342  loss: 564151.5246048339\n",
      "episode: 1706   score: 716  move: 96   memory length: 5000   epsilon: 0.11540924720468428  loss: 1840663.7292609613\n",
      "episode: 1707   score: 1468  move: 151   memory length: 5000   epsilon: 0.11523510987748768  loss: 1171493.5916405735\n",
      "episode: 1708   score: 2384  move: 205   memory length: 5000   epsilon: 0.11499911869588968  loss: 864146.3411895938\n",
      "episode: 1709   score: 1540  move: 162   memory length: 5000   epsilon: 0.11481297001400145  loss: 1094753.1996815293\n",
      "episode: 1710   score: 600  move: 90   memory length: 5000   epsilon: 0.11470968431009856  loss: 1971790.7447633955\n",
      "episode: 1711   score: 1116  move: 124   memory length: 5000   epsilon: 0.11456753174359646  loss: 1432369.4495058674\n",
      "episode: 1712   score: 608  move: 83   memory length: 5000   epsilon: 0.1144724796690563  loss: 2141222.4904610966\n",
      "episode: 1713   score: 156  move: 39   memory length: 5000   epsilon: 0.11442784388335026  loss: 4558227.346944662\n",
      "episode: 1714   score: 1068  move: 111   memory length: 5000   epsilon: 0.11430089880946406  loss: 1602831.011471482\n",
      "episode: 1715   score: 872  move: 104   memory length: 5000   epsilon: 0.11418208707345477  loss: 1712012.947424265\n",
      "episode: 1716   score: 2964  move: 253   memory length: 5000   epsilon: 0.1138935700784697  loss: 704991.4238038346\n",
      "episode: 1717   score: 2136  move: 180   memory length: 5000   epsilon: 0.11368874502605264  loss: 992157.934770139\n",
      "episode: 1718   score: 1124  move: 119   memory length: 5000   epsilon: 0.11355353520921903  loss: 1501975.6660757947\n",
      "episode: 1719   score: 624  move: 84   memory length: 5000   epsilon: 0.1134581898135884  loss: 2129027.551398368\n",
      "episode: 1720   score: 596  move: 83   memory length: 5000   epsilon: 0.11336405811544295  loss: 2155894.477394426\n",
      "episode: 1721   score: 688  move: 94   memory length: 5000   epsilon: 0.11325754543705241  loss: 1904862.1929050607\n",
      "episode: 1722   score: 1348  move: 137   memory length: 5000   epsilon: 0.11310248806306973  loss: 1308232.68597827\n",
      "episode: 1723   score: 1512  move: 157   memory length: 5000   epsilon: 0.11292505559058491  loss: 1142833.2634916124\n",
      "episode: 1724   score: 3016  move: 247   memory length: 5000   epsilon: 0.11264647350087952  loss: 727705.609045438\n",
      "episode: 1725   score: 1844  move: 175   memory length: 5000   epsilon: 0.11244951357765152  loss: 1028436.2051636832\n",
      "episode: 1726   score: 532  move: 78   memory length: 5000   epsilon: 0.11236183671709722  loss: 2308748.1200274443\n",
      "episode: 1727   score: 1388  move: 144   memory length: 5000   epsilon: 0.11220015130523286  loss: 1251922.2075781557\n",
      "episode: 1728   score: 988  move: 106   memory length: 5000   epsilon: 0.11208128156259393  loss: 1702034.0512748933\n",
      "episode: 1729   score: 3072  move: 253   memory length: 5000   epsilon: 0.11179807291420307  loss: 714491.4571152789\n",
      "episode: 1730   score: 1392  move: 151   memory length: 5000   epsilon: 0.11162938437256063  loss: 1198553.3508423306\n",
      "episode: 1731   score: 1268  move: 137   memory length: 5000   epsilon: 0.11147655606312382  loss: 1322468.4940347325\n",
      "episode: 1732   score: 3020  move: 241   memory length: 5000   epsilon: 0.11120821969652829  loss: 753269.8753280481\n",
      "episode: 1733   score: 1216  move: 125   memory length: 5000   epsilon: 0.11106929557295289  loss: 1453769.7252398988\n",
      "episode: 1734   score: 1528  move: 156   memory length: 5000   epsilon: 0.11089616168573273  loss: 1166385.753282327\n",
      "episode: 1735   score: 2060  move: 192   memory length: 5000   epsilon: 0.11068344426577853  loss: 949175.3806423545\n",
      "episode: 1736   score: 2136  move: 202   memory length: 5000   epsilon: 0.11046008825709834  loss: 903666.0719838095\n",
      "episode: 1737   score: 2496  move: 215   memory length: 5000   epsilon: 0.11022285300045472  loss: 850619.6080467934\n",
      "episode: 1738   score: 1340  move: 140   memory length: 5000   epsilon: 0.1100686482037741  loss: 1307835.075920459\n",
      "episode: 1739   score: 2472  move: 206   memory length: 5000   epsilon: 0.1098421390404674  loss: 890373.0647343941\n",
      "episode: 1740   score: 400  move: 68   memory length: 5000   epsilon: 0.10976747140245555  loss: 2698827.238969971\n",
      "episode: 1741   score: 2852  move: 233   memory length: 5000   epsilon: 0.1095120096452987  loss: 789118.0570595704\n",
      "episode: 1742   score: 1836  move: 186   memory length: 5000   epsilon: 0.10930850560726336  loss: 989965.2937918428\n",
      "episode: 1743   score: 688  move: 96   memory length: 5000   epsilon: 0.1092036192709451  loss: 1919507.8549870253\n",
      "episode: 1744   score: 1864  move: 189   memory length: 5000   epsilon: 0.10899741832079654  loss: 976374.0494314729\n",
      "episode: 1745   score: 1524  move: 162   memory length: 5000   epsilon: 0.10882098457087105  loss: 1140442.6906788438\n",
      "episode: 1746   score: 2276  move: 213   memory length: 5000   epsilon: 0.10858944139703959  loss: 868701.9610433265\n",
      "episode: 1747   score: 704  move: 93   memory length: 5000   epsilon: 0.10848849965701574  loss: 1990939.6776000403\n",
      "episode: 1748   score: 1600  move: 162   memory length: 5000   epsilon: 0.10831288969199862  loss: 1144197.845583433\n",
      "episode: 1749   score: 1700  move: 175   memory length: 5000   epsilon: 0.10812350694635801  loss: 1060443.8758772714\n",
      "episode: 1750   score: 2000  move: 186   memory length: 5000   epsilon: 0.10792258313588834  loss: 998952.1107332988\n",
      "episode: 1751   score: 588  move: 78   memory length: 5000   epsilon: 0.10783843592198569  loss: 2383340.6433107913\n",
      "episode: 1752   score: 788  move: 107   memory length: 5000   epsilon: 0.10772310992932799  loss: 1738550.8620504576\n",
      "episode: 1753   score: 2104  move: 192   memory length: 5000   epsilon: 0.10751647895432141  loss: 970069.6687982281\n",
      "episode: 1754   score: 2316  move: 194   memory length: 5000   epsilon: 0.10730809813799251  loss: 961259.2967165328\n",
      "episode: 1755   score: 1456  move: 157   memory length: 5000   epsilon: 0.10713975576554478  loss: 1188987.8073035805\n",
      "episode: 1756   score: 1560  move: 159   memory length: 5000   epsilon: 0.1069695380617237  loss: 1175168.790986571\n",
      "episode: 1757   score: 904  move: 108   memory length: 5000   epsilon: 0.1068540727457839  loss: 1731223.791621632\n",
      "episode: 1758   score: 1748  move: 178   memory length: 5000   epsilon: 0.10666404072480938  loss: 1051534.8335003157\n",
      "episode: 1759   score: 1752  move: 178   memory length: 5000   epsilon: 0.1064743466616503  loss: 1052666.4800155512\n",
      "episode: 1760   score: 592  move: 81   memory length: 5000   epsilon: 0.10638813692946046  loss: 2314382.0296392087\n",
      "episode: 1761   score: 1744  move: 180   memory length: 5000   epsilon: 0.10619680957262967  loss: 1042571.6633332359\n",
      "episode: 1762   score: 1408  move: 148   memory length: 5000   epsilon: 0.10603975375915255  loss: 1269092.3881767117\n",
      "episode: 1763   score: 1432  move: 145   memory length: 5000   epsilon: 0.10588610676895456  loss: 1296463.596022744\n",
      "episode: 1764   score: 1320  move: 136   memory length: 5000   epsilon: 0.10574219882379242  loss: 1383336.6040978432\n",
      "episode: 1765   score: 2752  move: 236   memory length: 5000   epsilon: 0.10549294022910592  loss: 798267.0300816196\n",
      "episode: 1766   score: 1212  move: 139   memory length: 5000   epsilon: 0.10534640617427808  loss: 1356424.0448385829\n",
      "episode: 1767   score: 1916  move: 193   memory length: 5000   epsilon: 0.10514328267197474  loss: 977994.2491168284\n",
      "episode: 1768   score: 3464  move: 286   memory length: 5000   epsilon: 0.10484300098961212  loss: 661074.284476607\n",
      "episode: 1769   score: 3404  move: 288   memory length: 5000   epsilon: 0.1045414860291374  loss: 657629.032744368\n",
      "episode: 1770   score: 2628  move: 226   memory length: 5000   epsilon: 0.10430548786908993  loss: 839155.6166023491\n",
      "episode: 1771   score: 796  move: 107   memory length: 5000   epsilon: 0.10419394012801497  loss: 1773510.7435612546\n",
      "episode: 1772   score: 3040  move: 250   memory length: 5000   epsilon: 0.10393377931340923  loss: 760170.2737591096\n",
      "episode: 1773   score: 1340  move: 140   memory length: 5000   epsilon: 0.10378837310343564  loss: 1358571.8343049458\n",
      "episode: 1774   score: 1320  move: 136   memory length: 5000   epsilon: 0.10364731615119879  loss: 1399635.1933671446\n",
      "episode: 1775   score: 1748  move: 178   memory length: 5000   epsilon: 0.10346298710832111  loss: 1070510.9253067917\n",
      "episode: 1776   score: 1436  move: 154   memory length: 5000   epsilon: 0.10330377593618598  loss: 1238458.879186977\n",
      "episode: 1777   score: 2548  move: 213   memory length: 5000   epsilon: 0.10308397196874934  loss: 896513.0018724074\n",
      "episode: 1778   score: 2540  move: 216   memory length: 5000   epsilon: 0.10286154977962751  loss: 885165.6626274145\n",
      "episode: 1779   score: 1412  move: 149   memory length: 5000   epsilon: 0.1027083994300483  loss: 1284267.1091961188\n",
      "episode: 1780   score: 1800  move: 185   memory length: 5000   epsilon: 0.10251856359421399  loss: 1035395.1393766868\n",
      "episode: 1781   score: 816  move: 102   memory length: 5000   epsilon: 0.10241404744906239  loss: 1878982.4939451404\n",
      "episode: 1782   score: 676  move: 88   memory length: 5000   epsilon: 0.10232396228016888  loss: 2179021.408688849\n",
      "episode: 1783   score: 1052  move: 117   memory length: 5000   epsilon: 0.10220431265473248  loss: 1640026.008977026\n",
      "episode: 1784   score: 880  move: 110   memory length: 5000   epsilon: 0.10209194916024636  loss: 1745482.027247377\n",
      "episode: 1785   score: 1956  move: 193   memory length: 5000   epsilon: 0.10189510073395917  loss: 995884.9597213231\n",
      "episode: 1786   score: 1728  move: 159   memory length: 5000   epsilon: 0.1017332154472734  loss: 1209934.9126822273\n",
      "episode: 1787   score: 640  move: 83   memory length: 5000   epsilon: 0.10164881148892033  loss: 2318951.267738664\n",
      "episode: 1788   score: 936  move: 114   memory length: 5000   epsilon: 0.10153299729138686  loss: 1689499.3823051117\n",
      "episode: 1789   score: 1612  move: 163   memory length: 5000   epsilon: 0.10136763248790545  loss: 1182786.6470465397\n",
      "episode: 1790   score: 752  move: 101   memory length: 5000   epsilon: 0.10126530235285876  loss: 1910025.2998332789\n",
      "episode: 1791   score: 1096  move: 120   memory length: 5000   epsilon: 0.10114385626503083  loss: 1608790.512671566\n",
      "episode: 1792   score: 1012  move: 122   memory length: 5000   epsilon: 0.10102053538481559  loss: 1583582.3257923126\n",
      "episode: 1793   score: 1456  move: 154   memory length: 5000   epsilon: 0.10086508271233961  loss: 1255698.3919833542\n",
      "episode: 1794   score: 1356  move: 139   memory length: 5000   epsilon: 0.1007249769429082  loss: 1392367.2534492821\n",
      "episode: 1795   score: 1760  move: 175   memory length: 5000   epsilon: 0.10054886149864034  loss: 1107121.5605124556\n",
      "episode: 1796   score: 660  move: 88   memory length: 5000   epsilon: 0.10046041697959468  loss: 2202868.155767484\n",
      "episode: 1797   score: 1492  move: 157   memory length: 5000   epsilon: 0.10030281708522622  loss: 1235941.231524352\n",
      "episode: 1798   score: 1032  move: 111   memory length: 5000   epsilon: 0.10019154217088926  loss: 1749356.9261701773\n",
      "episode: 1799   score: 828  move: 107   memory length: 5000   epsilon: 0.10008439401950911  loss: 1815963.7847417314\n",
      "episode: 1800   score: 1064  move: 127   memory length: 5000   epsilon: 0.1  loss: 1531203.3513007276\n",
      "episode: 1801   score: 396  move: 67   memory length: 5000   epsilon: 0.1  loss: 2903616.339800308\n",
      "episode: 1802   score: 1136  move: 121   memory length: 5000   epsilon: 0.1  loss: 1609096.2529469954\n",
      "episode: 1803   score: 1424  move: 146   memory length: 5000   epsilon: 0.1  loss: 1334817.972103302\n",
      "episode: 1804   score: 3160  move: 258   memory length: 5000   epsilon: 0.1  loss: 756545.9752124668\n",
      "episode: 1805   score: 824  move: 107   memory length: 5000   epsilon: 0.1  loss: 1825378.299325141\n",
      "episode: 1806   score: 804  move: 101   memory length: 5000   epsilon: 0.1  loss: 1934981.0966297188\n",
      "episode: 1807   score: 756  move: 102   memory length: 5000   epsilon: 0.1  loss: 1917167.3085155487\n",
      "episode: 1808   score: 2808  move: 234   memory length: 5000   epsilon: 0.1  loss: 836917.8628452171\n",
      "episode: 1809   score: 1776  move: 180   memory length: 5000   epsilon: 0.1  loss: 1089191.7182045195\n",
      "episode: 1810   score: 1092  move: 118   memory length: 5000   epsilon: 0.1  loss: 1662642.7322544486\n",
      "episode: 1811   score: 3140  move: 258   memory length: 5000   epsilon: 0.1  loss: 761595.2870410801\n",
      "episode: 1812   score: 916  move: 120   memory length: 5000   epsilon: 0.1  loss: 1638592.003057003\n",
      "episode: 1813   score: 1056  move: 128   memory length: 5000   epsilon: 0.1  loss: 1537353.7935892642\n",
      "episode: 1814   score: 1936  move: 192   memory length: 5000   epsilon: 0.1  loss: 1026058.8402943015\n",
      "episode: 1815   score: 1408  move: 142   memory length: 5000   epsilon: 0.1  loss: 1388487.6404553535\n",
      "episode: 1816   score: 712  move: 92   memory length: 5000   epsilon: 0.1  loss: 2144220.5099641965\n",
      "episode: 1817   score: 2840  move: 232   memory length: 5000   epsilon: 0.1  loss: 851429.3149664813\n",
      "episode: 1818   score: 1444  move: 148   memory length: 5000   epsilon: 0.1  loss: 1335815.1832862287\n",
      "episode: 1819   score: 744  move: 99   memory length: 5000   epsilon: 0.1  loss: 1998126.5873939053\n",
      "episode: 1820   score: 604  move: 83   memory length: 5000   epsilon: 0.1  loss: 2384448.3671752284\n",
      "episode: 1821   score: 1776  move: 184   memory length: 5000   epsilon: 0.1  loss: 1076701.7983800846\n",
      "episode: 1822   score: 636  move: 88   memory length: 5000   epsilon: 0.1  loss: 2252447.432700634\n",
      "episode: 1823   score: 1360  move: 141   memory length: 5000   epsilon: 0.1  loss: 1406905.5425264887\n",
      "episode: 1824   score: 776  move: 101   memory length: 5000   epsilon: 0.1  loss: 1965228.7702354582\n",
      "episode: 1825   score: 2628  move: 221   memory length: 5000   epsilon: 0.1  loss: 899274.4660510068\n",
      "episode: 1826   score: 3452  move: 294   memory length: 5000   epsilon: 0.1  loss: 677179.1012175294\n",
      "episode: 1827   score: 504  move: 73   memory length: 5000   epsilon: 0.1  loss: 2728485.5467255996\n",
      "episode: 1828   score: 1444  move: 150   memory length: 5000   epsilon: 0.1  loss: 1329004.483816045\n",
      "episode: 1829   score: 1460  move: 150   memory length: 5000   epsilon: 0.1  loss: 1330145.324877243\n",
      "episode: 1830   score: 576  move: 79   memory length: 5000   epsilon: 0.1  loss: 2526746.9571775123\n",
      "episode: 1831   score: 692  move: 91   memory length: 5000   epsilon: 0.1  loss: 2194706.8050264213\n",
      "episode: 1832   score: 1464  move: 150   memory length: 5000   epsilon: 0.1  loss: 1332593.5892506153\n",
      "episode: 1833   score: 1232  move: 129   memory length: 5000   epsilon: 0.1  loss: 1550658.2792047604\n",
      "episode: 1834   score: 1124  move: 120   memory length: 5000   epsilon: 0.1  loss: 1668083.9295411746\n",
      "episode: 1835   score: 1296  move: 134   memory length: 5000   epsilon: 0.1  loss: 1494909.1900781945\n",
      "episode: 1836   score: 2672  move: 232   memory length: 5000   epsilon: 0.1  loss: 864606.434622222\n",
      "episode: 1837   score: 1052  move: 114   memory length: 5000   epsilon: 0.1  loss: 1760719.6403419427\n",
      "episode: 1838   score: 1216  move: 130   memory length: 5000   epsilon: 0.1  loss: 1545206.0522406064\n",
      "episode: 1839   score: 460  move: 70   memory length: 5000   epsilon: 0.1  loss: 2870838.3088085176\n",
      "episode: 1840   score: 2060  move: 190   memory length: 5000   epsilon: 0.1  loss: 1058858.3597946367\n",
      "episode: 1841   score: 836  move: 106   memory length: 5000   epsilon: 0.1  loss: 1899167.7566132816\n",
      "episode: 1842   score: 928  move: 113   memory length: 5000   epsilon: 0.1  loss: 1782693.806239474\n",
      "episode: 1843   score: 3484  move: 294   memory length: 5000   epsilon: 0.1  loss: 686421.1430558834\n",
      "episode: 1844   score: 1220  move: 137   memory length: 5000   epsilon: 0.1  loss: 1474303.006572779\n",
      "episode: 1845   score: 2356  move: 198   memory length: 5000   epsilon: 0.1  loss: 1021398.9355019656\n",
      "episode: 1846   score: 1180  move: 128   memory length: 5000   epsilon: 0.1  loss: 1581283.767634064\n",
      "episode: 1847   score: 1564  move: 165   memory length: 5000   epsilon: 0.1  loss: 1227999.2322244586\n",
      "episode: 1848   score: 856  move: 102   memory length: 5000   epsilon: 0.1  loss: 1987774.1889285294\n",
      "episode: 1849   score: 1584  move: 157   memory length: 5000   epsilon: 0.1  loss: 1292721.4930277297\n",
      "episode: 1850   score: 1200  move: 129   memory length: 5000   epsilon: 0.1  loss: 1574663.046566187\n",
      "episode: 1851   score: 384  move: 69   memory length: 5000   epsilon: 0.1  loss: 2945223.921740822\n",
      "episode: 1852   score: 896  move: 119   memory length: 5000   epsilon: 0.1  loss: 1709075.6498183883\n",
      "episode: 1853   score: 792  move: 101   memory length: 5000   epsilon: 0.1  loss: 2015029.3646798087\n",
      "episode: 1854   score: 1632  move: 165   memory length: 5000   epsilon: 0.1  loss: 1234798.489233884\n",
      "episode: 1855   score: 1176  move: 128   memory length: 5000   epsilon: 0.1  loss: 1593155.3243409693\n",
      "episode: 1856   score: 2472  move: 210   memory length: 5000   epsilon: 0.1  loss: 972466.6901333218\n",
      "episode: 1857   score: 1548  move: 162   memory length: 5000   epsilon: 0.1  loss: 1262014.402421857\n",
      "episode: 1858   score: 800  move: 108   memory length: 5000   epsilon: 0.1  loss: 1894472.6730037618\n",
      "episode: 1859   score: 1120  move: 119   memory length: 5000   epsilon: 0.1  loss: 1720741.5200202044\n",
      "episode: 1860   score: 1208  move: 131   memory length: 5000   epsilon: 0.1  loss: 1564550.4110672637\n",
      "episode: 1861   score: 3188  move: 262   memory length: 5000   epsilon: 0.1  loss: 783697.0750041263\n",
      "episode: 1862   score: 3096  move: 259   memory length: 5000   epsilon: 0.1  loss: 794222.1179918709\n",
      "episode: 1863   score: 1388  move: 142   memory length: 5000   epsilon: 0.1  loss: 1450075.9871449268\n",
      "episode: 1864   score: 960  move: 116   memory length: 5000   epsilon: 0.1  loss: 1776544.44629291\n",
      "episode: 1865   score: 1396  move: 144   memory length: 5000   epsilon: 0.1  loss: 1432541.1047462092\n",
      "episode: 1866   score: 572  move: 78   memory length: 5000   epsilon: 0.1  loss: 2646121.1964685\n",
      "episode: 1867   score: 1732  move: 179   memory length: 5000   epsilon: 0.1  loss: 1154482.2521336093\n",
      "episode: 1868   score: 780  move: 101   memory length: 5000   epsilon: 0.1  loss: 2047478.3535937697\n",
      "episode: 1869   score: 1776  move: 179   memory length: 5000   epsilon: 0.1  loss: 1156651.2588611154\n",
      "episode: 1870   score: 1400  move: 143   memory length: 5000   epsilon: 0.1  loss: 1449186.871803684\n",
      "episode: 1871   score: 1544  move: 158   memory length: 5000   epsilon: 0.1  loss: 1312923.6856725428\n",
      "episode: 1872   score: 1124  move: 133   memory length: 5000   epsilon: 0.1  loss: 1561014.4367369744\n",
      "episode: 1873   score: 2284  move: 220   memory length: 5000   epsilon: 0.1  loss: 944968.1125916394\n",
      "episode: 1874   score: 1596  move: 161   memory length: 5000   epsilon: 0.1  loss: 1292513.1481252399\n",
      "episode: 1875   score: 716  move: 97   memory length: 5000   epsilon: 0.1  loss: 2146517.9815392643\n",
      "episode: 1876   score: 908  move: 115   memory length: 5000   epsilon: 0.1  loss: 1811732.2773301166\n",
      "episode: 1877   score: 1720  move: 161   memory length: 5000   epsilon: 0.1  loss: 1295277.1542276181\n",
      "episode: 1878   score: 1384  move: 143   memory length: 5000   epsilon: 0.1  loss: 1459496.0418079349\n",
      "episode: 1879   score: 1688  move: 177   memory length: 5000   epsilon: 0.1  loss: 1180317.996418689\n",
      "episode: 1880   score: 1988  move: 198   memory length: 5000   epsilon: 0.1  loss: 1056251.7016096981\n",
      "episode: 1881   score: 1448  move: 150   memory length: 5000   epsilon: 0.1  loss: 1395380.1710157522\n",
      "episode: 1882   score: 944  move: 112   memory length: 5000   epsilon: 0.1  loss: 1869923.454994917\n",
      "episode: 1883   score: 888  move: 110   memory length: 5000   epsilon: 0.1  loss: 1904985.023813872\n",
      "episode: 1884   score: 1408  move: 156   memory length: 5000   epsilon: 0.1  loss: 1344307.7870711547\n",
      "episode: 1885   score: 700  move: 92   memory length: 5000   epsilon: 0.1  loss: 2280488.9697002326\n",
      "episode: 1886   score: 956  move: 99   memory length: 5000   epsilon: 0.1  loss: 2120266.3679213477\n",
      "episode: 1887   score: 728  move: 95   memory length: 5000   epsilon: 0.1  loss: 2210539.5536546004\n",
      "episode: 1888   score: 1688  move: 164   memory length: 5000   epsilon: 0.1  loss: 1281484.9524109305\n",
      "episode: 1889   score: 608  move: 80   memory length: 5000   epsilon: 0.1  loss: 2628030.9312365055\n",
      "episode: 1890   score: 2948  move: 253   memory length: 5000   epsilon: 0.1  loss: 831995.4671781185\n",
      "episode: 1891   score: 2704  move: 229   memory length: 5000   epsilon: 0.1  loss: 920165.3321613994\n",
      "episode: 1892   score: 516  move: 77   memory length: 5000   epsilon: 0.1  loss: 2737582.2518852036\n",
      "episode: 1893   score: 1396  move: 146   memory length: 5000   epsilon: 0.1  loss: 1444796.6852209275\n",
      "episode: 1894   score: 3096  move: 258   memory length: 5000   epsilon: 0.1  loss: 818586.8904880997\n",
      "episode: 1895   score: 956  move: 119   memory length: 5000   epsilon: 0.1  loss: 1775759.520579266\n",
      "episode: 1896   score: 1968  move: 194   memory length: 5000   epsilon: 0.1  loss: 1090235.2579091848\n",
      "episode: 1897   score: 596  move: 83   memory length: 5000   epsilon: 0.1  loss: 2549240.1710464754\n",
      "episode: 1898   score: 1280  move: 136   memory length: 5000   epsilon: 0.1  loss: 1556731.5473364943\n",
      "episode: 1899   score: 1440  move: 150   memory length: 5000   epsilon: 0.1  loss: 1412375.1249126433\n",
      "episode: 1900   score: 1052  move: 113   memory length: 5000   epsilon: 0.1  loss: 1875769.0874554457\n",
      "episode: 1901   score: 920  move: 112   memory length: 5000   epsilon: 0.1  loss: 1893474.3483223575\n",
      "episode: 1902   score: 2012  move: 195   memory length: 5000   epsilon: 0.1  loss: 1088461.7840138949\n",
      "episode: 1903   score: 884  move: 108   memory length: 5000   epsilon: 0.1  loss: 1966168.944287512\n",
      "episode: 1904   score: 716  move: 93   memory length: 5000   epsilon: 0.1  loss: 2284167.020441732\n",
      "episode: 1905   score: 2996  move: 245   memory length: 5000   epsilon: 0.1  loss: 867936.6096468711\n",
      "episode: 1906   score: 736  move: 96   memory length: 5000   epsilon: 0.1  loss: 2215986.199141383\n",
      "episode: 1907   score: 1444  move: 150   memory length: 5000   epsilon: 0.1  loss: 1419151.4190732066\n",
      "episode: 1908   score: 1380  move: 141   memory length: 5000   epsilon: 0.1  loss: 1510670.0231190403\n",
      "episode: 1909   score: 1476  move: 154   memory length: 5000   epsilon: 0.1  loss: 1384095.2660729792\n",
      "episode: 1910   score: 2964  move: 245   memory length: 5000   epsilon: 0.1  loss: 870933.9976433734\n",
      "episode: 1911   score: 800  move: 107   memory length: 5000   epsilon: 0.1  loss: 1995147.218934995\n",
      "episode: 1912   score: 3464  move: 291   memory length: 5000   epsilon: 0.1  loss: 734545.9484446548\n",
      "episode: 1913   score: 1456  move: 152   memory length: 5000   epsilon: 0.1  loss: 1407217.3787333088\n",
      "episode: 1914   score: 2408  move: 206   memory length: 5000   epsilon: 0.1  loss: 1039298.981833245\n",
      "episode: 1915   score: 1588  move: 165   memory length: 5000   epsilon: 0.1  loss: 1298507.6172279357\n",
      "episode: 1916   score: 596  move: 82   memory length: 5000   epsilon: 0.1  loss: 2613808.5337742595\n",
      "episode: 1917   score: 2508  move: 218   memory length: 5000   epsilon: 0.1  loss: 984144.862795016\n",
      "episode: 1918   score: 888  move: 118   memory length: 5000   epsilon: 0.1  loss: 1819143.2858288328\n",
      "episode: 1919   score: 1396  move: 153   memory length: 5000   epsilon: 0.1  loss: 1403945.4459772296\n",
      "episode: 1920   score: 3096  move: 259   memory length: 5000   epsilon: 0.1  loss: 830319.6905763397\n",
      "episode: 1921   score: 1744  move: 180   memory length: 5000   epsilon: 0.1  loss: 1195744.9368351619\n",
      "episode: 1922   score: 1476  move: 154   memory length: 5000   epsilon: 0.1  loss: 1398620.98662312\n",
      "episode: 1923   score: 1156  move: 126   memory length: 5000   epsilon: 0.1  loss: 1710405.1619511256\n",
      "episode: 1924   score: 476  move: 76   memory length: 5000   epsilon: 0.1  loss: 2836631.061913189\n",
      "episode: 1925   score: 1768  move: 188   memory length: 5000   epsilon: 0.1  loss: 1147737.9303729483\n",
      "episode: 1926   score: 1444  move: 150   memory length: 5000   epsilon: 0.1  loss: 1439477.2359376273\n",
      "episode: 1927   score: 1456  move: 154   memory length: 5000   epsilon: 0.1  loss: 1403037.144216686\n",
      "episode: 1928   score: 1296  move: 141   memory length: 5000   epsilon: 0.1  loss: 1533347.1678593683\n",
      "episode: 1929   score: 1644  move: 164   memory length: 5000   epsilon: 0.1  loss: 1319273.3709137382\n",
      "episode: 1930   score: 1280  move: 136   memory length: 5000   epsilon: 0.1  loss: 1591856.7034285208\n",
      "episode: 1931   score: 3048  move: 252   memory length: 5000   epsilon: 0.1  loss: 860069.9109391258\n",
      "episode: 1932   score: 2388  move: 201   memory length: 5000   epsilon: 0.1  loss: 1079287.1459785765\n",
      "episode: 1933   score: 1356  move: 143   memory length: 5000   epsilon: 0.1  loss: 1518059.0678818976\n",
      "episode: 1934   score: 2568  move: 219   memory length: 5000   epsilon: 0.1  loss: 992234.6050067536\n",
      "episode: 1935   score: 2340  move: 195   memory length: 5000   epsilon: 0.1  loss: 1115336.1971931066\n",
      "episode: 1936   score: 1564  move: 157   memory length: 5000   epsilon: 0.1  loss: 1386237.0178624294\n",
      "episode: 1937   score: 1624  move: 149   memory length: 5000   epsilon: 0.1  loss: 1461596.1030131346\n",
      "episode: 1938   score: 1480  move: 155   memory length: 5000   epsilon: 0.1  loss: 1405946.588029357\n",
      "episode: 1939   score: 900  move: 107   memory length: 5000   epsilon: 0.1  loss: 2037608.451143532\n",
      "episode: 1940   score: 1624  move: 172   memory length: 5000   epsilon: 0.1  loss: 1268533.027832142\n",
      "episode: 1941   score: 1808  move: 174   memory length: 5000   epsilon: 0.1  loss: 1254919.5844124323\n",
      "episode: 1942   score: 1396  move: 145   memory length: 5000   epsilon: 0.1  loss: 1506824.8226795327\n",
      "episode: 1943   score: 1276  move: 135   memory length: 5000   epsilon: 0.1  loss: 1619364.68663299\n",
      "episode: 1944   score: 1888  move: 195   memory length: 5000   epsilon: 0.1  loss: 1122019.9031297928\n",
      "episode: 1945   score: 2400  move: 201   memory length: 5000   epsilon: 0.1  loss: 1089452.6208572958\n",
      "episode: 1946   score: 900  move: 114   memory length: 5000   epsilon: 0.1  loss: 1921793.0747430702\n",
      "episode: 1947   score: 2040  move: 188   memory length: 5000   epsilon: 0.1  loss: 1166250.2497988152\n",
      "episode: 1948   score: 932  move: 113   memory length: 5000   epsilon: 0.1  loss: 1941225.8977322537\n",
      "episode: 1949   score: 1440  move: 150   memory length: 5000   epsilon: 0.1  loss: 1463272.265683314\n",
      "episode: 1950   score: 716  move: 92   memory length: 5000   epsilon: 0.1  loss: 2386649.635306524\n",
      "episode: 1951   score: 1084  move: 131   memory length: 5000   epsilon: 0.1  loss: 1677007.6077840382\n",
      "episode: 1952   score: 408  move: 58   memory length: 5000   epsilon: 0.1  loss: 3788617.564591309\n",
      "episode: 1953   score: 1580  move: 154   memory length: 5000   epsilon: 0.1  loss: 1427782.5512557835\n",
      "episode: 1954   score: 936  move: 114   memory length: 5000   epsilon: 0.1  loss: 1929655.6345730496\n",
      "episode: 1955   score: 2044  move: 196   memory length: 5000   epsilon: 0.1  loss: 1123267.7762364952\n",
      "episode: 1956   score: 988  move: 101   memory length: 5000   epsilon: 0.1  loss: 2180749.6506742346\n",
      "episode: 1957   score: 1204  move: 137   memory length: 5000   epsilon: 0.1  loss: 1608638.9465262142\n",
      "episode: 1958   score: 1024  move: 122   memory length: 5000   epsilon: 0.1  loss: 1807329.4512510768\n",
      "episode: 1959   score: 1484  move: 155   memory length: 5000   epsilon: 0.1  loss: 1423451.4718629161\n",
      "episode: 1960   score: 404  move: 66   memory length: 5000   epsilon: 0.1  loss: 3343815.8422521534\n",
      "episode: 1961   score: 628  move: 84   memory length: 5000   epsilon: 0.1  loss: 2628192.3955763406\n",
      "episode: 1962   score: 436  move: 70   memory length: 5000   epsilon: 0.1  loss: 3154780.344346673\n",
      "episode: 1963   score: 2696  move: 213   memory length: 5000   epsilon: 0.1  loss: 1037722.5348061754\n",
      "episode: 1964   score: 1460  move: 153   memory length: 5000   epsilon: 0.1  loss: 1445629.8863594455\n",
      "episode: 1965   score: 1292  move: 131   memory length: 5000   epsilon: 0.1  loss: 1689397.7515609683\n",
      "episode: 1966   score: 1368  move: 134   memory length: 5000   epsilon: 0.1  loss: 1652536.2970955977\n",
      "episode: 1967   score: 824  move: 107   memory length: 5000   epsilon: 0.1  loss: 2070475.1500719374\n",
      "episode: 1968   score: 996  move: 119   memory length: 5000   epsilon: 0.1  loss: 1862637.8116469504\n",
      "episode: 1969   score: 3364  move: 278   memory length: 5000   epsilon: 0.1  loss: 798252.3298477749\n",
      "episode: 1970   score: 1468  move: 154   memory length: 5000   epsilon: 0.1  loss: 1441974.1273703885\n",
      "episode: 1971   score: 216  move: 46   memory length: 5000   epsilon: 0.1  loss: 4828430.238927178\n",
      "episode: 1972   score: 696  move: 93   memory length: 5000   epsilon: 0.1  loss: 2389239.4155856306\n",
      "episode: 1973   score: 1604  move: 168   memory length: 5000   epsilon: 0.1  loss: 1323611.6267009235\n",
      "episode: 1974   score: 1724  move: 163   memory length: 5000   epsilon: 0.1  loss: 1365179.7821609639\n",
      "episode: 1975   score: 1336  move: 137   memory length: 5000   epsilon: 0.1  loss: 1625231.6021749957\n",
      "episode: 1976   score: 2964  move: 244   memory length: 5000   epsilon: 0.1  loss: 913468.2939315076\n",
      "episode: 1977   score: 1332  move: 139   memory length: 5000   epsilon: 0.1  loss: 1604433.4777681914\n",
      "episode: 1978   score: 628  move: 86   memory length: 5000   epsilon: 0.1  loss: 2594152.250186521\n",
      "episode: 1979   score: 3520  move: 295   memory length: 5000   epsilon: 0.1  loss: 757229.3122479584\n",
      "episode: 1980   score: 1360  move: 136   memory length: 5000   epsilon: 0.1  loss: 1643508.5827716659\n",
      "episode: 1981   score: 564  move: 77   memory length: 5000   epsilon: 0.1  loss: 2903809.6514066723\n",
      "episode: 1982   score: 1864  move: 186   memory length: 5000   epsilon: 0.1  loss: 1203075.1754612462\n",
      "episode: 1983   score: 696  move: 92   memory length: 5000   epsilon: 0.1  loss: 2433262.960892926\n",
      "episode: 1984   score: 1520  move: 157   memory length: 5000   epsilon: 0.1  loss: 1426830.2094655856\n",
      "episode: 1985   score: 3332  move: 269   memory length: 5000   epsilon: 0.1  loss: 833732.4976307043\n",
      "episode: 1986   score: 600  move: 83   memory length: 5000   epsilon: 0.1  loss: 2703068.3727856833\n",
      "episode: 1987   score: 2376  move: 202   memory length: 5000   epsilon: 0.1  loss: 1111652.0989330972\n",
      "episode: 1988   score: 3060  move: 251   memory length: 5000   epsilon: 0.1  loss: 895611.681810797\n",
      "episode: 1989   score: 2092  move: 190   memory length: 5000   epsilon: 0.1  loss: 1184114.279329581\n",
      "episode: 1990   score: 2368  move: 201   memory length: 5000   epsilon: 0.1  loss: 1120292.497819075\n",
      "episode: 1991   score: 540  move: 84   memory length: 5000   epsilon: 0.1  loss: 2681657.3734325683\n",
      "episode: 1992   score: 1552  move: 160   memory length: 5000   epsilon: 0.1  loss: 1408868.8035369157\n",
      "episode: 1993   score: 1988  move: 192   memory length: 5000   epsilon: 0.1  loss: 1175017.8982848525\n",
      "episode: 1994   score: 672  move: 90   memory length: 5000   epsilon: 0.1  loss: 2507643.8906364017\n",
      "episode: 1995   score: 1432  move: 147   memory length: 5000   epsilon: 0.1  loss: 1536221.7003065096\n",
      "episode: 1996   score: 1548  move: 150   memory length: 5000   epsilon: 0.1  loss: 1506426.5534947969\n",
      "episode: 1997   score: 2696  move: 233   memory length: 5000   epsilon: 0.1  loss: 970725.6057398227\n",
      "episode: 1998   score: 1312  move: 137   memory length: 5000   epsilon: 0.1  loss: 1651870.6944877736\n",
      "episode: 1999   score: 2584  move: 223   memory length: 5000   epsilon: 0.1  loss: 1015736.3500560025\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = Env()\n",
    "    state_size = 16\n",
    "    action_size = 4\n",
    "    load_model = False\n",
    "    agent = DQNAgent(state_size, action_size, load_model)\n",
    "    Top = -np.inf\n",
    "    scores, episodes = [], []\n",
    "    lossss = []\n",
    "    EPISODES=2000\n",
    "    for e in range(EPISODES):\n",
    "        done=False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        maxScore = -np.inf\n",
    "        move =0\n",
    "        while not done:\n",
    "#             if agent.render:\n",
    "#             print(env.render())\n",
    "            move+=1\n",
    "            # get action for the current state and go one step in environment\n",
    "            action = agent.get_action(state, env)\n",
    "#             print(np.array(env.board))\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            # if an action make the episode end, then gives penalty of -100\n",
    "#             reward = reward if not done or score == 499 else agent.penalty\n",
    "#             print({0 : 'left', 1:'up' , 2:'right', 3:'down'}[action])\n",
    "            # save the sample <s, a, r, s'> to the replay memory\n",
    "            agent.append_sample(state, action, reward, next_state, done)\n",
    "            # every time step do the training\n",
    "            if agent.load_model is False and (len(agent.memory) >= agent.train_start):\n",
    "                agent.train_model()\n",
    "                \n",
    "            score += reward\n",
    "            state = next_state\n",
    "            if(reward > maxScore):\n",
    "                maxScore = reward\n",
    "            if done:\n",
    "                # every episode update the target model to be same with model\n",
    "                if agent.load_model is False:\n",
    "                    agent.update_target_model()\n",
    "                lossss.append(agent.train_loss/move)\n",
    "                # every episode, plot the play time\n",
    "#                 score = score if score == 500 else score + 100\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                print(\"episode:\", e, \"  score:\", score, \" move:\", move,\"  memory length:\", len(agent.memory), \"  epsilon:\", agent.epsilon, ' loss:', agent.train_loss/move)\n",
    "                if (maxScore > Top) and not (load_model):\n",
    "                        Top = maxScore\n",
    "                        print('Weights save... Top reward = {}'.format(maxScore))\n",
    "                        torch.save(agent.model.state_dict(), './save_model/2048_dqn_trained.pth')\n",
    "    pylab.plot(episodes, scores, 'b')\n",
    "    pylab.title('Score per episode')\n",
    "    pylab.savefig('save_plt/Learning_rate={},epsilon_min={},Discount_factor={},episod={}.png'.format(agent.learning_rate, agent.epsilon_min, agent.discount_factor, e+1), dpi=300, facecolor='w')\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "innocent-counter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_loaded...\n",
      "Top reward = 128\n",
      "episode: 0   score: 1768  move: 181   memory length: 181   epsilon: 0  loss: 0.0\n",
      "Top reward = 96\n",
      "episode: 1   score: 1360  move: 150   memory length: 331   epsilon: 0  loss: 0.0\n",
      "Top reward = 132\n",
      "episode: 2   score: 1596  move: 157   memory length: 488   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 3   score: 1384  move: 142   memory length: 630   epsilon: 0  loss: 0.0\n",
      "Top reward = 140\n",
      "episode: 4   score: 1672  move: 167   memory length: 797   epsilon: 0  loss: 0.0\n",
      "Top reward = 516\n",
      "episode: 5   score: 5400  move: 378   memory length: 1175   epsilon: 0  loss: 0.0\n",
      "Top reward = 288\n",
      "episode: 6   score: 2804  move: 244   memory length: 1419   epsilon: 0  loss: 0.0\n",
      "Top reward = 144\n",
      "episode: 7   score: 1984  move: 189   memory length: 1608   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 8   score: 1804  move: 186   memory length: 1794   epsilon: 0  loss: 0.0\n",
      "Top reward = 152\n",
      "episode: 9   score: 1372  move: 144   memory length: 1938   epsilon: 0  loss: 0.0\n",
      "Top reward = 268\n",
      "episode: 10   score: 3344  move: 280   memory length: 2218   epsilon: 0  loss: 0.0\n",
      "Top reward = 132\n",
      "episode: 11   score: 1668  move: 169   memory length: 2387   epsilon: 0  loss: 0.0\n",
      "Top reward = 268\n",
      "episode: 12   score: 3060  move: 251   memory length: 2638   epsilon: 0  loss: 0.0\n",
      "Top reward = 528\n",
      "episode: 13   score: 5236  move: 354   memory length: 2992   epsilon: 0  loss: 0.0\n",
      "Top reward = 512\n",
      "episode: 14   score: 4856  move: 331   memory length: 3323   epsilon: 0  loss: 0.0\n",
      "Top reward = 96\n",
      "episode: 15   score: 1360  move: 150   memory length: 3473   epsilon: 0  loss: 0.0\n",
      "Top reward = 272\n",
      "episode: 16   score: 2388  move: 205   memory length: 3678   epsilon: 0  loss: 0.0\n",
      "Top reward = 108\n",
      "episode: 17   score: 1044  move: 125   memory length: 3803   epsilon: 0  loss: 0.0\n",
      "Top reward = 276\n",
      "episode: 18   score: 3932  move: 321   memory length: 4124   epsilon: 0  loss: 0.0\n",
      "Top reward = 264\n",
      "episode: 19   score: 3084  move: 257   memory length: 4381   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 20   score: 3076  move: 254   memory length: 4635   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 21   score: 3120  move: 260   memory length: 4895   epsilon: 0  loss: 0.0\n",
      "Top reward = 268\n",
      "episode: 22   score: 2904  move: 242   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 540\n",
      "episode: 23   score: 6588  move: 455   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 268\n",
      "episode: 24   score: 3084  move: 266   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 25   score: 2804  move: 244   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 26   score: 1504  move: 153   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 136\n",
      "episode: 27   score: 1720  move: 175   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 292\n",
      "episode: 28   score: 2832  move: 252   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 152\n",
      "episode: 29   score: 1860  move: 188   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 288\n",
      "episode: 30   score: 3400  move: 282   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 264\n",
      "episode: 31   score: 6104  move: 475   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 516\n",
      "episode: 32   score: 4664  move: 322   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 276\n",
      "episode: 33   score: 3776  move: 311   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 136\n",
      "episode: 34   score: 1456  move: 152   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 156\n",
      "episode: 35   score: 2464  move: 220   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 36   score: 2044  move: 199   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 152\n",
      "episode: 37   score: 1460  move: 149   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 148\n",
      "episode: 38   score: 2196  move: 206   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 276\n",
      "episode: 39   score: 3168  move: 260   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 40   score: 2696  move: 227   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 41   score: 1720  move: 176   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 42   score: 2356  move: 229   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 43   score: 1692  move: 176   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 136\n",
      "episode: 44   score: 1620  move: 173   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 264\n",
      "episode: 45   score: 4092  move: 341   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 148\n",
      "episode: 46   score: 1800  move: 179   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 47   score: 2908  move: 239   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 48   score: 3212  move: 270   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 576\n",
      "episode: 49   score: 5084  move: 362   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 148\n",
      "episode: 50   score: 1704  move: 177   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 268\n",
      "episode: 51   score: 2944  move: 245   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 64\n",
      "episode: 52   score: 744  move: 99   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 268\n",
      "episode: 53   score: 3316  move: 280   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 192\n",
      "episode: 54   score: 1720  move: 176   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 132\n",
      "episode: 55   score: 1452  move: 148   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 64\n",
      "episode: 56   score: 648  move: 91   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 57   score: 1356  move: 139   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 180\n",
      "episode: 58   score: 1712  move: 173   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 59   score: 2284  move: 218   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 60   score: 2536  move: 211   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 152\n",
      "episode: 61   score: 1840  move: 185   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 264\n",
      "episode: 62   score: 2808  move: 244   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 152\n",
      "episode: 63   score: 2188  move: 208   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 544\n",
      "episode: 64   score: 5320  move: 367   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 276\n",
      "episode: 65   score: 3964  move: 306   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 66   score: 1552  move: 160   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 67   score: 2808  move: 245   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 304\n",
      "episode: 68   score: 3532  move: 295   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 69   score: 1428  move: 146   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 140\n",
      "episode: 70   score: 1444  move: 150   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 308\n",
      "episode: 71   score: 2932  move: 259   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 232\n",
      "episode: 72   score: 1824  move: 186   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 73   score: 2236  move: 184   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 74   score: 2672  move: 229   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 144\n",
      "episode: 75   score: 1916  move: 184   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 288\n",
      "episode: 76   score: 4068  move: 329   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 77   score: 3568  move: 306   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 78   score: 3392  move: 284   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 132\n",
      "episode: 79   score: 1884  move: 190   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 384\n",
      "episode: 80   score: 3636  move: 298   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 81   score: 2276  move: 190   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 136\n",
      "episode: 82   score: 1832  move: 190   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 280\n",
      "episode: 83   score: 2616  move: 230   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 284\n",
      "episode: 84   score: 2776  move: 242   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 264\n",
      "episode: 85   score: 3180  move: 264   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 288\n",
      "episode: 86   score: 3368  move: 279   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 72\n",
      "episode: 87   score: 720  move: 94   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 132\n",
      "episode: 88   score: 1328  move: 137   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 72\n",
      "episode: 89   score: 644  move: 85   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 132\n",
      "episode: 90   score: 1800  move: 186   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 91   score: 2488  move: 210   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 92   score: 1412  move: 146   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 276\n",
      "episode: 93   score: 3444  move: 285   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 94   score: 2836  move: 233   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 95   score: 2472  move: 215   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 264\n",
      "episode: 96   score: 2940  move: 240   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 97   score: 3100  move: 256   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 140\n",
      "episode: 98   score: 1132  move: 124   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 264\n",
      "episode: 99   score: 3148  move: 262   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 100   score: 2044  move: 171   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 264\n",
      "episode: 101   score: 2940  move: 260   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 264\n",
      "episode: 102   score: 3336  move: 271   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 103   score: 3068  move: 251   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 104   score: 1400  move: 150   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 104\n",
      "episode: 105   score: 1120  move: 132   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 164\n",
      "episode: 106   score: 1896  move: 190   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 288\n",
      "episode: 107   score: 3196  move: 257   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 324\n",
      "episode: 108   score: 3264  move: 273   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 264\n",
      "episode: 109   score: 3180  move: 264   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 196\n",
      "episode: 110   score: 1588  move: 159   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 272\n",
      "episode: 111   score: 3068  move: 252   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 112   score: 2884  move: 248   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 113   score: 2908  move: 234   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 114   score: 2652  move: 224   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 148\n",
      "episode: 115   score: 2024  move: 200   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 136\n",
      "episode: 116   score: 1572  move: 165   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 76\n",
      "episode: 117   score: 1048  move: 126   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 140\n",
      "episode: 118   score: 1400  move: 144   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 119   score: 3348  move: 285   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 512\n",
      "episode: 120   score: 4972  move: 352   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 144\n",
      "episode: 121   score: 2340  move: 227   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 122   score: 3260  move: 278   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 140\n",
      "episode: 123   score: 2260  move: 215   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 40\n",
      "episode: 124   score: 512  move: 79   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 125   score: 2812  move: 246   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 144\n",
      "episode: 126   score: 1224  move: 131   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 127   score: 3340  move: 281   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 116\n",
      "episode: 128   score: 760  move: 102   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 129   score: 1480  move: 153   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 320\n",
      "episode: 130   score: 3128  move: 269   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 131   score: 1644  move: 164   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 292\n",
      "episode: 132   score: 2628  move: 222   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 140\n",
      "episode: 133   score: 2396  move: 224   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 172\n",
      "episode: 134   score: 1496  move: 152   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 264\n",
      "episode: 135   score: 3112  move: 259   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 136   score: 2268  move: 196   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 137   score: 2964  move: 260   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 138   score: 1732  move: 174   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 136\n",
      "episode: 139   score: 1124  move: 119   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 148\n",
      "episode: 140   score: 1936  move: 189   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 264\n",
      "episode: 141   score: 2244  move: 183   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 142   score: 2052  move: 170   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 132\n",
      "episode: 143   score: 1756  move: 165   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 144   score: 1868  move: 188   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 145   score: 2584  move: 221   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 146   score: 1724  move: 172   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 147   score: 2628  move: 232   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 148   score: 3064  move: 252   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 276\n",
      "episode: 149   score: 5388  move: 412   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 396\n",
      "episode: 150   score: 3028  move: 246   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 151   score: 2544  move: 217   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 208\n",
      "episode: 152   score: 2396  move: 220   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 64\n",
      "episode: 153   score: 720  move: 97   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 148\n",
      "episode: 154   score: 1808  move: 173   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 264\n",
      "episode: 155   score: 2396  move: 204   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 92\n",
      "episode: 156   score: 1140  move: 137   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 152\n",
      "episode: 157   score: 1776  move: 183   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 144\n",
      "episode: 158   score: 1388  move: 138   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 144\n",
      "episode: 159   score: 2632  move: 237   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 280\n",
      "episode: 160   score: 2888  move: 239   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 161   score: 1488  move: 155   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 162   score: 1920  move: 188   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 160\n",
      "episode: 163   score: 1320  move: 142   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 268\n",
      "episode: 164   score: 2880  move: 251   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 165   score: 3448  move: 294   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 166   score: 2292  move: 191   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 528\n",
      "episode: 167   score: 4788  move: 336   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 156\n",
      "episode: 168   score: 1328  move: 137   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 268\n",
      "episode: 169   score: 2692  move: 229   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 272\n",
      "episode: 170   score: 3048  move: 272   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 171   score: 2744  move: 235   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 172   score: 2792  move: 227   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 76\n",
      "episode: 173   score: 1348  move: 153   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 280\n",
      "episode: 174   score: 3112  move: 258   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 276\n",
      "episode: 175   score: 3464  move: 285   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 176   score: 3092  move: 261   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 64\n",
      "episode: 177   score: 1024  move: 120   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 256\n",
      "episode: 178   score: 3132  move: 255   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 272\n",
      "episode: 179   score: 2944  move: 258   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 32\n",
      "episode: 180   score: 320  move: 58   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 288\n",
      "episode: 181   score: 3320  move: 281   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 144\n",
      "episode: 182   score: 1448  move: 150   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 280\n",
      "episode: 183   score: 2776  move: 239   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 148\n",
      "episode: 184   score: 1688  move: 174   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 185   score: 1472  move: 152   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 68\n",
      "episode: 186   score: 872  move: 110   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 260\n",
      "episode: 187   score: 4016  move: 324   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 128\n",
      "episode: 188   score: 1208  move: 136   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 112\n",
      "episode: 189   score: 1044  move: 124   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 320\n",
      "episode: 190   score: 3000  move: 240   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 132\n",
      "episode: 191   score: 1744  move: 176   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 280\n",
      "episode: 192   score: 2648  move: 224   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 268\n",
      "episode: 193   score: 4264  move: 337   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 268\n",
      "episode: 194   score: 2948  move: 247   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 144\n",
      "episode: 195   score: 1436  move: 149   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 320\n",
      "episode: 196   score: 2612  move: 228   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 148\n",
      "episode: 197   score: 1476  move: 153   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 276\n",
      "episode: 198   score: 2828  move: 230   memory length: 5000   epsilon: 0  loss: 0.0\n",
      "Top reward = 48\n",
      "episode: 199   score: 540  move: 79   memory length: 5000   epsilon: 0  loss: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = Env()\n",
    "    state_size = 16\n",
    "    action_size = 4\n",
    "    load_model = True\n",
    "    agent = DQNAgent(state_size, action_size, load_model)\n",
    "    Top = -np.inf\n",
    "    scores, episodes = [], []\n",
    "    lossss = []\n",
    "    EPISODES=200\n",
    "    for e in range(EPISODES):\n",
    "        done=False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        maxScore = -np.inf\n",
    "        move =0\n",
    "        while not done:\n",
    "#             if agent.render:\n",
    "#             print(env.render())\n",
    "            move+=1\n",
    "            # get action for the current state and go one step in environment\n",
    "            action = agent.get_action(state, env)\n",
    "#             print(np.array(env.board))\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            # if an action make the episode end, then gives penalty of -100\n",
    "#             reward = reward if not done or score == 499 else agent.penalty\n",
    "#             print({0 : 'left', 1:'up' , 2:'right', 3:'down'}[action])\n",
    "            # save the sample <s, a, r, s'> to the replay memory\n",
    "            agent.append_sample(state, action, reward, next_state, done)\n",
    "            # every time step do the training\n",
    "            if (load_model is False) and (len(agent.memory) >= agent.train_start):\n",
    "                agent.train_model()\n",
    "                \n",
    "            score += reward\n",
    "            state = next_state\n",
    "            if(reward > maxScore):\n",
    "                maxScore = reward\n",
    "            if done:\n",
    "                # every episode update the target model to be same with model\n",
    "                if load_model is False:\n",
    "                    agent.update_target_model()\n",
    "                print('Top reward = {}'.format(maxScore))\n",
    "                lossss.append(agent.train_loss/move)\n",
    "                # every episode, plot the play time\n",
    "#                 score = score if score == 500 else score + 100\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                print(\"episode:\", e, \"  score:\", score, \" move:\", move,\"  memory length:\", len(agent.memory), \"  epsilon:\", agent.epsilon, ' loss:', agent.train_loss/move)\n",
    "                if (maxScore > Top) and not (load_model):\n",
    "                        Top = maxScore\n",
    "                        print('Weights save... Top reward = {}'.format(maxScore))\n",
    "                        torch.save(agent.model.state_dict(), './save_model/2048_dqn_trained.pth')\n",
    "    pylab.plot(episodes, scores, 'b')\n",
    "    pylab.title('Score per episode')\n",
    "#     pylab.savefig('save_plt/Learning_rate={},epsilon_min={},Discount_factor={},episod={}.png'.format(agent.learning_rate, agent.epsilon_min, agent.discount_factor, e+1), dpi=300, facecolor='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "rocky-problem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20990d9ed60>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.plot(scores, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-detection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-qatar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-wright",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-spice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "temporal-milan",
   "metadata": {},
   "source": [
    "# 2048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "failing-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rand\n",
    "import time\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "\n",
    "FONT = (\"Verdana\", 40, \"bold\")\n",
    "\n",
    "\n",
    "class Env(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super(Env, self).__init__()\n",
    "        self.title('2048')\n",
    "        self.geometry('{0}x{1}'.format(700, 800))\n",
    "        self.SIZE = 500\n",
    "        self.GRID_LEN = 4\n",
    "        self.GRID_PADDING = 10\n",
    "        self.BACKGROUND_COLOR_GAME = \"#92877d\"\n",
    "        self.BACKGROUND_COLOR_CELL_EMPTY = \"#9e948a\"\n",
    "        self.BACKGROUND_COLOR_DICT = {2: \"#eee4da\", 4: \"#ede0c8\", 8: \"#f2b179\", 16: \"#f59563\",\n",
    "                                      32: \"#f67c5f\", 64: \"#f65e3b\", 128: \"#edcf72\", 256: \"#edcc61\",\n",
    "                                      512: \"#edc850\", 1024: \"#edc53f\", 2048: \"#edc22e\"}\n",
    "\n",
    "        self.CELL_COLOR_DICT = {2: \"#776e65\", 4: \"#776e65\", 8: \"#f9f6f2\", 16: \"#f9f6f2\",\n",
    "                                32: \"#f9f6f2\", 64: \"#f9f6f2\", 128: \"#f9f6f2\", 256: \"#f9f6f2\",\n",
    "                                512: \"#f9f6f2\", 1024: \"#f9f6f2\", 2048: \"#f9f6f2\"}\n",
    "        self.grid_cells = []\n",
    "        self.init_grid()\n",
    "        self.init_matrix()\n",
    "        self.action_space = ['u', 'd', 'l', 'r']\n",
    "        self.action_size = len(self.action_space)\n",
    "        self.counter = 0\n",
    "        self.wait_visibility()\n",
    "\n",
    "    def init_grid(self):\n",
    "        self.background = tk.Frame(self, bg=self.BACKGROUND_COLOR_GAME, width=self.SIZE, height=self.SIZE)\n",
    "        self.background.grid()\n",
    "        for i in range(self.GRID_LEN):\n",
    "            self.grid_row = []\n",
    "            for j in range(self.GRID_LEN):\n",
    "                self.cell = tk.Frame(self.background, bg=self.BACKGROUND_COLOR_CELL_EMPTY,\n",
    "                                     width=self.SIZE / self.GRID_LEN, height=self.SIZE / self.GRID_LEN)\n",
    "                self.cell.grid(row=i, column=j, padx=self.GRID_PADDING, pady=self.GRID_PADDING)\n",
    "                # font = Font(size=FONT_SIZE, family=FONT_FAMILY, weight=FONT_WEIGHT)\n",
    "                t = Label(master=self.cell, text=\"\", bg=self.BACKGROUND_COLOR_CELL_EMPTY, justify=CENTER, font=FONT,\n",
    "                          width=4, height=2)\n",
    "                t.grid()\n",
    "                self.grid_row.append(t)\n",
    "\n",
    "            self.grid_cells.append(self.grid_row)\n",
    "        self.grid_row = []\n",
    "        self.cell = tk.Frame(self.background, bg=self.BACKGROUND_COLOR_CELL_EMPTY, width=self.SIZE,\n",
    "                             height=self.SIZE / self.GRID_LEN)\n",
    "        self.cell.grid(row=4, columnspan=4, padx=self.GRID_PADDING, pady=self.GRID_PADDING, sticky=W + E + N + S)\n",
    "        t = Label(master=self.cell, text=\"\", bg=self.BACKGROUND_COLOR_CELL_EMPTY, justify=CENTER, font=FONT, width=4,\n",
    "                  height=2)\n",
    "        t.grid(columnspan=4, ipadx=250)\n",
    "        self.grid_row.append(t)\n",
    "        self.grid_cells.append(self.grid_row)\n",
    "\n",
    "    def init_matrix(self):\n",
    "        self.game = Game(self.GRID_LEN)\n",
    "        self.state = self.game.start()\n",
    "\n",
    "    def render(self):\n",
    "        time.sleep(0.01)\n",
    "        self.update()\n",
    "\n",
    "    def make_move(self, move=None):\n",
    "        #         self.title.configure(f'2048 : {self.game.score}')\n",
    "        #         print(self.game.score)\n",
    "\n",
    "        #         output = 0 # 이 부분이 인공 신경망에서 전달해준 값을 바탕으로 선택된 action에 전달될 움직임 방향 -> 나중에 적용할 때 매개변수로 받고 환경에서 부르면 될듯\n",
    "        #         move = rand.choice([0,1,2,3]) # np.argmax(output[0]) 이런식으로 신경망이 뱉어준 움직임을 선택하거나 따로 인덱스를 주거나 해서 선택하면 될듯\n",
    "        self.game.move(move)\n",
    "        self.state = self.game.getBord()\n",
    "        return self.state\n",
    "\n",
    "    def reset(self):\n",
    "        self.game.reset()\n",
    "        self.init_matrix()\n",
    "        return self.game.getBord().reshape(-1, 1)\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        self.counter += 1\n",
    "        next_state = self.make_move(action).reshape(-1, 1)\n",
    "        reward = self.game.getReward()\n",
    "        done = self.game.isDone()\n",
    "        for i in range(self.GRID_LEN):\n",
    "            for j in range(self.GRID_LEN):\n",
    "                new_number = self.state[i][j]\n",
    "                if new_number == 0:\n",
    "                    self.grid_cells[i][j].configure(text=\"\", bg=self.BACKGROUND_COLOR_CELL_EMPTY)\n",
    "                else:\n",
    "                    self.grid_cells[i][j].configure(text=str(new_number), bg=self.BACKGROUND_COLOR_DICT[new_number],\n",
    "                                                    fg=self.CELL_COLOR_DICT[new_number])\n",
    "        self.grid_cells[4][0].configure(text=\"Game Score : {}\".format(self.game.getScore()),\n",
    "                                        bg=self.BACKGROUND_COLOR_CELL_EMPTY, justify=CENTER)\n",
    "        if done:\n",
    "            self.grid_cells[1][1].configure(text=\"You\", bg=self.BACKGROUND_COLOR_CELL_EMPTY)\n",
    "            self.grid_cells[1][2].configure(text=\"Lose!\", bg=self.BACKGROUND_COLOR_CELL_EMPTY)\n",
    "            reward = self.game.getScore()\n",
    "        return next_state, reward, done\n",
    "    \n",
    "    def close(self):\n",
    "        self.destroy()\n",
    "\n",
    "\n",
    "\n",
    "class Game:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.bord = np.zeros((self.size, self.size), dtype='int64')\n",
    "        self.score = 0\n",
    "        self.reward = 0\n",
    "        self.done = False\n",
    "\n",
    "    def findEmpty(self):\n",
    "        # 빈칸을 확인해서 좌표 return / 없으면 None return\n",
    "        z_list = np.array([[r, c] for r, c in zip(np.where(self.bord == 0)[0], np.where(self.bord == 0)[1])])\n",
    "        if z_list.size == 0:\n",
    "            return None\n",
    "        location = rand.choice(z_list)\n",
    "        return location\n",
    "\n",
    "    def isfull(self):\n",
    "        # bord가 숫자로 가득 차있는경우 True/ 빈칸이 있는경우 False 반환\n",
    "        if 0 in self.bord.reshape(-1):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def mkblock(self):\n",
    "        # 빈칸에 확률에 맞춰서 2또는 4 블럭을 생성\n",
    "        location = self.findEmpty()\n",
    "        self.bord[location[0]][location[1]] = 2 if rand.random() < 0.9 else 4\n",
    "\n",
    "    def merge(self, lstin):\n",
    "        # 합치는 연산\n",
    "        lst = lstin\n",
    "        if lst.size != len(set(lst)):\n",
    "            for t in range(lst.size - 1):\n",
    "                if lst[t] == lst[t + 1]:\n",
    "                    self.reward += lst[t]\n",
    "                    lst[t] *= 2\n",
    "                    lst[t + 1] = 0\n",
    "            lst = lst[np.where(lst != 0)]\n",
    "        return lst\n",
    "\n",
    "    def move(self, index):\n",
    "        self.reward = 0  # 움직이기 전에 보상을 초기화\n",
    "        ismove = False  # 움직임 후 변화가 없는 경우에는 안 움직인 것으로 판단하기위해 설정\n",
    "        # index에 따라 움직임\n",
    "        # 움직임이 가능한지 확인하고\n",
    "        #         print( self.canMove())\n",
    "        if self.canMove():\n",
    "            # 가능하다면 움직임 (0 - 상) (1 - 하) (2 - 좌) (3 - 우)\n",
    "            if index == 0:\n",
    "                for c in range(self.size):\n",
    "                    col = self.bord[:, c][np.where(self.bord[:, c] != 0)]\n",
    "                    col = self.merge(col)\n",
    "                    pd = 4 - col.size\n",
    "                    if np.any(self.bord[:, c] != np.pad(col, (0, pd))):\n",
    "                        self.bord[:, c] = np.pad(col, (0, pd))\n",
    "                        ismove = True\n",
    "\n",
    "            elif index == 1:\n",
    "                for c in range(self.size):\n",
    "                    col = self.bord[:, c][np.where(self.bord[:, c] != 0)]\n",
    "                    col = self.merge(col[::-1])[::-1]\n",
    "                    pd = 4 - col.size\n",
    "                    if np.any(self.bord[:, c] != np.pad(col, (pd, 0))):\n",
    "                        self.bord[:, c] = np.pad(col, (pd, 0))\n",
    "                        ismove = True\n",
    "\n",
    "            elif index == 2:\n",
    "                for r in range(self.size):\n",
    "                    row = self.bord[r, :][np.where(self.bord[r, :] != 0)]\n",
    "                    row = self.merge(row)\n",
    "                    pd = 4 - row.size\n",
    "                    if np.any(self.bord[r, :] != np.pad(row, (0, pd))):\n",
    "                        self.bord[r, :] = np.pad(row, (0, pd))\n",
    "                        ismove = True\n",
    "\n",
    "            elif index == 3:\n",
    "                for r in range(self.size):\n",
    "                    row = self.bord[r, :][np.where(self.bord[r, :] != 0)]\n",
    "                    row = self.merge(row[::-1])[::-1]\n",
    "                    pd = 4 - row.size\n",
    "                    if np.any(self.bord[r, :] != np.pad(row, (pd, 0))):\n",
    "                        self.bord[r, :] = np.pad(row, (pd, 0))\n",
    "                        ismove = True\n",
    "\n",
    "            if ismove:  # 움직임이 있었던 경우에만 블럭 생성\n",
    "                self.mkblock()\n",
    "                self.score += self.reward\n",
    "                self.reward = 10\n",
    "            else:\n",
    "                self.reward = -100\n",
    "        else:\n",
    "            # 움직일 수 없는 경우는 게임종료\n",
    "            self.gameOver()\n",
    "\n",
    "    def canMove(self):\n",
    "        # 움직임이 가능한지 확인 움직임이 가능하면 ture\n",
    "        # 반환 불가능하면 게임 종료\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size - 1):\n",
    "                if self.bord[i][j] == self.bord[i][j + 1]:\n",
    "                    return True\n",
    "        for j in range(self.size):\n",
    "            for i in range(self.size - 1):\n",
    "                if self.bord[i][j] == self.bord[i + 1][j]:\n",
    "                    return True\n",
    "        if not self.isfull():\n",
    "            return True\n",
    "        self.done = True\n",
    "        return False\n",
    "\n",
    "    def gameOver(self):\n",
    "        # done 게임 종료 선언\n",
    "        self.done = True\n",
    "        self.reward = self.score\n",
    "\n",
    "    def reset(self):\n",
    "        self.bord = np.zeros((self.size, self.size), dtype='int64')\n",
    "        self.score = 0\n",
    "        self.reward = 0\n",
    "        self.done = False\n",
    "\n",
    "    def start(self):\n",
    "        # 게임 시작\n",
    "        self.mkblock()\n",
    "        self.mkblock()\n",
    "        return self.bord\n",
    "\n",
    "    def getBord(self):\n",
    "        return self.bord\n",
    "\n",
    "    def getScore(self):\n",
    "        return self.score\n",
    "\n",
    "    def getReward(self):\n",
    "        return self.reward\n",
    "\n",
    "    def isDone(self):\n",
    "        return self.done\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "immune-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EPISODES = 2000\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, pretrain=False):\n",
    "        self.load_model = pretrain\n",
    "        self.render = True\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.01\n",
    "\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.99999\n",
    "        self.epsilon_min = 0.2\n",
    "\n",
    "        self.batch_size = 256\n",
    "        self.train_start = 1000\n",
    "\n",
    "        self.queueLenMax = 3000\n",
    "        self.memory = deque(maxlen=self.queueLenMax)\n",
    "\n",
    "        self.perfWindowSize = 10\n",
    "        self.penalty = -100\n",
    "\n",
    "        self.nNodesLayer1 = 64\n",
    "        self.nNodesLayer2 = 32\n",
    "\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "\n",
    "        self.update_target_model()  # set same weights at the first time\n",
    "\n",
    "        if self.load_model:\n",
    "            self.model.load_weights(\"./save_model/2048.h5\")\n",
    "            self.epsilon_decay = 1\n",
    "            self.epsilon = 0\n",
    "            self.epsilon_min = 0\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.nNodesLayer1, input_dim=self.state_size, activation='relu', init='he_uniform'))  # , kernel_initializer ='he_uniform'))\n",
    "        model.add(Dense(self.nNodesLayer2, activation='relu', init='he_uniform'))  # , kernel_initializer ='he_uniform'))\n",
    "        model.add(Dense(self.action_size, activation='linear', init='he_uniform'))  # , kernel_initializer ='he_uniform'))\n",
    "        model.summary()\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def get_action(self, state):\n",
    "        for i in range(4):\n",
    "                    temp_board,_,_ = controls[i](temp_board)\n",
    "                    if(np.array_equal(temp_board,prev_board)):\n",
    "                        continue\n",
    "                    else:\n",
    "                        legal_moves.append(i)\n",
    "                if(len(legal_moves)==0):\n",
    "                    finish = 'lose'\n",
    "                    continue\n",
    "        s = state.reshape(1, -1)\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            q_value = self.model.predict(s)\n",
    "            print(q_value)\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def train_model(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        else:\n",
    "            self.epsilon = self.epsilon_min\n",
    "\n",
    "        mini_batch = random.sample(self.memory, self.batch_size)\n",
    "\n",
    "        states = np.zeros((self.batch_size, self.state_size))\n",
    "        next_states = np.zeros((self.batch_size, self.state_size))\n",
    "        actions, rewards, dones = [], [], []\n",
    "        for i in range(self.batch_size):\n",
    "            states[i] = mini_batch[i][0].reshape(-1)\n",
    "            actions.append(mini_batch[i][1])\n",
    "            rewards.append(mini_batch[i][2])\n",
    "            next_states[i] = mini_batch[i][3].reshape(-1)\n",
    "            dones.append(mini_batch[i][4])\n",
    "\n",
    "        target = self.model.predict(states)\n",
    "        target_val = self.target_model.predict(next_states)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "\n",
    "            if dones[i]:\n",
    "                target[i][actions[i]] = rewards[i]\n",
    "            else:\n",
    "                target[i][actions[i]] = rewards[i] + self.discount_factor * (np.amax(target_val[i]))\n",
    "\n",
    "        # and do the model fit!\n",
    "        self.model.fit(states, target, batch_size=self.batch_size, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "third-parliament",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 64)            1088        dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 32)            2080        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 4)             132         dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3,300\n",
      "Trainable params: 3,300\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_4 (Dense)                  (None, 64)            1088        dense_input_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 32)            2080        dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 4)             132         dense_5[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3,300\n",
      "Trainable params: 3,300\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Episode: 0  score: 636  memory length 152  epsilon: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-7ca8a9a1008d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#             if i_episode > 990:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-d6fcb77e523e>\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m         \u001b[1;34m\"\"\"Enter event loop until all pending events have been processed by Tcl.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'update'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate_idletasks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \"\"\"Enter event loop until all idle callbacks have been called. This\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = Env()\n",
    "    state_size = env.get_state().reshape(1, -1).shape[1]\n",
    "    action_size = len(env.action_space)\n",
    "    agent = DQNAgent(state_size, action_size, pretrain=False)\n",
    "\n",
    "    maxScore = -np.inf\n",
    "\n",
    "\n",
    "    s = []\n",
    "    for i_episode in range(1000):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        while True:\n",
    "#             if i_episode > 990:\n",
    "            env.render()\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            agent.append_sample(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            if (agent.load_model is False) and (len(agent.memory) >= agent.train_start):\n",
    "                agent.train_model()\n",
    "\n",
    "            if done:\n",
    "                s.append(reward)\n",
    "                print('Episode:', i_episode, ' score:', reward, ' memory length', len(agent.memory), ' epsilon:', agent.epsilon)\n",
    "                if agent.load_model is False:\n",
    "                    agent.update_target_model()\n",
    "                    if reward > maxScore:\n",
    "                        maxScore = reward\n",
    "#                         agent.model.save_weights('save_model/2048.h5')\n",
    "                break\n",
    "    plt.plot(s)\n",
    "    plt.title('Score per episode, Learning_rate = {}, epsilon_min={}'.format(agent.learning_rate, agent.epsilon_min))\n",
    "    plt.savefig('save_plt/Learning_rate={},epsilon_min={},Discount_factor={},episod={}.png'.format(agent.learning_rate, agent.epsilon_min, agent.discount_factor, i_episode+1), dpi=300, facecolor='w')\n",
    "    plt.show()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "informative-young",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.argmin(np.array([-np.inf,-1000000000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-athens",
   "metadata": {},
   "source": [
    "# pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wrong-radiation",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 3,300\n",
      "Trainable params: 3,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 3,300\n",
      "Trainable params: 3,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "TclError",
     "evalue": "invalid command name \".!frame.!frame.!label\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a0d6614250ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-d6fcb77e523e>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[0mnew_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnew_number\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_cells\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBACKGROUND_COLOR_CELL_EMPTY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     self.grid_cells[i][j].configure(text=str(new_number), bg=self.BACKGROUND_COLOR_DICT[new_number],\n",
      "\u001b[1;32m~\\anaconda3\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mconfigure\u001b[1;34m(self, cnf, **kw)\u001b[0m\n\u001b[0;32m   1635\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mallowed\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mcall\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1636\u001b[0m         \"\"\"\n\u001b[1;32m-> 1637\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_configure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'configure'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfigure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36m_configure\u001b[1;34m(self, cmd, cnf, kw)\u001b[0m\n\u001b[0;32m   1625\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1626\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getconfigure1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcnf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1627\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1628\u001b[0m     \u001b[1;31m# These used to be defined in Widget:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTclError\u001b[0m: invalid command name \".!frame.!frame.!label\""
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = Env()\n",
    "    state_size = env.get_state().reshape(1, -1).shape[1]\n",
    "    action_size = len(env.action_space)\n",
    "    agent = DQNAgent(state_size, action_size, pretrain=True)\n",
    "\n",
    "    maxScore = -np.inf\n",
    "\n",
    "\n",
    "    s = []\n",
    "    for i_episode in range(20):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        while True:\n",
    "            env.render()\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            agent.append_sample(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            if (agent.load_model is False) and (len(agent.memory) >= agent.train_start):\n",
    "                agent.train_model()\n",
    "\n",
    "            if done:\n",
    "                s.append(reward)\n",
    "                print('Episode:', i_episode, ' score:', reward, ' memory length', len(agent.memory), ' epsilon:', agent.epsilon)\n",
    "                if agent.load_model is False:\n",
    "                    agent.update_target_model()\n",
    "                    if reward > maxScore:\n",
    "                        maxScore = reward\n",
    "                        agent.model.save_weights('save_model/2048.h5')\n",
    "                break\n",
    "    plt.plot(s)\n",
    "    plt.title('Score per episode, Learning_rate = {}, epsilon_min={}'.format(agent.learning_rate, agent.epsilon_min))\n",
    "    if agent.load_model is False:\n",
    "        plt.savefig('save_plt/Learning_rate={},epsilon_min={},Discount_factor={},episod={}.png'.format(agent.learning_rate, agent.epsilon_min, agent.discount_factor, i_episode+1), dpi=300, facecolor='w')\n",
    "    plt.show()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "psychological-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "a = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]])\n",
    "def change_values(X):\n",
    "    power_mat = np.zeros(shape=(1,4,4,16),dtype=np.float32)\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if(X[i][j]==0):\n",
    "                power_mat[0][i][j][0] = 1.0\n",
    "            else:\n",
    "                power = int(math.log(X[i][j],2))\n",
    "                power_mat[0][i][j][power] = 1.0\n",
    "    return power_mat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "through-killing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 4, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_values(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "secret-details",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 16 into shape (4,4,16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2a4cd8cbf5c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 16 into shape (4,4,16)"
     ]
    }
   ],
   "source": [
    "a.reshape((4,4,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-mobility",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
