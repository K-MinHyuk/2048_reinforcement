1. 선택할 수 없는 action을 선택하게되는 문제
	구현단계에서 선택한 action에 대해서 matrix의 변화가 없는경우, 즉 해당 방향으로 움직이기 전과 후의 변화가 없는경우
	score를 올리지 않고, 음의 reward만 주고 다음 step으로 넘어가도록 구현했는데,
	이로 인해 모델이 학습되지 않을 뿐 만 아니라 pre-train된 모델이 greedy한 선택을 할 경우 해당 action만 선택하여 그냥 멈춰있는 것 처럼 보임.
	
	* 생각해본 해결 방법으로는, 
		1. 선택할 수 있는 action별로 모델을 만들어서 (상하좌우, 상하좌, 상하우, ...) 선택 가능한 action별로 따로 trian시키는방법... - > 너무더러움
		2. predict에서 뱉어주는 q_value를 선택할 때, 만약 가장 높게 예측되는 action이 변화가 없는 action이라면 다음으로 높은 action을 선택하는 방법... 
			구현해보다 말았음 and 이렇게 해도 되나...?

2. 학습이 안되는 문제
	아마 1번 문제가 먼저 해결되어야 할것 같은데, 어떤 점을 바꿔볼까 생각했을 때
	인공신경망에서 마지막 layer가 linear로 나오고, loss를 mse을 사용하는점이 마음에 걸림...
	softmax를 사용하고, cross-entropy를 사용하면 안 되는지 잘 모르겠음


